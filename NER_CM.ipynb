{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5971a7c5",
   "metadata": {},
   "source": [
    "# Generate own Spacy NER tag categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9c8ae96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic categories\n",
    "\n",
    "objective = {'profile','career goal','objective','career objective','employment objective','professional objective','summary',\n",
    "             'career summary', 'professional summary','personal statement'}\n",
    "\n",
    "work_and_employment=  { 'employment history','work history','work experience','professional experience','professional background',\n",
    "        'career related experience','employment','career experience','career summary','career history','professional proficiency'}\n",
    "        \n",
    "education_and_training= {'academic background','academic experience','programs','courses','related courses','education',\n",
    "        'educational background','educational qualifications','educational training','education and training','training','academic training',\n",
    "        'professional training','course project experience','related course projects','internship experience','internships','apprenticeships',\n",
    "        'college activities','certifications','special training','qualifications','degree'}\n",
    "\n",
    "skills = {'areas of experience','areas of expertise','areas of knowledge','skills',\"other skills\",\n",
    "        \"other abilities\",'career related skills','professional skills','specialized skills','technical skills','computer skills',\n",
    "        'personal skills','computer knowledge','technologies','technical experience','proficiencies','languages','language competencies and skills',\n",
    "        'programming languages','competencies'}\n",
    "\n",
    "misc={'activities','affiliations','professional affiliations','associations','professional associations',\n",
    "        'memberships','professional memberships','athletic involvement','community involvement','referee','civic activities',\n",
    "        'extra-curricular activities','professional activities','volunteer work','additional information',\n",
    "        'interests','volunteer','volunteering','community'}\n",
    "\n",
    "accomplishments={'achievement','licenses','presentations','conference presentations','conventions','dissertations','exhibits',\n",
    "        'papers','publications','professional publications','research','research grants','project','research projects','personal projects',\n",
    "        'current research interests','thesis','theses','projects'}\n",
    "linkedin = {'linkedin'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ba29f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the training data into the right format from the objective list\n",
    "# takes in the predefined dictionaries from above\n",
    "def create_training_data(dict_inp, type): \n",
    "    \n",
    "    data = dict_inp\n",
    "    \n",
    "    patterns = []\n",
    "    for item in data:\n",
    "        pattern = {\n",
    "                    \"label\": type,\n",
    "                    \"pattern\": item\n",
    "                    }\n",
    "        patterns.append(pattern)\n",
    "    return (patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f551f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'OBJECTIVE', 'pattern': 'career objective'}, {'label': 'OBJECTIVE', 'pattern': 'objective'}, {'label': 'OBJECTIVE', 'pattern': 'profile'}, {'label': 'OBJECTIVE', 'pattern': 'professional summary'}, {'label': 'OBJECTIVE', 'pattern': 'career summary'}, {'label': 'OBJECTIVE', 'pattern': 'employment objective'}, {'label': 'OBJECTIVE', 'pattern': 'career goal'}, {'label': 'OBJECTIVE', 'pattern': 'summary'}, {'label': 'OBJECTIVE', 'pattern': 'personal statement'}, {'label': 'OBJECTIVE', 'pattern': 'professional objective'}]\n",
      "[{'label': 'WORK_AND_EMPLOYMENT', 'pattern': 'work history'}, {'label': 'WORK_AND_EMPLOYMENT', 'pattern': 'career history'}, {'label': 'WORK_AND_EMPLOYMENT', 'pattern': 'career related experience'}, {'label': 'WORK_AND_EMPLOYMENT', 'pattern': 'professional background'}, {'label': 'WORK_AND_EMPLOYMENT', 'pattern': 'employment'}, {'label': 'WORK_AND_EMPLOYMENT', 'pattern': 'career summary'}, {'label': 'WORK_AND_EMPLOYMENT', 'pattern': 'professional proficiency'}, {'label': 'WORK_AND_EMPLOYMENT', 'pattern': 'professional experience'}, {'label': 'WORK_AND_EMPLOYMENT', 'pattern': 'work experience'}, {'label': 'WORK_AND_EMPLOYMENT', 'pattern': 'career experience'}, {'label': 'WORK_AND_EMPLOYMENT', 'pattern': 'employment history'}]\n",
      "[{'label': 'EDUCATION_AND_TRAINING', 'pattern': 'education and training'}, {'label': 'EDUCATION_AND_TRAINING', 'pattern': 'academic background'}, {'label': 'EDUCATION_AND_TRAINING', 'pattern': 'college activities'}, {'label': 'EDUCATION_AND_TRAINING', 'pattern': 'related courses'}, {'label': 'EDUCATION_AND_TRAINING', 'pattern': 'academic experience'}, {'label': 'EDUCATION_AND_TRAINING', 'pattern': 'internship experience'}, {'label': 'EDUCATION_AND_TRAINING', 'pattern': 'related course projects'}, {'label': 'EDUCATION_AND_TRAINING', 'pattern': 'qualifications'}, {'label': 'EDUCATION_AND_TRAINING', 'pattern': 'degree'}, {'label': 'EDUCATION_AND_TRAINING', 'pattern': 'academic training'}, {'label': 'EDUCATION_AND_TRAINING', 'pattern': 'educational qualifications'}, {'label': 'EDUCATION_AND_TRAINING', 'pattern': 'training'}, {'label': 'EDUCATION_AND_TRAINING', 'pattern': 'courses'}, {'label': 'EDUCATION_AND_TRAINING', 'pattern': 'professional training'}, {'label': 'EDUCATION_AND_TRAINING', 'pattern': 'course project experience'}, {'label': 'EDUCATION_AND_TRAINING', 'pattern': 'educational training'}, {'label': 'EDUCATION_AND_TRAINING', 'pattern': 'apprenticeships'}, {'label': 'EDUCATION_AND_TRAINING', 'pattern': 'educational background'}, {'label': 'EDUCATION_AND_TRAINING', 'pattern': 'special training'}, {'label': 'EDUCATION_AND_TRAINING', 'pattern': 'internships'}, {'label': 'EDUCATION_AND_TRAINING', 'pattern': 'programs'}, {'label': 'EDUCATION_AND_TRAINING', 'pattern': 'certifications'}, {'label': 'EDUCATION_AND_TRAINING', 'pattern': 'education'}]\n",
      "[{'label': 'SKILLS', 'pattern': 'language competencies and skills'}, {'label': 'SKILLS', 'pattern': 'areas of experience'}, {'label': 'SKILLS', 'pattern': 'technical experience'}, {'label': 'SKILLS', 'pattern': 'skills'}, {'label': 'SKILLS', 'pattern': 'specialized skills'}, {'label': 'SKILLS', 'pattern': 'professional skills'}, {'label': 'SKILLS', 'pattern': 'areas of knowledge'}, {'label': 'SKILLS', 'pattern': 'other abilities'}, {'label': 'SKILLS', 'pattern': 'areas of expertise'}, {'label': 'SKILLS', 'pattern': 'languages'}, {'label': 'SKILLS', 'pattern': 'competencies'}, {'label': 'SKILLS', 'pattern': 'career related skills'}, {'label': 'SKILLS', 'pattern': 'technical skills'}, {'label': 'SKILLS', 'pattern': 'personal skills'}, {'label': 'SKILLS', 'pattern': 'technologies'}, {'label': 'SKILLS', 'pattern': 'computer skills'}, {'label': 'SKILLS', 'pattern': 'programming languages'}, {'label': 'SKILLS', 'pattern': 'proficiencies'}, {'label': 'SKILLS', 'pattern': 'other skills'}, {'label': 'SKILLS', 'pattern': 'computer knowledge'}]\n",
      "[{'label': 'MISC', 'pattern': 'associations'}, {'label': 'MISC', 'pattern': 'professional memberships'}, {'label': 'MISC', 'pattern': 'extra-curricular activities'}, {'label': 'MISC', 'pattern': 'volunteer work'}, {'label': 'MISC', 'pattern': 'community'}, {'label': 'MISC', 'pattern': 'volunteering'}, {'label': 'MISC', 'pattern': 'community involvement'}, {'label': 'MISC', 'pattern': 'volunteer'}, {'label': 'MISC', 'pattern': 'activities'}, {'label': 'MISC', 'pattern': 'athletic involvement'}, {'label': 'MISC', 'pattern': 'professional affiliations'}, {'label': 'MISC', 'pattern': 'additional information'}, {'label': 'MISC', 'pattern': 'civic activities'}, {'label': 'MISC', 'pattern': 'memberships'}, {'label': 'MISC', 'pattern': 'affiliations'}, {'label': 'MISC', 'pattern': 'professional associations'}, {'label': 'MISC', 'pattern': 'interests'}, {'label': 'MISC', 'pattern': 'professional activities'}, {'label': 'MISC', 'pattern': 'referee'}]\n",
      "[{'label': 'ACCOMPLISHMENTS', 'pattern': 'licenses'}, {'label': 'ACCOMPLISHMENTS', 'pattern': 'achievement'}, {'label': 'ACCOMPLISHMENTS', 'pattern': 'personal projects'}, {'label': 'ACCOMPLISHMENTS', 'pattern': 'presentations'}, {'label': 'ACCOMPLISHMENTS', 'pattern': 'project'}, {'label': 'ACCOMPLISHMENTS', 'pattern': 'dissertations'}, {'label': 'ACCOMPLISHMENTS', 'pattern': 'thesis'}, {'label': 'ACCOMPLISHMENTS', 'pattern': 'current research interests'}, {'label': 'ACCOMPLISHMENTS', 'pattern': 'professional publications'}, {'label': 'ACCOMPLISHMENTS', 'pattern': 'conventions'}, {'label': 'ACCOMPLISHMENTS', 'pattern': 'papers'}, {'label': 'ACCOMPLISHMENTS', 'pattern': 'research grants'}, {'label': 'ACCOMPLISHMENTS', 'pattern': 'theses'}, {'label': 'ACCOMPLISHMENTS', 'pattern': 'research'}, {'label': 'ACCOMPLISHMENTS', 'pattern': 'research projects'}, {'label': 'ACCOMPLISHMENTS', 'pattern': 'projects'}, {'label': 'ACCOMPLISHMENTS', 'pattern': 'publications'}, {'label': 'ACCOMPLISHMENTS', 'pattern': 'conference presentations'}, {'label': 'ACCOMPLISHMENTS', 'pattern': 'exhibits'}]\n",
      "[{'label': 'LINKEDIN', 'pattern': 'linkedin'}]\n"
     ]
    }
   ],
   "source": [
    "patterns = create_training_data(objective,'OBJECTIVE')\n",
    "print(patterns)\n",
    "patterns_w = create_training_data(work_and_employment,'WORK_AND_EMPLOYMENT')\n",
    "print(patterns_w)\n",
    "patterns_e = create_training_data(education_and_training,'EDUCATION_AND_TRAINING')\n",
    "print(patterns_e)\n",
    "patterns_sk = create_training_data(skills,'SKILLS')\n",
    "print(patterns_sk)\n",
    "patterns_m = create_training_data(misc,'MISC')\n",
    "print(patterns_m)\n",
    "patterns_a = create_training_data(accomplishments,'ACCOMPLISHMENTS')\n",
    "print(patterns_a)\n",
    "patterns_l = create_training_data(linkedin,'LINKEDIN')\n",
    "print(patterns_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b688c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'OBJECTIVE', 'pattern': 'career objective'}, {'label': 'OBJECTIVE', 'pattern': 'objective'}, {'label': 'OBJECTIVE', 'pattern': 'profile'}, {'label': 'OBJECTIVE', 'pattern': 'professional summary'}, {'label': 'OBJECTIVE', 'pattern': 'career summary'}, {'label': 'OBJECTIVE', 'pattern': 'employment objective'}, {'label': 'OBJECTIVE', 'pattern': 'career goal'}, {'label': 'OBJECTIVE', 'pattern': 'summary'}, {'label': 'OBJECTIVE', 'pattern': 'personal statement'}, {'label': 'OBJECTIVE', 'pattern': 'professional objective'}, {'label': 'WORK_AND_EMPLOYMENT', 'pattern': 'work history'}, {'label': 'WORK_AND_EMPLOYMENT', 'pattern': 'career history'}, {'label': 'WORK_AND_EMPLOYMENT', 'pattern': 'career related experience'}, {'label': 'WORK_AND_EMPLOYMENT', 'pattern': 'professional background'}, {'label': 'WORK_AND_EMPLOYMENT', 'pattern': 'employment'}, {'label': 'WORK_AND_EMPLOYMENT', 'pattern': 'career summary'}, {'label': 'WORK_AND_EMPLOYMENT', 'pattern': 'professional proficiency'}, {'label': 'WORK_AND_EMPLOYMENT', 'pattern': 'professional experience'}, {'label': 'WORK_AND_EMPLOYMENT', 'pattern': 'work experience'}, {'label': 'WORK_AND_EMPLOYMENT', 'pattern': 'career experience'}, {'label': 'WORK_AND_EMPLOYMENT', 'pattern': 'employment history'}, {'label': 'EDUCATION_AND_TRAINING', 'pattern': 'education and training'}, {'label': 'EDUCATION_AND_TRAINING', 'pattern': 'academic background'}, {'label': 'EDUCATION_AND_TRAINING', 'pattern': 'college activities'}, {'label': 'EDUCATION_AND_TRAINING', 'pattern': 'related courses'}, {'label': 'EDUCATION_AND_TRAINING', 'pattern': 'academic experience'}, {'label': 'EDUCATION_AND_TRAINING', 'pattern': 'internship experience'}, {'label': 'EDUCATION_AND_TRAINING', 'pattern': 'related course projects'}, {'label': 'EDUCATION_AND_TRAINING', 'pattern': 'qualifications'}, {'label': 'EDUCATION_AND_TRAINING', 'pattern': 'degree'}, {'label': 'EDUCATION_AND_TRAINING', 'pattern': 'academic training'}, {'label': 'EDUCATION_AND_TRAINING', 'pattern': 'educational qualifications'}, {'label': 'EDUCATION_AND_TRAINING', 'pattern': 'training'}, {'label': 'EDUCATION_AND_TRAINING', 'pattern': 'courses'}, {'label': 'EDUCATION_AND_TRAINING', 'pattern': 'professional training'}, {'label': 'EDUCATION_AND_TRAINING', 'pattern': 'course project experience'}, {'label': 'EDUCATION_AND_TRAINING', 'pattern': 'educational training'}, {'label': 'EDUCATION_AND_TRAINING', 'pattern': 'apprenticeships'}, {'label': 'EDUCATION_AND_TRAINING', 'pattern': 'educational background'}, {'label': 'EDUCATION_AND_TRAINING', 'pattern': 'special training'}, {'label': 'EDUCATION_AND_TRAINING', 'pattern': 'internships'}, {'label': 'EDUCATION_AND_TRAINING', 'pattern': 'programs'}, {'label': 'EDUCATION_AND_TRAINING', 'pattern': 'certifications'}, {'label': 'EDUCATION_AND_TRAINING', 'pattern': 'education'}, {'label': 'SKILLS', 'pattern': 'language competencies and skills'}, {'label': 'SKILLS', 'pattern': 'areas of experience'}, {'label': 'SKILLS', 'pattern': 'technical experience'}, {'label': 'SKILLS', 'pattern': 'skills'}, {'label': 'SKILLS', 'pattern': 'specialized skills'}, {'label': 'SKILLS', 'pattern': 'professional skills'}, {'label': 'SKILLS', 'pattern': 'areas of knowledge'}, {'label': 'SKILLS', 'pattern': 'other abilities'}, {'label': 'SKILLS', 'pattern': 'areas of expertise'}, {'label': 'SKILLS', 'pattern': 'languages'}, {'label': 'SKILLS', 'pattern': 'competencies'}, {'label': 'SKILLS', 'pattern': 'career related skills'}, {'label': 'SKILLS', 'pattern': 'technical skills'}, {'label': 'SKILLS', 'pattern': 'personal skills'}, {'label': 'SKILLS', 'pattern': 'technologies'}, {'label': 'SKILLS', 'pattern': 'computer skills'}, {'label': 'SKILLS', 'pattern': 'programming languages'}, {'label': 'SKILLS', 'pattern': 'proficiencies'}, {'label': 'SKILLS', 'pattern': 'other skills'}, {'label': 'SKILLS', 'pattern': 'computer knowledge'}, {'label': 'MISC', 'pattern': 'associations'}, {'label': 'MISC', 'pattern': 'professional memberships'}, {'label': 'MISC', 'pattern': 'extra-curricular activities'}, {'label': 'MISC', 'pattern': 'volunteer work'}, {'label': 'MISC', 'pattern': 'community'}, {'label': 'MISC', 'pattern': 'volunteering'}, {'label': 'MISC', 'pattern': 'community involvement'}, {'label': 'MISC', 'pattern': 'volunteer'}, {'label': 'MISC', 'pattern': 'activities'}, {'label': 'MISC', 'pattern': 'athletic involvement'}, {'label': 'MISC', 'pattern': 'professional affiliations'}, {'label': 'MISC', 'pattern': 'additional information'}, {'label': 'MISC', 'pattern': 'civic activities'}, {'label': 'MISC', 'pattern': 'memberships'}, {'label': 'MISC', 'pattern': 'affiliations'}, {'label': 'MISC', 'pattern': 'professional associations'}, {'label': 'MISC', 'pattern': 'interests'}, {'label': 'MISC', 'pattern': 'professional activities'}, {'label': 'MISC', 'pattern': 'referee'}]\n"
     ]
    }
   ],
   "source": [
    "combine_dict = patterns+patterns_w+patterns_e+patterns_sk+patterns_m #+patterns_a+patterns_l\n",
    "print(combine_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df1d9d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "from spacy.pipeline import EntityRuler\n",
    "import json\n",
    "\n",
    "# create a new NER pattern based on objective and saves them in resume_ner \n",
    "def generate_rules(patterns):\n",
    "    #nlp = English()\n",
    "    nlp = spacy.load('en_core_web_lg')\n",
    "    ruler = EntityRuler(nlp)\n",
    "    ruler.add_patterns(patterns)\n",
    "    nlp.add_pipe(ruler)\n",
    "    nlp.to_disk(\"resume_ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e239e4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_res = spacy.load('resume_ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "707d0b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now generte the rules based on combined dictionary\n",
    "generate_rules(combine_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2af61b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a simple functon to print out the entities in a text string\n",
    "def print_doc_ents(text):\n",
    "    \n",
    "    doc = nlp_res(text.lower()) # incase it isn't already lower case    \n",
    "    \n",
    "    #for token in doc:\n",
    "    #    if(token.pos_print(token.text,'->',token.pos_)\n",
    "    #ind = {}\n",
    "    ind_list = []\n",
    "    for ent in doc.ents:\n",
    "        if(ent.label_=='OBJECTIVE'):\n",
    "            print(ent.text, ent.label_,ent.start, ent.end)\n",
    "            ind_list.append((ent.text,ent.start))\n",
    "        elif(ent.label_=='WORK_AND_EMPLOYMENT'):\n",
    "            #print(token.tag_)\n",
    "            print(ent.text, ent.label_, ent.start,ent.end) #_char-ent.sent.start_char, ent.end_char-ent.sent.start_char)\n",
    "            ind_list.append((ent.text,ent.start))\n",
    "        elif(ent.label_=='EDUCATION_AND_TRAINING'):\n",
    "            print(ent.text, ent.label_, ent.start, ent.end)\n",
    "            ind_list.append((ent.text,ent.start))\n",
    "        elif(ent.label_=='SKILLS_HEADER'):\n",
    "            print(ent.text, ent.label_, ent.start, ent.end)\n",
    "            ind_list.append((ent.text,ent.start))\n",
    "        elif(ent.label_=='MISC'):\n",
    "            print(ent.text, ent.label_, ent.start, ent.end)\n",
    "            ind_list.append((ent.text,ent.start))\n",
    "        elif(ent.label_=='ACCOMPLISHMENTS'):\n",
    "            print(ent.text, ent.label_, ent.start, ent.end)\n",
    "            ind_list.append((ent.text,ent.start))\n",
    "                    \n",
    "    print(sorted(ind_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3bbc27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.high_level import extract_text\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = extract_text(pdf_path)\n",
    "    #for line in text:\n",
    "    #    print(line)\n",
    "    #print(text)\n",
    "    return text \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5639e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "peter_text = extract_text_from_pdf('/home/chris/reesby/reverse_Malih/new_resumes/pdfs/Peter-Ziminovic-Resume.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ceffb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "peter_text = peter_text.replace('\\n',' ')\n",
    "peter_text = peter_text.replace('\\t',' ')\n",
    "peter_text = peter_text.replace('\\uf0b7',' ')\n",
    "peter_text = peter_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd8f2186",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'date: 20th june 2020 name : peter zimonovic email: stormy_pete_1@yahoo.com phone: +61 404 123 333  personal statement  i was employed at the bureau of meteorology (bom) for 27 years as an operational  meteorologist and was made redundant in december 2020. i am currently completing a  masters in data science (expected completion august 2021).  i am currently doing a data science internship at reeby.  in my previous role i  provided direct advice to air traffic controllers and airlines on the  current and expected weather at sydney airport. i have extensive knowledge of aviation  meteorology and how that affects airline operations. i also used my extensive computing  knowledge to develop and maintain several oracle databases tables and java based web  applications.   my education history demonstrates the drive i have to keep my skills up to date and i wish  to continue learning and challenging myself. i am currently current completing a master’s  degree, see below. my current studies have increased my desire to move into a machine  learning/ai field, as well as working with large amounts of computer-based data and  modelling information.   bsc (hons) atmospheric science macquarie university, completed 1993  education   hsc barker college, hornsby, completed 1989     dip met. bureau of meteorology training centre, completed 1994   grad dip computing monash university, completed 2003   master of data science - james cook university – expected august 2021.  computing skills, experience and abilities   java programmer - sun certification – completed 2005 java web component developer – sun certification – completed 2005 16 years sql experience (oracle) excellent knowledge of linux/windows operating systems            more recently with my master’s studies i have learned to program in python and r   statistical program.  career history  reesby  at reesby i have worked on 2 projects. the first was an emotional recognition system that  would split up and interview into the speakers and then perform emotional recognition  based on the separated audio and video of that interview. the current project involves extracting information from a persons resume and tehn using  that information to match with potential employment opportunities. both projects have been developed using the python programming language.  may 2021-present  bureau of meteorology  operational weather forecaster for nsw 1995-2000. antarctic weather forecaster - casey station.          summer 1997 – 1998                   january 1994 – december 2020  \\x0csenior forecaster - sydney airport meteorological unit    2000-2020     in my day to day operations, i must provide:  o accurate and timely weather forecasts for sydney airport working on 12-hour  o make decisive and urgent decision-making action, as a result of developing   o talking to customers including: airlines, air traffic controllers, parachutist’s,   and sky writers, to provide information  o support and maintenance of all computer systems and navigating database   shifts.  weather events.  issues.   o training new staff.      i have developed numerous web-based applications to streamline the forecasting  process. using the apache tomcat webserver as a front end for displaying web pages and providing the ux for presenting results. with back end java classes performing  oracle database manipulations such as querying, storing, and retrieving data.  systems developed include the jsp pages, servlets and java classes used to run these  in model-view-controller (mvc) architecture – i am the person with sole  responsibility for this system having developed all layers.      other applications created store important forecast/warnings in self-developed  databases, then verify these forecasts against later observations as they occur.   other web applications developed include display programs that take both current   and past data and display in meaningful graphical visualisations.    more specifically using historical data from the observations database to develop  and refine a fog forecasting methodology for sydney airport. this methodology  compares observed values with climatological data and determines if thresholds  have been exceeded and fog is a possibility. data from all fog events back to 1977 at  sydney airport were extracted manually using sql, data manipulation and  visualisation techniques.    use case – early morning fog was rolling across the airport and the airlines wanted a definitive and direct answer as to when the fog would clear? they would have to  divert their early morning 6.00am arrivals, if i have not been able to tell then that it  would disperse by 6.20am. it did as i forecast to them. this decision alone saved the  airlines over $1.0m that morning.   strong accountability and ability to work under pressure.     community organisations level 3 football referee - kuringai district referee association player/manager - west pymble football club teams  player - gordon golf club            2012-present          2007-present          2007-present  professional references  \\x0c'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peter_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14bda12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "personal statement OBJECTIVE 19 21\n",
      "education EDUCATION_AND_TRAINING 145 146\n",
      "degree EDUCATION_AND_TRAINING 179 180\n",
      "education EDUCATION_AND_TRAINING 232 233\n",
      "training EDUCATION_AND_TRAINING 249 250\n",
      "career history WORK_AND_EMPLOYMENT 340 342\n",
      "employment WORK_AND_EMPLOYMENT 408 409\n",
      "training EDUCATION_AND_TRAINING 558 559\n",
      "programs EDUCATION_AND_TRAINING 697 698\n",
      "community MISC 875 876\n",
      "referee MISC 880 881\n",
      "referee MISC 884 885\n",
      "[('career history', 340), ('community', 875), ('degree', 179), ('education', 145), ('education', 232), ('employment', 408), ('personal statement', 19), ('programs', 697), ('referee', 880), ('referee', 884), ('training', 249), ('training', 558)]\n"
     ]
    }
   ],
   "source": [
    "print_doc_ents(peter_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9353c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp_res(peter_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7ca7ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6edcd7c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "personal statement"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[19:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae359dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "personal statement  i was employed at the bureau of meteorology (bom) for 27 years as an operational  meteorologist and was made redundant in december 2020. i am currently completing a  masters in data science (expected completion august 2021).  i am currently doing a data science internship at reeby.  in my previous role i  provided direct advice to air traffic controllers and airlines on the  current and expected weather at sydney airport. i have extensive knowledge of aviation  meteorology and how that affects airline operations. i also used my extensive computing  knowledge to develop and maintain several oracle databases tables and java based web  applications.   "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[19:144]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b75d450d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "education history demonstrates the drive i have to keep my skills up to date and i wish  to continue learning and challenging myself. i am currently current completing a master’s  degree"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[145:180]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70b0a231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "education   hsc barker college, hornsby, completed 1989     dip met. bureau of meteorology training centre, completed 1994   grad dip computing monash university, completed 2003   master of data science - james cook university – expected august 2021.  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[232:278]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb6f54c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "career history  reesby  at reesby i have worked on 2 projects. the first was an emotional recognition system that  would split up and interview into the speakers and then perform emotional recognition  based on the separated audio and video of that interview. the current project involves extracting information from a persons resume and tehn using  that information to match with potential employment opportunities. both projects have been developed using the python programming language.  may 2021-present  bureau of meteorology  operational weather forecaster for nsw 1995-2000. antarctic weather forecaster - casey station.          summer 1997 – 1998                   january 1994 – december 2020  \n",
       "senior forecaster - sydney airport meteorological unit    2000-2020     in my day to day operations, i must provide:  o accurate and timely weather forecasts for sydney airport working on 12-hour  o make decisive and urgent decision-making action, as a result of developing   o talking to customers including: airlines, air traffic controllers, parachutist’s,   and sky writers, to provide information  o support and maintenance of all computer systems and navigating database   shifts.  weather events.  issues.   o"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[340:558]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20527bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "training new staff.      i have developed numerous web-based applications to streamline the forecasting  process. using the apache tomcat webserver as a front end for displaying web pages and providing the ux for presenting results. with back end java classes performing  oracle database manipulations such as querying, storing, and retrieving data.  systems developed include the jsp pages, servlets and java classes used to run these  in model-view-controller (mvc) architecture – i am the person with sole  responsibility for this system having developed all layers.      other applications created store important forecast/warnings in self-developed  databases, then verify these forecasts against later observations as they occur.   other web applications developed include display programs that take both current   and past data and display in meaningful graphical visualisations.    more specifically using historical data from the observations database to develop  and refine a fog forecasting methodology for sydney airport. this methodology  compares observed values with climatological data and determines if thresholds  have been exceeded and fog is a possibility. data from all fog events back to 1977 at  sydney airport were extracted manually using sql, data manipulation and  visualisation techniques.    use case – early morning fog was rolling across the airport and the airlines wanted a definitive and direct answer as to when the fog would clear? they would have to  divert their early morning 6.00am arrivals, if i have not been able to tell then that it  would disperse by 6.20am. it did as i forecast to them. this decision alone saved the  airlines over $1.0m that morning.   strong accountability and ability to work under pressure.     "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[558:875]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aad0d409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "community organisations level 3 football referee - kuringai district referee association player/manager - west pymble football club teams  player - gordon golf club            2012-present          2007-present          2007-present  professional references  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[875:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586d3b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25854c9a",
   "metadata": {},
   "source": [
    "# now to load lots of resumes and see if the categorisation works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bfc2e2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tika import parser\n",
    "import os,glob\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def convert_pdf_to_text(dir):\n",
    "    output = []\n",
    "    #output = pd.DataFrame()\n",
    "    #for root, dirs, files in os.walk(dir):\n",
    "    #    print(files)\n",
    "    res_list = sorted(glob.glob(dir),key=os.path.getmtime)\n",
    "    #print('from convert to pdf - ', res_list)\n",
    "    for res in res_list:\n",
    "    \n",
    "\n",
    "#        for file in files:\n",
    "        #path_to_pdf = os.path.join(root, file)\n",
    "        [stem, ext] = os.path.splitext(res)#path_to_pdf)\n",
    "        if ext == \".pdf\":\n",
    "            print(\"Processing \" + res)#  path_to_pdf)\n",
    "            pdf_contents = parser.from_file(res, service=\"text\") \n",
    "            path_to_txt = stem + \".txt\"\n",
    "            pdf_remove_newline = pdf_contents[\"content\"].replace(\"\\n\",\" \")\n",
    "            output.append(pdf_remove_newline) #pdf_contents[\"content\"])\n",
    "    \n",
    "    df = pd.DataFrame(output, columns=[\"Resumes\"])\n",
    "    df.to_csv(\"/home/chris/reesby/reverse_Malih/new_resumes/pdfs/All_new.csv\")\n",
    "    return print_doc_ents(' '.join(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "799d05bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/chris/reesby/reverse_Malih/new_resumes/pdfs/Resume 2.pdf\n",
      "Processing /home/chris/reesby/reverse_Malih/new_resumes/pdfs/Emily Loughlin Online Sales Representative Resume.pdf\n",
      "Processing /home/chris/reesby/reverse_Malih/new_resumes/pdfs/Francesca Purcell Online Sales Representative Resume.pdf\n",
      "Processing /home/chris/reesby/reverse_Malih/new_resumes/pdfs/Joshua Nicholson Online Sales Representative Resume.pdf\n",
      "Processing /home/chris/reesby/reverse_Malih/new_resumes/pdfs/Jon-Michael Parr Online Sales Representative Resume.pdf\n",
      "Processing /home/chris/reesby/reverse_Malih/new_resumes/pdfs/Mathew Milanese Online Sales Representative Resume.pdf\n",
      "Processing /home/chris/reesby/reverse_Malih/new_resumes/pdfs/Sarah Musgrave Online Sales Representative Resume.pdf\n",
      "Processing /home/chris/reesby/reverse_Malih/new_resumes/pdfs/Genovev Biddle Online Sales Representative Resume.pdf\n",
      "Processing /home/chris/reesby/reverse_Malih/new_resumes/pdfs/Martin Howells Online Sales Representative Resume.pdf\n",
      "Processing /home/chris/reesby/reverse_Malih/new_resumes/pdfs/Shontel Lester Online Sales Representative Resume.pdf\n",
      "Processing /home/chris/reesby/reverse_Malih/new_resumes/pdfs/Ngatau O'Dowd Online Sales Representative Resume.pdf\n",
      "Processing /home/chris/reesby/reverse_Malih/new_resumes/pdfs/Donna Harvey Online Sales Representative Resume.pdf\n",
      "Processing /home/chris/reesby/reverse_Malih/new_resumes/pdfs/Peter-Ziminovic-Resume.pdf\n",
      "objective OBJECTIVE 5 6\n",
      "profile OBJECTIVE 67 68\n",
      "training EDUCATION_AND_TRAINING 177 178\n",
      "profile OBJECTIVE 220 221\n",
      "training EDUCATION_AND_TRAINING 254 255\n",
      "degree EDUCATION_AND_TRAINING 328 329\n",
      "education EDUCATION_AND_TRAINING 357 358\n",
      "education EDUCATION_AND_TRAINING 380 381\n",
      "training EDUCATION_AND_TRAINING 444 445\n",
      "objective OBJECTIVE 687 688\n",
      "activities MISC 1092 1093\n",
      "training EDUCATION_AND_TRAINING 1114 1115\n",
      "courses EDUCATION_AND_TRAINING 1783 1784\n",
      "programs EDUCATION_AND_TRAINING 2429 2430\n",
      "training EDUCATION_AND_TRAINING 2530 2531\n",
      "community MISC 2584 2585\n",
      "education EDUCATION_AND_TRAINING 3090 3091\n",
      "summary OBJECTIVE 3317 3318\n",
      "programs EDUCATION_AND_TRAINING 3389 3390\n",
      "activities MISC 3460 3461\n",
      "programs EDUCATION_AND_TRAINING 3553 3554\n",
      "activities MISC 3557 3558\n",
      "programs EDUCATION_AND_TRAINING 3782 3783\n",
      "activities MISC 3845 3846\n",
      "activities MISC 3872 3873\n",
      "activities MISC 3958 3959\n",
      "programs EDUCATION_AND_TRAINING 3999 4000\n",
      "programs EDUCATION_AND_TRAINING 4090 4091\n",
      "activities MISC 4114 4115\n",
      "activities MISC 4168 4169\n",
      "activities MISC 4527 4528\n",
      "education EDUCATION_AND_TRAINING 4562 4563\n",
      "personal statement OBJECTIVE 4670 4672\n",
      "training EDUCATION_AND_TRAINING 4768 4769\n",
      "employment history WORK_AND_EMPLOYMENT 4838 4840\n",
      "qualifications EDUCATION_AND_TRAINING 4929 4930\n",
      "education EDUCATION_AND_TRAINING 5062 5063\n",
      "profile OBJECTIVE 5119 5120\n",
      "education EDUCATION_AND_TRAINING 5609 5610\n",
      "education EDUCATION_AND_TRAINING 5614 5615\n",
      "education EDUCATION_AND_TRAINING 5621 5622\n",
      "profile OBJECTIVE 5671 5672\n",
      "employment WORK_AND_EMPLOYMENT 5685 5686\n",
      "education EDUCATION_AND_TRAINING 5889 5890\n",
      "community MISC 5902 5903\n",
      "work experience WORK_AND_EMPLOYMENT 5916 5918\n",
      "activities MISC 6469 6470\n",
      "summary OBJECTIVE 7036 7037\n",
      "training EDUCATION_AND_TRAINING 7194 7195\n",
      "profile OBJECTIVE 7227 7228\n",
      "training EDUCATION_AND_TRAINING 7297 7298\n",
      "training EDUCATION_AND_TRAINING 7508 7509\n",
      "programs EDUCATION_AND_TRAINING 7512 7513\n",
      "education EDUCATION_AND_TRAINING 7663 7664\n",
      "summary OBJECTIVE 7743 7744\n",
      "education EDUCATION_AND_TRAINING 7848 7849\n",
      "profile OBJECTIVE 7877 7878\n",
      "professional experience WORK_AND_EMPLOYMENT 7890 7892\n",
      "objective OBJECTIVE 8021 8022\n",
      "professional experience WORK_AND_EMPLOYMENT 8094 8096\n",
      "summary OBJECTIVE 8231 8232\n",
      "education EDUCATION_AND_TRAINING 8336 8337\n",
      "work history WORK_AND_EMPLOYMENT 8364 8366\n",
      "summary OBJECTIVE 8751 8752\n",
      "education EDUCATION_AND_TRAINING 8856 8857\n",
      "work history WORK_AND_EMPLOYMENT 8884 8886\n",
      "summary OBJECTIVE 9138 9139\n",
      "profile OBJECTIVE 9211 9212\n",
      "training EDUCATION_AND_TRAINING 9804 9805\n",
      "education EDUCATION_AND_TRAINING 9807 9808\n",
      "activities MISC 10028 10029\n",
      "activities MISC 10077 10078\n",
      "activities MISC 10087 10088\n",
      "activities MISC 10317 10318\n",
      "programs EDUCATION_AND_TRAINING 10447 10448\n",
      "qualifications EDUCATION_AND_TRAINING 10499 10500\n",
      "training EDUCATION_AND_TRAINING 10518 10519\n",
      "summary OBJECTIVE 10653 10654\n",
      "employment WORK_AND_EMPLOYMENT 10924 10925\n",
      "employment WORK_AND_EMPLOYMENT 11141 11142\n",
      "objective OBJECTIVE 11863 11864\n",
      "employment WORK_AND_EMPLOYMENT 11875 11876\n",
      "employment history WORK_AND_EMPLOYMENT 12126 12128\n",
      "profile OBJECTIVE 12636 12637\n",
      "education EDUCATION_AND_TRAINING 12658 12659\n",
      "qualifications EDUCATION_AND_TRAINING 12677 12678\n",
      "objective OBJECTIVE 12861 12862\n",
      "professional experience WORK_AND_EMPLOYMENT 12901 12903\n",
      "activities MISC 13107 13108\n",
      "employment WORK_AND_EMPLOYMENT 13141 13142\n",
      "volunteer MISC 13482 13483\n",
      "volunteer MISC 13502 13503\n",
      "training EDUCATION_AND_TRAINING 13732 13733\n",
      "qualifications EDUCATION_AND_TRAINING 14131 14132\n",
      "work experience WORK_AND_EMPLOYMENT 14200 14202\n",
      "training EDUCATION_AND_TRAINING 14423 14424\n",
      "programs EDUCATION_AND_TRAINING 14426 14427\n",
      "programs EDUCATION_AND_TRAINING 14472 14473\n",
      "training EDUCATION_AND_TRAINING 14477 14478\n",
      "personal statement OBJECTIVE 14917 14919\n",
      "education EDUCATION_AND_TRAINING 15042 15043\n",
      "degree EDUCATION_AND_TRAINING 15076 15077\n",
      "education EDUCATION_AND_TRAINING 15117 15118\n",
      "training EDUCATION_AND_TRAINING 15146 15147\n",
      "career history WORK_AND_EMPLOYMENT 15241 15243\n",
      "employment WORK_AND_EMPLOYMENT 15309 15310\n",
      "training EDUCATION_AND_TRAINING 15457 15458\n",
      "programs EDUCATION_AND_TRAINING 15599 15600\n",
      "community MISC 15780 15781\n",
      "referee MISC 15785 15786\n",
      "referee MISC 15789 15790\n",
      "[('activities', 1092), ('activities', 3460), ('activities', 3557), ('activities', 3845), ('activities', 3872), ('activities', 3958), ('activities', 4114), ('activities', 4168), ('activities', 4527), ('activities', 6469), ('activities', 10028), ('activities', 10077), ('activities', 10087), ('activities', 10317), ('activities', 13107), ('career history', 15241), ('community', 2584), ('community', 5902), ('community', 15780), ('courses', 1783), ('degree', 328), ('degree', 15076), ('education', 357), ('education', 380), ('education', 3090), ('education', 4562), ('education', 5062), ('education', 5609), ('education', 5614), ('education', 5621), ('education', 5889), ('education', 7663), ('education', 7848), ('education', 8336), ('education', 8856), ('education', 9807), ('education', 12658), ('education', 15042), ('education', 15117), ('employment', 5685), ('employment', 10924), ('employment', 11141), ('employment', 11875), ('employment', 13141), ('employment', 15309), ('employment history', 4838), ('employment history', 12126), ('objective', 5), ('objective', 687), ('objective', 8021), ('objective', 11863), ('objective', 12861), ('personal statement', 4670), ('personal statement', 14917), ('professional experience', 7890), ('professional experience', 8094), ('professional experience', 12901), ('profile', 67), ('profile', 220), ('profile', 5119), ('profile', 5671), ('profile', 7227), ('profile', 7877), ('profile', 9211), ('profile', 12636), ('programs', 2429), ('programs', 3389), ('programs', 3553), ('programs', 3782), ('programs', 3999), ('programs', 4090), ('programs', 7512), ('programs', 10447), ('programs', 14426), ('programs', 14472), ('programs', 15599), ('qualifications', 4929), ('qualifications', 10499), ('qualifications', 12677), ('qualifications', 14131), ('referee', 15785), ('referee', 15789), ('summary', 3317), ('summary', 7036), ('summary', 7743), ('summary', 8231), ('summary', 8751), ('summary', 9138), ('summary', 10653), ('training', 177), ('training', 254), ('training', 444), ('training', 1114), ('training', 2530), ('training', 4768), ('training', 7194), ('training', 7297), ('training', 7508), ('training', 9804), ('training', 10518), ('training', 13732), ('training', 14423), ('training', 14477), ('training', 15146), ('training', 15457), ('volunteer', 13482), ('volunteer', 13502), ('work experience', 5916), ('work experience', 14200), ('work history', 8364), ('work history', 8884)]\n"
     ]
    }
   ],
   "source": [
    "convert_pdf_to_text('/home/chris/reesby/reverse_Malih/new_resumes/pdfs/*.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "db139beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">date: \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    20th june 2020\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " name : \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    peter zimonovic\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " email: stormy_pete_1@yahoo.com phone: +61 \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    404\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " 123 \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    333\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       "  \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    personal statement\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">OBJECTIVE</span>\n",
       "</mark>\n",
       "  i was employed at \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the bureau of meteorology (bom)\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " for \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    27 years\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " as an operational  meteorologist and was made redundant in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    december 2020\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ". i am currently completing a  masters in data science (expected completion \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    august 2021\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ").  i am currently doing a data science internship at \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    reeby\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ".  in my previous role i  provided direct advice to air traffic controllers and airlines on the  current and expected weather at \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    sydney airport\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">FAC</span>\n",
       "</mark>\n",
       ". i have extensive knowledge of aviation  meteorology and how that affects airline operations. i also used my extensive computing  knowledge to develop and maintain several oracle databases tables and java based web  applications.   my \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    education\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">EDUCATION_AND_TRAINING</span>\n",
       "</mark>\n",
       " history demonstrates the drive i have to keep my \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    skills\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">SKILLS</span>\n",
       "</mark>\n",
       " up to date and i wish  to continue learning and challenging myself. i am currently current completing a master’s  \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    degree\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">EDUCATION_AND_TRAINING</span>\n",
       "</mark>\n",
       ", see below. my current studies have increased my desire to move into a machine  learning/ai field, as well as working with large amounts of computer-based data and  modelling information.   bsc (hons) atmospheric science macquarie university, completed \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    1993\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       "  \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    education\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">EDUCATION_AND_TRAINING</span>\n",
       "</mark>\n",
       "   hsc barker college, \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    hornsby\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", completed \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    1989\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       "     dip met. bureau of meteorology \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    training\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">EDUCATION_AND_TRAINING</span>\n",
       "</mark>\n",
       " centre, completed \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    1994\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       "   grad dip computing \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    monash university\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", completed \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2003\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       "   master of data science - james cook university – expected \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    august 2021\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ".  computing \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    skills\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">SKILLS</span>\n",
       "</mark>\n",
       ", experience and abilities   java programmer - sun certification – completed \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2005\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " java web component developer – sun certification – completed \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2005\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    16 years\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " sql experience (oracle) excellent knowledge of linux/windows operating systems            more recently with my master’s studies i have learned to program in python and r   statistical program.  \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    career history\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">WORK_AND_EMPLOYMENT</span>\n",
       "</mark>\n",
       "  reesby  at reesby i have worked on \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " projects. the \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    first\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
       "</mark>\n",
       " was an emotional recognition system that  would split up and interview into the speakers and then perform emotional recognition  based on the separated audio and video of that interview. the current project involves extracting information from a persons resume and tehn using  that information to match with potential \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    employment\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">WORK_AND_EMPLOYMENT</span>\n",
       "</mark>\n",
       " opportunities. both projects have been developed using the python programming language.  may 2021-present  bureau of meteorology  operational weather forecaster for nsw 1995-2000. \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    antarctic weather\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " forecaster - casey station.          \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    summer 1997 – 1998\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       "                   \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    january 1994 –\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    december 2020\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       "  \f",
       "senior forecaster - \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    sydney airport meteorological\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">FAC</span>\n",
       "</mark>\n",
       " unit    \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2000-2020\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       "     in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    my day\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " to day operations, i must provide:  o accurate and timely weather forecasts for \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    sydney airport\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">FAC</span>\n",
       "</mark>\n",
       " working on \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    12-hour\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">TIME</span>\n",
       "</mark>\n",
       "  o make decisive and urgent decision-making action, as a result of developing   o talking to customers including: airlines, air traffic controllers, parachutist’s,   and sky writers, to provide information  o support and maintenance of all computer systems and navigating database   shifts.  weather events.  issues.   o \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    training\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">EDUCATION_AND_TRAINING</span>\n",
       "</mark>\n",
       " new staff.      i have developed numerous web-based applications to streamline the forecasting  process. using the \n",
       "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    apache\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
       "</mark>\n",
       " tomcat webserver as a front end for displaying web pages and providing the ux for presenting results. with back end java classes performing  oracle database manipulations such as querying, storing, and retrieving data.  systems developed include the \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    jsp\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " pages, servlets and java classes used to run these  in model-view-controller (\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    mvc\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ") architecture – i am the person with sole  responsibility for this system having developed all layers.      other applications created store important forecast/warnings in self-developed  databases, then verify these forecasts against later observations as they occur.   other web applications developed include display \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    programs\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">EDUCATION_AND_TRAINING</span>\n",
       "</mark>\n",
       " that take both current   and past data and display in meaningful graphical visualisations.    more specifically using historical data from the observations database to develop  and refine a fog forecasting methodology for \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    sydney airport\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">FAC</span>\n",
       "</mark>\n",
       ". this methodology  compares observed values with climatological data and determines if thresholds  have been exceeded and fog is a possibility. data from all fog events back to \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    1977\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " at  \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    sydney airport\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">FAC</span>\n",
       "</mark>\n",
       " were extracted manually using sql, data manipulation and  visualisation techniques.    use case – \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    early morning\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">TIME</span>\n",
       "</mark>\n",
       " fog was rolling across the airport and the airlines wanted a definitive and direct answer as to when the fog would clear? they would have to  divert their \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    early morning\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">TIME</span>\n",
       "</mark>\n",
       " 6.00am arrivals, if i have not been able to tell then that it  would disperse by 6.20am. it did as i forecast to them. this decision alone saved the  airlines over $1.0m that \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    morning\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">TIME</span>\n",
       "</mark>\n",
       ".   strong accountability and ability to work under pressure.     \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    community\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
       "</mark>\n",
       " organisations level \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    3\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " football \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    referee\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
       "</mark>\n",
       " - kuringai district \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    referee\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
       "</mark>\n",
       " association player/manager - west pymble football club teams  player - gordon golf club            2012-present          2007-present          2007-present  professional references  \f",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "displacy.render(nlp_res(doc.text), style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb512293",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type distilbert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at manishiitg/distilbert-resume-parts-classify were not used when initializing BertForTokenClassification: ['distilbert.transformer.layer.0.attention.out_lin.bias', 'distilbert.transformer.layer.3.ffn.lin2.weight', 'distilbert.transformer.layer.0.attention.k_lin.weight', 'distilbert.transformer.layer.3.attention.k_lin.bias', 'distilbert.transformer.layer.1.attention.out_lin.weight', 'distilbert.transformer.layer.2.attention.v_lin.weight', 'distilbert.transformer.layer.5.attention.v_lin.bias', 'distilbert.embeddings.LayerNorm.weight', 'distilbert.transformer.layer.0.ffn.lin2.weight', 'distilbert.transformer.layer.4.attention.k_lin.weight', 'distilbert.transformer.layer.0.output_layer_norm.weight', 'distilbert.transformer.layer.4.attention.k_lin.bias', 'distilbert.transformer.layer.5.attention.q_lin.weight', 'distilbert.transformer.layer.5.output_layer_norm.weight', 'distilbert.transformer.layer.4.ffn.lin1.weight', 'distilbert.transformer.layer.2.attention.out_lin.bias', 'distilbert.transformer.layer.0.sa_layer_norm.weight', 'distilbert.transformer.layer.3.output_layer_norm.bias', 'distilbert.transformer.layer.1.sa_layer_norm.bias', 'distilbert.transformer.layer.3.ffn.lin1.bias', 'distilbert.transformer.layer.0.attention.q_lin.bias', 'distilbert.transformer.layer.1.output_layer_norm.weight', 'distilbert.transformer.layer.0.ffn.lin1.bias', 'distilbert.transformer.layer.4.output_layer_norm.bias', 'distilbert.transformer.layer.2.output_layer_norm.weight', 'distilbert.transformer.layer.2.ffn.lin1.bias', 'distilbert.transformer.layer.1.attention.q_lin.bias', 'distilbert.transformer.layer.0.attention.q_lin.weight', 'distilbert.transformer.layer.5.ffn.lin1.weight', 'distilbert.transformer.layer.5.attention.out_lin.weight', 'distilbert.embeddings.word_embeddings.weight', 'distilbert.transformer.layer.4.attention.out_lin.bias', 'distilbert.transformer.layer.1.attention.out_lin.bias', 'distilbert.transformer.layer.3.attention.v_lin.bias', 'distilbert.transformer.layer.0.attention.v_lin.weight', 'distilbert.transformer.layer.3.output_layer_norm.weight', 'distilbert.transformer.layer.5.ffn.lin2.bias', 'distilbert.transformer.layer.1.ffn.lin1.bias', 'distilbert.transformer.layer.3.ffn.lin1.weight', 'distilbert.transformer.layer.3.ffn.lin2.bias', 'distilbert.transformer.layer.1.attention.q_lin.weight', 'distilbert.transformer.layer.1.ffn.lin2.weight', 'distilbert.transformer.layer.2.attention.q_lin.weight', 'pre_classifier.weight', 'distilbert.transformer.layer.3.attention.out_lin.bias', 'distilbert.transformer.layer.0.attention.out_lin.weight', 'distilbert.embeddings.LayerNorm.bias', 'distilbert.transformer.layer.2.ffn.lin2.bias', 'distilbert.transformer.layer.4.attention.q_lin.weight', 'distilbert.transformer.layer.2.attention.k_lin.bias', 'distilbert.transformer.layer.0.output_layer_norm.bias', 'distilbert.transformer.layer.0.sa_layer_norm.bias', 'distilbert.transformer.layer.4.sa_layer_norm.weight', 'distilbert.transformer.layer.5.output_layer_norm.bias', 'distilbert.transformer.layer.4.attention.v_lin.bias', 'distilbert.transformer.layer.1.attention.v_lin.weight', 'distilbert.transformer.layer.5.sa_layer_norm.weight', 'distilbert.transformer.layer.4.attention.q_lin.bias', 'distilbert.transformer.layer.2.attention.k_lin.weight', 'distilbert.transformer.layer.4.ffn.lin1.bias', 'distilbert.transformer.layer.2.attention.q_lin.bias', 'distilbert.transformer.layer.0.attention.v_lin.bias', 'distilbert.transformer.layer.2.output_layer_norm.bias', 'distilbert.transformer.layer.1.attention.v_lin.bias', 'distilbert.transformer.layer.0.ffn.lin2.bias', 'distilbert.transformer.layer.5.ffn.lin2.weight', 'distilbert.transformer.layer.3.attention.q_lin.bias', 'distilbert.transformer.layer.1.ffn.lin2.bias', 'distilbert.transformer.layer.3.sa_layer_norm.bias', 'distilbert.transformer.layer.5.attention.out_lin.bias', 'distilbert.transformer.layer.5.attention.k_lin.bias', 'distilbert.transformer.layer.0.ffn.lin1.weight', 'distilbert.transformer.layer.3.attention.v_lin.weight', 'distilbert.transformer.layer.5.ffn.lin1.bias', 'distilbert.transformer.layer.3.attention.out_lin.weight', 'distilbert.transformer.layer.1.sa_layer_norm.weight', 'distilbert.transformer.layer.4.ffn.lin2.weight', 'distilbert.transformer.layer.4.attention.out_lin.weight', 'distilbert.transformer.layer.2.ffn.lin2.weight', 'distilbert.transformer.layer.5.attention.k_lin.weight', 'distilbert.transformer.layer.3.attention.q_lin.weight', 'distilbert.transformer.layer.5.attention.q_lin.bias', 'distilbert.transformer.layer.2.attention.v_lin.bias', 'distilbert.transformer.layer.2.sa_layer_norm.bias', 'distilbert.embeddings.position_embeddings.weight', 'distilbert.transformer.layer.1.attention.k_lin.bias', 'distilbert.transformer.layer.5.sa_layer_norm.bias', 'distilbert.transformer.layer.4.sa_layer_norm.bias', 'distilbert.transformer.layer.2.sa_layer_norm.weight', 'distilbert.transformer.layer.1.ffn.lin1.weight', 'distilbert.transformer.layer.2.attention.out_lin.weight', 'distilbert.transformer.layer.4.output_layer_norm.weight', 'distilbert.transformer.layer.4.attention.v_lin.weight', 'pre_classifier.bias', 'distilbert.transformer.layer.3.attention.k_lin.weight', 'distilbert.transformer.layer.0.attention.k_lin.bias', 'distilbert.transformer.layer.1.output_layer_norm.bias', 'distilbert.transformer.layer.1.attention.k_lin.weight', 'distilbert.transformer.layer.5.attention.v_lin.weight', 'distilbert.transformer.layer.2.ffn.lin1.weight', 'distilbert.transformer.layer.4.ffn.lin2.bias', 'distilbert.transformer.layer.3.sa_layer_norm.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at manishiitg/distilbert-resume-parts-classify and are newly initialized: ['encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.4.attention.self.query.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.10.output.dense.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForTokenClassification,pipeline\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "#import logging\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#model_name = 'manishiitg/distilbert-resume-parts-classify'\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "#tokenizer = BertTokenizer.from_pretrained(model)\n",
    "\n",
    "model_name_or_path = 'manishiitg/distilbert-resume-parts-classify'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name_or_path)\n",
    "model = BertForTokenClassification.from_pretrained(model_name_or_path)  # Pytorch\n",
    "# model = TFAutoModelForTokenClassification.from_pretrained(model_name_or_path)  # Tensorflow\n",
    "\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "ner_results = nlp(peter_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8763b83d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL_7 date\n",
      "LABEL_7 :\n",
      "LABEL_0 20th\n",
      "LABEL_7 june\n",
      "LABEL_6 2020\n",
      "LABEL_5 name\n",
      "LABEL_10 :\n",
      "LABEL_7 peter\n",
      "LABEL_6 z\n",
      "LABEL_9 ##imo\n",
      "LABEL_7 ##nov\n",
      "LABEL_7 ##ic\n",
      "LABEL_6 email\n",
      "LABEL_1 :\n",
      "LABEL_10 stormy\n",
      "LABEL_0 _\n",
      "LABEL_7 pete\n",
      "LABEL_0 _\n",
      "LABEL_5 1\n",
      "LABEL_0 @\n",
      "LABEL_1 yahoo\n",
      "LABEL_5 .\n",
      "LABEL_0 com\n",
      "LABEL_4 phone\n",
      "LABEL_7 :\n",
      "LABEL_1 +\n",
      "LABEL_10 61\n",
      "LABEL_7 404\n",
      "LABEL_7 123\n",
      "LABEL_7 333\n",
      "LABEL_7 personal\n",
      "LABEL_7 statement\n",
      "LABEL_7 i\n",
      "LABEL_0 was\n",
      "LABEL_7 employed\n",
      "LABEL_0 at\n",
      "LABEL_1 the\n",
      "LABEL_6 bureau\n",
      "LABEL_1 of\n",
      "LABEL_1 meteor\n",
      "LABEL_4 ##ology\n",
      "LABEL_7 (\n",
      "LABEL_0 bo\n",
      "LABEL_5 ##m\n",
      "LABEL_6 )\n",
      "LABEL_7 for\n",
      "LABEL_7 27\n",
      "LABEL_0 years\n",
      "LABEL_4 as\n",
      "LABEL_9 an\n",
      "LABEL_7 operational\n",
      "LABEL_1 meteor\n",
      "LABEL_0 ##ologist\n",
      "LABEL_4 and\n",
      "LABEL_1 was\n",
      "LABEL_0 made\n",
      "LABEL_6 redundant\n",
      "LABEL_6 in\n",
      "LABEL_7 december\n",
      "LABEL_6 2020\n",
      "LABEL_2 .\n",
      "LABEL_6 i\n",
      "LABEL_9 am\n",
      "LABEL_7 currently\n",
      "LABEL_7 completing\n",
      "LABEL_4 a\n",
      "LABEL_0 masters\n",
      "LABEL_6 in\n",
      "LABEL_10 data\n",
      "LABEL_0 science\n",
      "LABEL_1 (\n",
      "LABEL_7 expected\n",
      "LABEL_10 completion\n",
      "LABEL_4 august\n",
      "LABEL_6 2021\n",
      "LABEL_7 )\n",
      "LABEL_0 .\n",
      "LABEL_7 i\n",
      "LABEL_0 am\n",
      "LABEL_7 currently\n",
      "LABEL_0 doing\n",
      "LABEL_4 a\n",
      "LABEL_5 data\n",
      "LABEL_7 science\n",
      "LABEL_1 internship\n",
      "LABEL_0 at\n",
      "LABEL_5 re\n",
      "LABEL_5 ##eb\n",
      "LABEL_1 ##y\n",
      "LABEL_4 .\n",
      "LABEL_1 in\n",
      "LABEL_6 my\n",
      "LABEL_1 previous\n",
      "LABEL_9 role\n",
      "LABEL_7 i\n",
      "LABEL_7 provided\n",
      "LABEL_6 direct\n",
      "LABEL_10 advice\n",
      "LABEL_4 to\n",
      "LABEL_4 air\n",
      "LABEL_10 traffic\n",
      "LABEL_6 controllers\n",
      "LABEL_1 and\n",
      "LABEL_0 airlines\n",
      "LABEL_0 on\n",
      "LABEL_8 the\n",
      "LABEL_9 current\n",
      "LABEL_7 and\n",
      "LABEL_7 expected\n",
      "LABEL_3 weather\n",
      "LABEL_0 at\n",
      "LABEL_4 sydney\n",
      "LABEL_10 airport\n",
      "LABEL_7 .\n",
      "LABEL_7 i\n",
      "LABEL_1 have\n",
      "LABEL_4 extensive\n",
      "LABEL_7 knowledge\n",
      "LABEL_9 of\n",
      "LABEL_7 aviation\n",
      "LABEL_1 meteor\n",
      "LABEL_2 ##ology\n",
      "LABEL_7 and\n",
      "LABEL_7 how\n",
      "LABEL_7 that\n",
      "LABEL_9 affects\n",
      "LABEL_3 airline\n",
      "LABEL_7 operations\n",
      "LABEL_2 .\n",
      "LABEL_1 i\n",
      "LABEL_4 also\n",
      "LABEL_1 used\n",
      "LABEL_6 my\n",
      "LABEL_1 extensive\n",
      "LABEL_7 computing\n",
      "LABEL_7 knowledge\n",
      "LABEL_7 to\n",
      "LABEL_5 develop\n",
      "LABEL_0 and\n",
      "LABEL_7 maintain\n",
      "LABEL_7 several\n",
      "LABEL_4 oracle\n",
      "LABEL_7 databases\n",
      "LABEL_7 tables\n",
      "LABEL_0 and\n",
      "LABEL_10 java\n",
      "LABEL_7 based\n",
      "LABEL_6 web\n",
      "LABEL_10 applications\n",
      "LABEL_9 .\n",
      "LABEL_9 my\n",
      "LABEL_0 education\n",
      "LABEL_10 history\n",
      "LABEL_0 demonstrates\n",
      "LABEL_9 the\n",
      "LABEL_0 drive\n",
      "LABEL_7 i\n",
      "LABEL_1 have\n",
      "LABEL_9 to\n",
      "LABEL_6 keep\n",
      "LABEL_4 my\n",
      "LABEL_10 skills\n",
      "LABEL_6 up\n",
      "LABEL_5 to\n",
      "LABEL_7 date\n",
      "LABEL_6 and\n",
      "LABEL_7 i\n",
      "LABEL_1 wish\n",
      "LABEL_9 to\n",
      "LABEL_7 continue\n",
      "LABEL_0 learning\n",
      "LABEL_7 and\n",
      "LABEL_5 challenging\n",
      "LABEL_10 myself\n",
      "LABEL_0 .\n",
      "LABEL_3 i\n",
      "LABEL_1 am\n",
      "LABEL_10 currently\n",
      "LABEL_10 current\n",
      "LABEL_7 completing\n",
      "LABEL_4 a\n",
      "LABEL_7 master\n",
      "LABEL_1 ’\n",
      "LABEL_7 s\n",
      "LABEL_7 degree\n",
      "LABEL_7 ,\n",
      "LABEL_0 see\n",
      "LABEL_1 below\n",
      "LABEL_4 .\n",
      "LABEL_7 my\n",
      "LABEL_7 current\n",
      "LABEL_7 studies\n",
      "LABEL_7 have\n",
      "LABEL_7 increased\n",
      "LABEL_6 my\n",
      "LABEL_0 desire\n",
      "LABEL_4 to\n",
      "LABEL_7 move\n",
      "LABEL_6 into\n",
      "LABEL_1 a\n",
      "LABEL_0 machine\n",
      "LABEL_4 learning\n",
      "LABEL_3 /\n",
      "LABEL_9 ai\n",
      "LABEL_10 field\n",
      "LABEL_0 ,\n",
      "LABEL_6 as\n",
      "LABEL_7 well\n",
      "LABEL_7 as\n",
      "LABEL_0 working\n",
      "LABEL_0 with\n",
      "LABEL_1 large\n",
      "LABEL_6 amounts\n",
      "LABEL_7 of\n",
      "LABEL_5 computer\n",
      "LABEL_7 -\n",
      "LABEL_10 based\n",
      "LABEL_5 data\n",
      "LABEL_7 and\n",
      "LABEL_7 modelling\n",
      "LABEL_0 information\n",
      "LABEL_9 .\n",
      "LABEL_5 bsc\n",
      "LABEL_4 (\n",
      "LABEL_7 hon\n",
      "LABEL_6 ##s\n",
      "LABEL_0 )\n",
      "LABEL_9 atmospheric\n",
      "LABEL_9 science\n",
      "LABEL_7 macquarie\n",
      "LABEL_6 university\n",
      "LABEL_7 ,\n",
      "LABEL_1 completed\n",
      "LABEL_4 1993\n",
      "LABEL_0 education\n",
      "LABEL_0 hs\n",
      "LABEL_7 ##c\n",
      "LABEL_0 barker\n",
      "LABEL_4 college\n",
      "LABEL_1 ,\n",
      "LABEL_6 horns\n",
      "LABEL_1 ##by\n",
      "LABEL_0 ,\n",
      "LABEL_1 completed\n",
      "LABEL_0 1989\n",
      "LABEL_0 dip\n",
      "LABEL_5 met\n",
      "LABEL_5 .\n",
      "LABEL_1 bureau\n",
      "LABEL_0 of\n",
      "LABEL_1 meteor\n",
      "LABEL_5 ##ology\n",
      "LABEL_6 training\n",
      "LABEL_5 centre\n",
      "LABEL_0 ,\n",
      "LABEL_1 completed\n",
      "LABEL_1 1994\n",
      "LABEL_7 gr\n",
      "LABEL_8 ##ad\n",
      "LABEL_4 dip\n",
      "LABEL_1 computing\n",
      "LABEL_7 mona\n",
      "LABEL_1 ##sh\n",
      "LABEL_6 university\n",
      "LABEL_7 ,\n",
      "LABEL_1 completed\n",
      "LABEL_0 2003\n",
      "LABEL_4 master\n",
      "LABEL_7 of\n",
      "LABEL_5 data\n",
      "LABEL_6 science\n",
      "LABEL_0 -\n",
      "LABEL_1 james\n",
      "LABEL_4 cook\n",
      "LABEL_6 university\n",
      "LABEL_0 –\n",
      "LABEL_1 expected\n",
      "LABEL_6 august\n",
      "LABEL_5 2021\n",
      "LABEL_0 .\n",
      "LABEL_4 computing\n",
      "LABEL_6 skills\n",
      "LABEL_1 ,\n",
      "LABEL_7 experience\n",
      "LABEL_1 and\n",
      "LABEL_1 abilities\n",
      "LABEL_1 java\n",
      "LABEL_1 programmer\n",
      "LABEL_7 -\n",
      "LABEL_4 sun\n",
      "LABEL_4 certification\n",
      "LABEL_10 –\n",
      "LABEL_1 completed\n",
      "LABEL_7 2005\n",
      "LABEL_10 java\n",
      "LABEL_6 web\n",
      "LABEL_6 component\n",
      "LABEL_1 developer\n",
      "LABEL_2 –\n",
      "LABEL_7 sun\n",
      "LABEL_7 certification\n",
      "LABEL_0 –\n",
      "LABEL_1 completed\n",
      "LABEL_7 2005\n",
      "LABEL_1 16\n",
      "LABEL_0 years\n",
      "LABEL_0 sql\n",
      "LABEL_5 experience\n",
      "LABEL_1 (\n",
      "LABEL_7 oracle\n",
      "LABEL_0 )\n",
      "LABEL_4 excellent\n",
      "LABEL_7 knowledge\n",
      "LABEL_0 of\n",
      "LABEL_7 linux\n",
      "LABEL_1 /\n",
      "LABEL_9 windows\n",
      "LABEL_4 operating\n",
      "LABEL_6 systems\n",
      "LABEL_5 more\n",
      "LABEL_7 recently\n",
      "LABEL_0 with\n",
      "LABEL_6 my\n",
      "LABEL_6 master\n",
      "LABEL_7 ’\n",
      "LABEL_0 s\n",
      "LABEL_6 studies\n",
      "LABEL_7 i\n",
      "LABEL_10 have\n",
      "LABEL_1 learned\n",
      "LABEL_4 to\n",
      "LABEL_1 program\n",
      "LABEL_7 in\n",
      "LABEL_6 python\n",
      "LABEL_6 and\n",
      "LABEL_7 r\n",
      "LABEL_10 statistical\n",
      "LABEL_6 program\n",
      "LABEL_0 .\n",
      "LABEL_0 career\n",
      "LABEL_5 history\n",
      "LABEL_4 rees\n",
      "LABEL_7 ##by\n",
      "LABEL_0 at\n",
      "LABEL_0 rees\n",
      "LABEL_7 ##by\n",
      "LABEL_7 i\n",
      "LABEL_0 have\n",
      "LABEL_9 worked\n",
      "LABEL_4 on\n",
      "LABEL_1 2\n",
      "LABEL_6 projects\n",
      "LABEL_5 .\n",
      "LABEL_9 the\n",
      "LABEL_0 first\n",
      "LABEL_1 was\n",
      "LABEL_9 an\n",
      "LABEL_5 emotional\n",
      "LABEL_0 recognition\n",
      "LABEL_0 system\n",
      "LABEL_1 that\n",
      "LABEL_0 would\n",
      "LABEL_7 split\n",
      "LABEL_6 up\n",
      "LABEL_1 and\n",
      "LABEL_4 interview\n",
      "LABEL_7 into\n",
      "LABEL_9 the\n",
      "LABEL_10 speakers\n",
      "LABEL_7 and\n",
      "LABEL_6 then\n",
      "LABEL_7 perform\n",
      "LABEL_7 emotional\n",
      "LABEL_0 recognition\n",
      "LABEL_4 based\n",
      "LABEL_4 on\n",
      "LABEL_1 the\n",
      "LABEL_6 separated\n",
      "LABEL_5 audio\n",
      "LABEL_0 and\n",
      "LABEL_11 video\n",
      "LABEL_0 of\n",
      "LABEL_1 that\n",
      "LABEL_6 interview\n",
      "LABEL_4 .\n",
      "LABEL_1 the\n",
      "LABEL_1 current\n",
      "LABEL_6 project\n",
      "LABEL_7 involves\n",
      "LABEL_0 extract\n",
      "LABEL_7 ##ing\n",
      "LABEL_7 information\n",
      "LABEL_0 from\n",
      "LABEL_6 a\n",
      "LABEL_10 persons\n",
      "LABEL_3 resume\n",
      "LABEL_6 and\n",
      "LABEL_7 te\n",
      "LABEL_4 ##hn\n",
      "LABEL_1 using\n",
      "LABEL_4 that\n",
      "LABEL_7 information\n",
      "LABEL_7 to\n",
      "LABEL_3 match\n",
      "LABEL_0 with\n",
      "LABEL_0 potential\n",
      "LABEL_4 employment\n",
      "LABEL_10 opportunities\n",
      "LABEL_6 .\n",
      "LABEL_7 both\n",
      "LABEL_1 projects\n",
      "LABEL_1 have\n",
      "LABEL_7 been\n",
      "LABEL_7 developed\n",
      "LABEL_1 using\n",
      "LABEL_1 the\n",
      "LABEL_7 python\n",
      "LABEL_4 programming\n",
      "LABEL_1 language\n",
      "LABEL_4 .\n",
      "LABEL_1 may\n",
      "LABEL_0 2021\n",
      "LABEL_7 -\n",
      "LABEL_7 present\n",
      "LABEL_6 bureau\n",
      "LABEL_0 of\n",
      "LABEL_1 meteor\n",
      "LABEL_1 ##ology\n",
      "LABEL_1 operational\n",
      "LABEL_7 weather\n",
      "LABEL_1 forecast\n",
      "LABEL_10 ##er\n",
      "LABEL_4 for\n",
      "LABEL_6 nsw\n",
      "LABEL_6 1995\n",
      "LABEL_0 -\n",
      "LABEL_7 2000\n",
      "LABEL_4 .\n",
      "LABEL_1 antarctic\n",
      "LABEL_9 weather\n",
      "LABEL_6 forecast\n",
      "LABEL_9 ##er\n",
      "LABEL_0 -\n",
      "LABEL_6 casey\n",
      "LABEL_7 station\n",
      "LABEL_0 .\n",
      "LABEL_4 summer\n",
      "LABEL_0 1997\n",
      "LABEL_0 –\n",
      "LABEL_7 1998\n",
      "LABEL_1 january\n",
      "LABEL_1 1994\n",
      "LABEL_10 –\n",
      "LABEL_7 december\n",
      "LABEL_1 2020\n",
      "LABEL_10 senior\n",
      "LABEL_6 forecast\n",
      "LABEL_9 ##er\n",
      "LABEL_10 -\n",
      "LABEL_4 sydney\n",
      "LABEL_7 airport\n",
      "LABEL_7 meteorological\n",
      "LABEL_4 unit\n",
      "LABEL_7 2000\n",
      "LABEL_7 -\n",
      "LABEL_1 2020\n",
      "LABEL_0 in\n",
      "LABEL_6 my\n",
      "LABEL_7 day\n",
      "LABEL_4 to\n",
      "LABEL_4 day\n",
      "LABEL_10 operations\n",
      "LABEL_0 ,\n",
      "LABEL_6 i\n",
      "LABEL_7 must\n",
      "LABEL_7 provide\n",
      "LABEL_7 :\n",
      "LABEL_5 o\n",
      "LABEL_7 accurate\n",
      "LABEL_6 and\n",
      "LABEL_6 timely\n",
      "LABEL_9 weather\n",
      "LABEL_7 forecast\n",
      "LABEL_7 ##s\n",
      "LABEL_4 for\n",
      "LABEL_6 sydney\n",
      "LABEL_7 airport\n",
      "LABEL_0 working\n",
      "LABEL_9 on\n",
      "LABEL_1 12\n",
      "LABEL_0 -\n",
      "LABEL_4 hour\n",
      "LABEL_5 o\n",
      "LABEL_10 make\n",
      "LABEL_1 decisive\n",
      "LABEL_5 and\n",
      "LABEL_0 urgent\n",
      "LABEL_9 decision\n",
      "LABEL_0 -\n",
      "LABEL_4 making\n",
      "LABEL_10 action\n",
      "LABEL_1 ,\n",
      "LABEL_0 as\n",
      "LABEL_7 a\n",
      "LABEL_0 result\n",
      "LABEL_1 of\n",
      "LABEL_7 developing\n",
      "LABEL_6 o\n",
      "LABEL_7 talking\n",
      "LABEL_9 to\n"
     ]
    }
   ],
   "source": [
    "#print(ner_results)\n",
    "for ent in ner_results:\n",
    "    print(ent[\"entity\"],ent[\"word\"])#.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "523737ae",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at manishiitg/distilbert-resume-parts-classify were not used when initializing DistilBertForTokenClassification: ['pre_classifier.bias', 'pre_classifier.weight']\n",
      "- This IS expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForTokenClassification  # for pytorch\n",
    "#from transformers import TFAutoModelForTokenClassification  # for tensorflow\n",
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "model_name_or_path = 'manishiitg/distilbert-resume-parts-classify'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name_or_path)  # Pytorch\n",
    "\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "ner_results = nlp(peter_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "73b59a2b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL_7 date\n",
      "LABEL_7 :\n",
      "LABEL_7 20th\n",
      "LABEL_7 june\n",
      "LABEL_7 2020\n",
      "LABEL_7 name\n",
      "LABEL_7 :\n",
      "LABEL_3 peter\n",
      "LABEL_3 z\n",
      "LABEL_8 ##imo\n",
      "LABEL_3 ##nov\n",
      "LABEL_3 ##ic\n",
      "LABEL_11 email\n",
      "LABEL_7 :\n",
      "LABEL_7 stormy\n",
      "LABEL_7 _\n",
      "LABEL_7 pete\n",
      "LABEL_7 _\n",
      "LABEL_3 1\n",
      "LABEL_8 @\n",
      "LABEL_8 yahoo\n",
      "LABEL_8 .\n",
      "LABEL_8 com\n",
      "LABEL_7 phone\n",
      "LABEL_7 :\n",
      "LABEL_7 +\n",
      "LABEL_7 61\n",
      "LABEL_7 404\n",
      "LABEL_7 123\n",
      "LABEL_3 333\n",
      "LABEL_7 personal\n",
      "LABEL_11 statement\n",
      "LABEL_11 i\n",
      "LABEL_3 was\n",
      "LABEL_3 employed\n",
      "LABEL_3 at\n",
      "LABEL_3 the\n",
      "LABEL_7 bureau\n",
      "LABEL_7 of\n",
      "LABEL_7 meteor\n",
      "LABEL_7 ##ology\n",
      "LABEL_3 (\n",
      "LABEL_7 bo\n",
      "LABEL_7 ##m\n",
      "LABEL_11 )\n",
      "LABEL_3 for\n",
      "LABEL_3 27\n",
      "LABEL_7 years\n",
      "LABEL_7 as\n",
      "LABEL_7 an\n",
      "LABEL_3 operational\n",
      "LABEL_7 meteor\n",
      "LABEL_7 ##ologist\n",
      "LABEL_3 and\n",
      "LABEL_3 was\n",
      "LABEL_3 made\n",
      "LABEL_3 redundant\n",
      "LABEL_7 in\n",
      "LABEL_3 december\n",
      "LABEL_3 2020\n",
      "LABEL_7 .\n",
      "LABEL_11 i\n",
      "LABEL_11 am\n",
      "LABEL_7 currently\n",
      "LABEL_3 completing\n",
      "LABEL_3 a\n",
      "LABEL_7 masters\n",
      "LABEL_7 in\n",
      "LABEL_7 data\n",
      "LABEL_7 science\n",
      "LABEL_3 (\n",
      "LABEL_3 expected\n",
      "LABEL_3 completion\n",
      "LABEL_7 august\n",
      "LABEL_3 2021\n",
      "LABEL_7 )\n",
      "LABEL_7 .\n",
      "LABEL_11 i\n",
      "LABEL_11 am\n",
      "LABEL_11 currently\n",
      "LABEL_3 doing\n",
      "LABEL_3 a\n",
      "LABEL_7 data\n",
      "LABEL_7 science\n",
      "LABEL_3 internship\n",
      "LABEL_3 at\n",
      "LABEL_7 re\n",
      "LABEL_11 ##eb\n",
      "LABEL_7 ##y\n",
      "LABEL_3 .\n",
      "LABEL_3 in\n",
      "LABEL_3 my\n",
      "LABEL_3 previous\n",
      "LABEL_3 role\n",
      "LABEL_7 i\n",
      "LABEL_11 provided\n",
      "LABEL_3 direct\n",
      "LABEL_3 advice\n",
      "LABEL_3 to\n",
      "LABEL_4 air\n",
      "LABEL_4 traffic\n",
      "LABEL_9 controllers\n",
      "LABEL_3 and\n",
      "LABEL_8 airlines\n",
      "LABEL_5 on\n",
      "LABEL_3 the\n",
      "LABEL_7 current\n",
      "LABEL_10 and\n",
      "LABEL_11 expected\n",
      "LABEL_3 weather\n",
      "LABEL_3 at\n",
      "LABEL_3 sydney\n",
      "LABEL_8 airport\n",
      "LABEL_3 .\n",
      "LABEL_11 i\n",
      "LABEL_11 have\n",
      "LABEL_11 extensive\n",
      "LABEL_11 knowledge\n",
      "LABEL_11 of\n",
      "LABEL_3 aviation\n",
      "LABEL_7 meteor\n",
      "LABEL_7 ##ology\n",
      "LABEL_11 and\n",
      "LABEL_11 how\n",
      "LABEL_11 that\n",
      "LABEL_3 affects\n",
      "LABEL_4 airline\n",
      "LABEL_3 operations\n",
      "LABEL_3 .\n",
      "LABEL_3 i\n",
      "LABEL_3 also\n",
      "LABEL_3 used\n",
      "LABEL_3 my\n",
      "LABEL_9 extensive\n",
      "LABEL_3 computing\n",
      "LABEL_7 knowledge\n",
      "LABEL_9 to\n",
      "LABEL_11 develop\n",
      "LABEL_3 and\n",
      "LABEL_11 maintain\n",
      "LABEL_3 several\n",
      "LABEL_11 oracle\n",
      "LABEL_11 databases\n",
      "LABEL_11 tables\n",
      "LABEL_3 and\n",
      "LABEL_11 java\n",
      "LABEL_11 based\n",
      "LABEL_7 web\n",
      "LABEL_11 applications\n",
      "LABEL_3 .\n",
      "LABEL_9 my\n",
      "LABEL_3 education\n",
      "LABEL_3 history\n",
      "LABEL_3 demonstrates\n",
      "LABEL_3 the\n",
      "LABEL_3 drive\n",
      "LABEL_3 i\n",
      "LABEL_3 have\n",
      "LABEL_3 to\n",
      "LABEL_3 keep\n",
      "LABEL_3 my\n",
      "LABEL_3 skills\n",
      "LABEL_3 up\n",
      "LABEL_3 to\n",
      "LABEL_3 date\n",
      "LABEL_3 and\n",
      "LABEL_11 i\n",
      "LABEL_3 wish\n",
      "LABEL_3 to\n",
      "LABEL_3 continue\n",
      "LABEL_3 learning\n",
      "LABEL_3 and\n",
      "LABEL_3 challenging\n",
      "LABEL_3 myself\n",
      "LABEL_11 .\n",
      "LABEL_11 i\n",
      "LABEL_3 am\n",
      "LABEL_3 currently\n",
      "LABEL_3 current\n",
      "LABEL_3 completing\n",
      "LABEL_3 a\n",
      "LABEL_3 master\n",
      "LABEL_3 ’\n",
      "LABEL_3 s\n",
      "LABEL_3 degree\n",
      "LABEL_3 ,\n",
      "LABEL_3 see\n",
      "LABEL_3 below\n",
      "LABEL_3 .\n",
      "LABEL_11 my\n",
      "LABEL_3 current\n",
      "LABEL_3 studies\n",
      "LABEL_3 have\n",
      "LABEL_3 increased\n",
      "LABEL_11 my\n",
      "LABEL_3 desire\n",
      "LABEL_3 to\n",
      "LABEL_1 move\n",
      "LABEL_1 into\n",
      "LABEL_3 a\n",
      "LABEL_3 machine\n",
      "LABEL_11 learning\n",
      "LABEL_11 /\n",
      "LABEL_11 ai\n",
      "LABEL_3 field\n",
      "LABEL_3 ,\n",
      "LABEL_11 as\n",
      "LABEL_3 well\n",
      "LABEL_3 as\n",
      "LABEL_11 working\n",
      "LABEL_11 with\n",
      "LABEL_3 large\n",
      "LABEL_11 amounts\n",
      "LABEL_11 of\n",
      "LABEL_7 computer\n",
      "LABEL_11 -\n",
      "LABEL_11 based\n",
      "LABEL_7 data\n",
      "LABEL_11 and\n",
      "LABEL_11 modelling\n",
      "LABEL_11 information\n",
      "LABEL_7 .\n",
      "LABEL_7 bsc\n",
      "LABEL_7 (\n",
      "LABEL_7 hon\n",
      "LABEL_7 ##s\n",
      "LABEL_7 )\n",
      "LABEL_7 atmospheric\n",
      "LABEL_3 science\n",
      "LABEL_3 macquarie\n",
      "LABEL_7 university\n",
      "LABEL_7 ,\n",
      "LABEL_7 completed\n",
      "LABEL_3 1993\n",
      "LABEL_3 education\n",
      "LABEL_7 hs\n",
      "LABEL_7 ##c\n",
      "LABEL_3 barker\n",
      "LABEL_7 college\n",
      "LABEL_7 ,\n",
      "LABEL_7 horns\n",
      "LABEL_3 ##by\n",
      "LABEL_7 ,\n",
      "LABEL_7 completed\n",
      "LABEL_3 1989\n",
      "LABEL_7 dip\n",
      "LABEL_7 met\n",
      "LABEL_7 .\n",
      "LABEL_7 bureau\n",
      "LABEL_7 of\n",
      "LABEL_7 meteor\n",
      "LABEL_7 ##ology\n",
      "LABEL_3 training\n",
      "LABEL_3 centre\n",
      "LABEL_7 ,\n",
      "LABEL_7 completed\n",
      "LABEL_7 1994\n",
      "LABEL_7 gr\n",
      "LABEL_7 ##ad\n",
      "LABEL_7 dip\n",
      "LABEL_7 computing\n",
      "LABEL_3 mona\n",
      "LABEL_11 ##sh\n",
      "LABEL_7 university\n",
      "LABEL_7 ,\n",
      "LABEL_7 completed\n",
      "LABEL_7 2003\n",
      "LABEL_7 master\n",
      "LABEL_7 of\n",
      "LABEL_7 data\n",
      "LABEL_7 science\n",
      "LABEL_7 -\n",
      "LABEL_7 james\n",
      "LABEL_11 cook\n",
      "LABEL_7 university\n",
      "LABEL_7 –\n",
      "LABEL_7 expected\n",
      "LABEL_7 august\n",
      "LABEL_7 2021\n",
      "LABEL_7 .\n",
      "LABEL_7 computing\n",
      "LABEL_7 skills\n",
      "LABEL_7 ,\n",
      "LABEL_7 experience\n",
      "LABEL_11 and\n",
      "LABEL_11 abilities\n",
      "LABEL_7 java\n",
      "LABEL_3 programmer\n",
      "LABEL_7 -\n",
      "LABEL_7 sun\n",
      "LABEL_7 certification\n",
      "LABEL_3 –\n",
      "LABEL_7 completed\n",
      "LABEL_7 2005\n",
      "LABEL_3 java\n",
      "LABEL_11 web\n",
      "LABEL_11 component\n",
      "LABEL_3 developer\n",
      "LABEL_7 –\n",
      "LABEL_7 sun\n",
      "LABEL_7 certification\n",
      "LABEL_3 –\n",
      "LABEL_7 completed\n",
      "LABEL_3 2005\n",
      "LABEL_3 16\n",
      "LABEL_7 years\n",
      "LABEL_7 sql\n",
      "LABEL_7 experience\n",
      "LABEL_7 (\n",
      "LABEL_11 oracle\n",
      "LABEL_7 )\n",
      "LABEL_7 excellent\n",
      "LABEL_7 knowledge\n",
      "LABEL_11 of\n",
      "LABEL_11 linux\n",
      "LABEL_11 /\n",
      "LABEL_11 windows\n",
      "LABEL_11 operating\n",
      "LABEL_3 systems\n",
      "LABEL_3 more\n",
      "LABEL_3 recently\n",
      "LABEL_3 with\n",
      "LABEL_7 my\n",
      "LABEL_7 master\n",
      "LABEL_11 ’\n",
      "LABEL_7 s\n",
      "LABEL_3 studies\n",
      "LABEL_3 i\n",
      "LABEL_3 have\n",
      "LABEL_3 learned\n",
      "LABEL_7 to\n",
      "LABEL_3 program\n",
      "LABEL_7 in\n",
      "LABEL_11 python\n",
      "LABEL_11 and\n",
      "LABEL_11 r\n",
      "LABEL_7 statistical\n",
      "LABEL_3 program\n",
      "LABEL_3 .\n",
      "LABEL_7 career\n",
      "LABEL_3 history\n",
      "LABEL_3 rees\n",
      "LABEL_3 ##by\n",
      "LABEL_7 at\n",
      "LABEL_3 rees\n",
      "LABEL_3 ##by\n",
      "LABEL_11 i\n",
      "LABEL_3 have\n",
      "LABEL_7 worked\n",
      "LABEL_10 on\n",
      "LABEL_3 2\n",
      "LABEL_3 projects\n",
      "LABEL_3 .\n",
      "LABEL_11 the\n",
      "LABEL_3 first\n",
      "LABEL_3 was\n",
      "LABEL_3 an\n",
      "LABEL_11 emotional\n",
      "LABEL_7 recognition\n",
      "LABEL_3 system\n",
      "LABEL_3 that\n",
      "LABEL_3 would\n",
      "LABEL_7 split\n",
      "LABEL_10 up\n",
      "LABEL_11 and\n",
      "LABEL_10 interview\n",
      "LABEL_7 into\n",
      "LABEL_11 the\n",
      "LABEL_10 speakers\n",
      "LABEL_10 and\n",
      "LABEL_11 then\n",
      "LABEL_10 perform\n",
      "LABEL_4 emotional\n",
      "LABEL_8 recognition\n",
      "LABEL_7 based\n",
      "LABEL_10 on\n",
      "LABEL_3 the\n",
      "LABEL_10 separated\n",
      "LABEL_8 audio\n",
      "LABEL_10 and\n",
      "LABEL_7 video\n",
      "LABEL_7 of\n",
      "LABEL_3 that\n",
      "LABEL_8 interview\n",
      "LABEL_3 .\n",
      "LABEL_3 the\n",
      "LABEL_7 current\n",
      "LABEL_3 project\n",
      "LABEL_3 involves\n",
      "LABEL_7 extract\n",
      "LABEL_11 ##ing\n",
      "LABEL_7 information\n",
      "LABEL_7 from\n",
      "LABEL_0 a\n",
      "LABEL_3 persons\n",
      "LABEL_3 resume\n",
      "LABEL_3 and\n",
      "LABEL_11 te\n",
      "LABEL_7 ##hn\n",
      "LABEL_7 using\n",
      "LABEL_3 that\n",
      "LABEL_7 information\n",
      "LABEL_11 to\n",
      "LABEL_10 match\n",
      "LABEL_10 with\n",
      "LABEL_5 potential\n",
      "LABEL_4 employment\n",
      "LABEL_8 opportunities\n",
      "LABEL_11 .\n",
      "LABEL_3 both\n",
      "LABEL_3 projects\n",
      "LABEL_3 have\n",
      "LABEL_3 been\n",
      "LABEL_3 developed\n",
      "LABEL_3 using\n",
      "LABEL_3 the\n",
      "LABEL_3 python\n",
      "LABEL_3 programming\n",
      "LABEL_3 language\n",
      "LABEL_3 .\n",
      "LABEL_3 may\n",
      "LABEL_3 2021\n",
      "LABEL_7 -\n",
      "LABEL_11 present\n",
      "LABEL_11 bureau\n",
      "LABEL_11 of\n",
      "LABEL_7 meteor\n",
      "LABEL_11 ##ology\n",
      "LABEL_3 operational\n",
      "LABEL_3 weather\n",
      "LABEL_7 forecast\n",
      "LABEL_11 ##er\n",
      "LABEL_3 for\n",
      "LABEL_3 nsw\n",
      "LABEL_3 1995\n",
      "LABEL_7 -\n",
      "LABEL_3 2000\n",
      "LABEL_4 .\n",
      "LABEL_11 antarctic\n",
      "LABEL_3 weather\n",
      "LABEL_7 forecast\n",
      "LABEL_11 ##er\n",
      "LABEL_7 -\n",
      "LABEL_5 casey\n",
      "LABEL_3 station\n",
      "LABEL_3 .\n",
      "LABEL_7 summer\n",
      "LABEL_1 1997\n",
      "LABEL_3 –\n",
      "LABEL_11 1998\n",
      "LABEL_3 january\n",
      "LABEL_0 1994\n",
      "LABEL_3 –\n",
      "LABEL_3 december\n",
      "LABEL_3 2020\n",
      "LABEL_3 senior\n",
      "LABEL_7 forecast\n",
      "LABEL_11 ##er\n",
      "LABEL_3 -\n",
      "LABEL_3 sydney\n",
      "LABEL_3 airport\n",
      "LABEL_3 meteorological\n",
      "LABEL_3 unit\n",
      "LABEL_3 2000\n",
      "LABEL_3 -\n",
      "LABEL_3 2020\n",
      "LABEL_3 in\n",
      "LABEL_3 my\n",
      "LABEL_3 day\n",
      "LABEL_11 to\n",
      "LABEL_3 day\n",
      "LABEL_3 operations\n",
      "LABEL_3 ,\n",
      "LABEL_3 i\n",
      "LABEL_3 must\n",
      "LABEL_11 provide\n",
      "LABEL_3 :\n",
      "LABEL_11 o\n",
      "LABEL_11 accurate\n",
      "LABEL_11 and\n",
      "LABEL_11 timely\n",
      "LABEL_3 weather\n",
      "LABEL_7 forecast\n",
      "LABEL_3 ##s\n",
      "LABEL_3 for\n",
      "LABEL_3 sydney\n",
      "LABEL_3 airport\n",
      "LABEL_11 working\n",
      "LABEL_11 on\n",
      "LABEL_3 12\n",
      "LABEL_3 -\n",
      "LABEL_11 hour\n",
      "LABEL_3 o\n",
      "LABEL_11 make\n",
      "LABEL_11 decisive\n",
      "LABEL_3 and\n",
      "LABEL_11 urgent\n",
      "LABEL_11 decision\n",
      "LABEL_11 -\n",
      "LABEL_11 making\n",
      "LABEL_11 action\n",
      "LABEL_3 ,\n",
      "LABEL_10 as\n",
      "LABEL_3 a\n",
      "LABEL_3 result\n",
      "LABEL_3 of\n",
      "LABEL_3 developing\n",
      "LABEL_3 o\n",
      "LABEL_11 talking\n",
      "LABEL_11 to\n"
     ]
    }
   ],
   "source": [
    "#print(ner_results)\n",
    "for ent in ner_results:\n",
    "    print(ent[\"entity\"],ent[\"word\"])#.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e832a4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "[\"awards\", \"certifications\", \"education_\", \"exp_\", \"extra\", \"hobbies\", \"personal_\", \"projects_\", \"references\", \"skills\", \"summary\", \"training\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef03034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a3aaa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3565071c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "826dbfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForTokenClassification  # for pytorch\n",
    "from transformers import TFAutoModelForTokenClassification  # for tensorflow\n",
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "model_name_or_path = 'manishiitg/resume-ner'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name_or_path)  # Pytorch\n",
    "# model = TFAutoModelForTokenClassification.from_pretrained(model_name_or_path)  # Tensorflow\n",
    "\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "ner_results = nlp(peter_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f3877cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phone 123\n",
      "ORG bureau\n",
      "ORG of\n",
      "ORG ##ology\n",
      "ORG bo\n",
      "ORG ##m\n",
      "ExperianceYears 27\n",
      "ExperianceYears years\n",
      "Designation ##ologist\n",
      "DATE december\n",
      "DATE 2020\n",
      "EducationDegree masters\n",
      "DATE august\n",
      "DATE 2021\n",
      "EducationDegree master\n",
      "ExperianceYears 16\n",
      "ExperianceYears years\n",
      "DATE 2021\n"
     ]
    }
   ],
   "source": [
    "#ner_results = nlp(peter_text)\n",
    "for ent in ner_results:\n",
    "    print(ent[\"entity\"],ent[\"word\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e6a37f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7313009",
   "metadata": {},
   "outputs": [],
   "source": [
    "martin_text = extract_text_from_pdf('/home/chris/reesby/reverse_Malih/new_resumes/pdfs/Martin Howells Online Sales Representative Resume.pdf')\n",
    "#print(donna_text)\n",
    "martin_text = martin_text.replace('\\n',' ')\n",
    "martin_text = martin_text.replace('\\t',' ')\n",
    "martin_text = martin_text.lower()\n",
    "\n",
    "with open('/home/chris/reesby/reverse_Malih/new_resumes/txts/martin_howells.txt','w') as f:\n",
    "    f.write(martin_text)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4248c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_results = nlp(martin_text)\n",
    "for ent in ner_results:\n",
    "    print(ent[\"entity\"],ent[\"word\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00be2e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "jon_text = extract_text_from_pdf('/home/chris/reesby/reverse_Malih/new_resumes/pdfs/Jon-Michael Parr Online Sales Representative Resume.pdf')\n",
    "#print(donna_text)\n",
    "jon_text = jon_text.replace('\\n',' ')\n",
    "jon_text = jon_text.replace('\\t',' ')\n",
    "jon_text = jon_text.lower()\n",
    "\n",
    "with open('/home/chris/reesby/reverse_Malih/new_resumes/txts/jon_michael_parr','w') as f:\n",
    "    f.write(jon_text)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4a5260cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "donna_text = extract_text_from_pdf('/home/chris/reesby/reverse_Malih/new_resumes/pdfs/Donna Harvey Online Sales Representative Resume.pdf')\n",
    "#print(donna_text)\n",
    "donna_text = donna_text.replace('\\n',' ')\n",
    "donna_text = donna_text.replace('\\t',' ')\n",
    "donna_text = donna_text.lower()\n",
    "\n",
    "with open('/home/chris/reesby/reverse_Malih/new_resumes/txts/donna_harvey.txt','w') as f:\n",
    "    f.write(donna_text)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a213e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "peter_text = extract_text_from_pdf('/home/chris/reesby/reverse_Malih/new_resumes/pdfs/Peter-Ziminovic-Resume.pdf')\n",
    "peter_text = peter_text.replace('\\n',' ')\n",
    "peter_text = peter_text.replace('\\t',' ')\n",
    "peter_text = peter_text.replace('\\uf0b7',' ')\n",
    "peter_text = peter_text.lower()\n",
    "\n",
    "with open('/home/chris/reesby/reverse_Malih/new_resumes/txts/peter_ziminovic.txt','w') as f:\n",
    "    f.write(peter_text)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c6b52307",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tika import parser\n",
    "import os\n",
    "import glob\n",
    "#import emoji\n",
    "#import pandas as pd\n",
    "\n",
    "'''\n",
    "Takes a directory as input and then converts all pdfs to text and saves in .txt files\n",
    "'''\n",
    "def convert_pdf_to_text_file(dir):\n",
    "    output = []\n",
    "    dir_files = os.path.join(dir,'*.*') # need to add in *.* to search for all files\n",
    "    res_list = sorted(glob.glob(dir_files),key=os.path.getmtime)\n",
    "    #print('from convert to pdf - ', res_list)\n",
    "    for res in res_list:\n",
    "        [stem, ext] = os.path.splitext(res)    #path_to_pdf)\n",
    "        #process pdf files with tika \n",
    "        if (ext == \".pdf\"):\n",
    "            print(\"Processing \" + res)#  path_to_pdf)\n",
    "            pdf_contents = parser.from_file(res, service=\"text\") \n",
    "            path_to_txt = stem + \".txt\"\n",
    "            pdf_remove_newline = pdf_contents[\"content\"].replace(\"\\n\",\" \").lower()\n",
    "            #pdf_remove_newline = emoji.get_emoji_regexp().sub(\"\", pdf_remove_newline)\n",
    "            # write text to filename.txt\n",
    "            with open(path_to_txt,'w') as f:                \n",
    "                print('Text writen to ',path_to_txt)\n",
    "                f.write(pdf_remove_newline)\n",
    "                f.close()\n",
    "        elif (ext ==\".doc\"):\n",
    "            # add this in later to convert doc files\n",
    "            pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ed50943b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/chris/reesby/reverse_Malih/new_resumes/pdfs/Resume 2.pdf\n",
      "Text writen to  /home/chris/reesby/reverse_Malih/new_resumes/pdfs/Resume 2.txt\n",
      "Processing /home/chris/reesby/reverse_Malih/new_resumes/pdfs/Emily Loughlin Online Sales Representative Resume.pdf\n",
      "Text writen to  /home/chris/reesby/reverse_Malih/new_resumes/pdfs/Emily Loughlin Online Sales Representative Resume.txt\n",
      "Processing /home/chris/reesby/reverse_Malih/new_resumes/pdfs/Francesca Purcell Online Sales Representative Resume.pdf\n",
      "Text writen to  /home/chris/reesby/reverse_Malih/new_resumes/pdfs/Francesca Purcell Online Sales Representative Resume.txt\n",
      "Processing /home/chris/reesby/reverse_Malih/new_resumes/pdfs/Joshua Nicholson Online Sales Representative Resume.pdf\n",
      "Text writen to  /home/chris/reesby/reverse_Malih/new_resumes/pdfs/Joshua Nicholson Online Sales Representative Resume.txt\n",
      "Processing /home/chris/reesby/reverse_Malih/new_resumes/pdfs/Jon-Michael Parr Online Sales Representative Resume.pdf\n",
      "Text writen to  /home/chris/reesby/reverse_Malih/new_resumes/pdfs/Jon-Michael Parr Online Sales Representative Resume.txt\n",
      "Processing /home/chris/reesby/reverse_Malih/new_resumes/pdfs/Mathew Milanese Online Sales Representative Resume.pdf\n",
      "Text writen to  /home/chris/reesby/reverse_Malih/new_resumes/pdfs/Mathew Milanese Online Sales Representative Resume.txt\n",
      "Processing /home/chris/reesby/reverse_Malih/new_resumes/pdfs/Sarah Musgrave Online Sales Representative Resume.pdf\n",
      "Text writen to  /home/chris/reesby/reverse_Malih/new_resumes/pdfs/Sarah Musgrave Online Sales Representative Resume.txt\n",
      "Processing /home/chris/reesby/reverse_Malih/new_resumes/pdfs/Genovev Biddle Online Sales Representative Resume.pdf\n",
      "Text writen to  /home/chris/reesby/reverse_Malih/new_resumes/pdfs/Genovev Biddle Online Sales Representative Resume.txt\n",
      "Processing /home/chris/reesby/reverse_Malih/new_resumes/pdfs/Martin Howells Online Sales Representative Resume.pdf\n",
      "Text writen to  /home/chris/reesby/reverse_Malih/new_resumes/pdfs/Martin Howells Online Sales Representative Resume.txt\n",
      "Processing /home/chris/reesby/reverse_Malih/new_resumes/pdfs/Shontel Lester Online Sales Representative Resume.pdf\n",
      "Text writen to  /home/chris/reesby/reverse_Malih/new_resumes/pdfs/Shontel Lester Online Sales Representative Resume.txt\n",
      "Processing /home/chris/reesby/reverse_Malih/new_resumes/pdfs/Ngatau O'Dowd Online Sales Representative Resume.pdf\n",
      "Text writen to  /home/chris/reesby/reverse_Malih/new_resumes/pdfs/Ngatau O'Dowd Online Sales Representative Resume.txt\n",
      "Processing /home/chris/reesby/reverse_Malih/new_resumes/pdfs/Donna Harvey Online Sales Representative Resume.pdf\n",
      "Text writen to  /home/chris/reesby/reverse_Malih/new_resumes/pdfs/Donna Harvey Online Sales Representative Resume.txt\n",
      "Processing /home/chris/reesby/reverse_Malih/new_resumes/pdfs/Peter-Ziminovic-Resume.pdf\n",
      "Text writen to  /home/chris/reesby/reverse_Malih/new_resumes/pdfs/Peter-Ziminovic-Resume.txt\n"
     ]
    }
   ],
   "source": [
    "convert_pdf_to_text_file('/home/chris/reesby/reverse_Malih/new_resumes/pdfs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b40f048a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "from spacy.pipeline import EntityRuler\n",
    "import json\n",
    "\n",
    "# create a new NER pattern based on objective and saves them in resume_ner \n",
    "def generate_rules(patterns):\n",
    "    #nlp = English()\n",
    "    nlp = spacy.load('en_core_web_lg')\n",
    "    ruler = EntityRuler(nlp)\n",
    "    ruler.add_patterns(patterns)\n",
    "    nlp.add_pipe(ruler)\n",
    "    nlp.to_disk(\"resume_ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e54112f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "labeled_data = []\n",
    "with open(r\"/home/chris/reesby/reverse_Malih/Doccano/all.jsonl\", \"r\") as read_file:\n",
    "#with open(r\"/home/chris/reesby/reverse_Malih/python/Resume-Parser-master/Entity_Recognition_in_Resumes.json\", \"r\") as read_file:\n",
    "    for line in read_file:\n",
    "        data = json.loads(line)\n",
    "        labeled_data.append(data)\n",
    "#print(labeled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7e2d62ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'points'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-ed628a6836b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mentities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#print(entry['label'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"points\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mentities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mspacy_entry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"entities\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'points'"
     ]
    }
   ],
   "source": [
    "TRAINING_DATA = []\n",
    "for entry in labeled_data:\n",
    "    \n",
    "    entities = []\n",
    "    #print(entry['label'])\n",
    "    for e in entry[\"label\"]:\n",
    "        entities.append((e[0], e[1],e[2]))\n",
    "    spacy_entry = (entry['label'], {\"entities\": entities})\n",
    "    TRAINING_DATA.append(spacy_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "54063ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def trim_entity_spans(data: list) -> list:\n",
    "    \"\"\"Removes leading and trailing white spaces from entity spans.\n",
    "\n",
    "    Args:\n",
    "    data (list): The data to be cleaned in spaCy JSON format.\n",
    "\n",
    "    Returns:\n",
    "    list: The cleaned data.\n",
    "    \"\"\"\n",
    "    invalid_span_tokens = re.compile(r'\\s')\n",
    "\n",
    "    cleaned_data = []\n",
    "    for text, annotations in data:\n",
    "        entities = annotations['entities']\n",
    "        valid_entities = []\n",
    "        for start, end, label in entities:\n",
    "            valid_start = start\n",
    "            valid_end = end\n",
    "            # if there's preceding spaces, move the start position to nearest character\n",
    "            while valid_start < len(text) and invalid_span_tokens.match(\n",
    "                    text[valid_start]):\n",
    "                valid_start += 1\n",
    "            while valid_end > 1 and invalid_span_tokens.match(\n",
    "                    text[valid_end - 1]):\n",
    "                valid_end -= 1\n",
    "            valid_entities.append([valid_start, valid_end, label])\n",
    "        cleaned_data.append([text, {'entities': valid_entities}])\n",
    "    return cleaned_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d0b48fac",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-80a655e479d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrim_entity_spans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAINING_DATA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-79-274dddf57a8b>\u001b[0m in \u001b[0;36mtrim_entity_spans\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mvalid_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;31m# if there's preceding spaces, move the start position to nearest character\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             while valid_start < len(text) and invalid_span_tokens.match(\n\u001b[0m\u001b[1;32m     22\u001b[0m                     text[valid_start]):\n\u001b[1;32m     23\u001b[0m                 \u001b[0mvalid_start\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "trim_entity_spans(TRAINING_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "69b6c340",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([[6, 20, 'DATE'], [28, 43, 'PERSON'], [82, 97, 'PHONE'], [1155, 1186, 'EDUCATION'], [1187, 1207, 'INSTITUTION'], [1237, 1240, 'EDUCATION'], [1241, 1255, 'INSTITUTION'], [1285, 1293, 'EDUCATION'], [1294, 1331, 'INSTITUTION'], [1350, 1368, 'EDUCATION'], [1369, 1386, 'INSTITUTION'], [1405, 1427, 'EDUCATION'], [1430, 1451, 'INSTITUTION'], [1650, 1653, 'SKILLS'], [1808, 1814, 'SKILLS'], [1819, 1820, 'SKILLS'], [1861, 1867, 'ADDRESS'], [1872, 1878, 'ADDRESS'], [2354, 2375, 'ADDRESS'], [2377, 2407, 'SKILLS'], [2427, 2455, 'SKILLS'], [2550, 2567, 'SKILLS'], [2570, 2604, 'ADDRESS'], [3067, 3085, 'SKILLS'], [3191, 3214, 'COMPUTING_SKILLS'], [4854, 4878, 'ACCOMPLISHMENTS'], [4881, 4918, 'INSTITUTION'], [4919, 4961, 'ACCOMPLISHMENTS'], [4969, 4994, 'ACCOMPLISHMENTS'], [141, 162, 'EMPLOYER'], [173, 181, 'DATE'], [51, 74, 'EMAIL'], [188, 214, 'SKILLS'], [1209, 1223, 'DATE'], [1333, 1347, 'DATE'], [1266, 1280, 'DATE'], [1388, 1402, 'DATE'], [1463, 1474, 'DATE'], [1560, 1574, 'DATE'], [1540, 1557, 'ACCOMPLISHMENTS'], [1626, 1640, 'DATE'], [1641, 1649, 'DATE'], [1697, 1702, 'COMPUTING_SKILLS'], [1703, 1710, 'COMPUTING_SKILLS'], [1575, 1603, 'COMPUTING_SKILLS'], [1521, 1537, 'COMPUTING_SKILLS'], [1606, 1623, 'ACCOMPLISHMENTS'], [2306, 2333, 'COMPUTING_SKILLS'], [2336, 2352, 'DATE'], [2482, 2500, 'DATE'], [2518, 2547, 'DATE'], [2416, 2425, 'DATE'], [2608, 2617, 'DATE'], [2682, 2707, 'SKILLS'], [2738, 2745, 'DATE'], [3118, 3140, 'COMPUTING_SKILLS'], [4331, 4334, 'COMPUTING_SKILLS'], [4277, 4281, 'DATE'], [5006, 5018, 'DATE'], [5028, 5040, 'DATE'], [5049, 5062, 'DATE'], [5064, 5087, 'REFERENCES'], [2828, 2848, 'SKILLS'], [4767, 4789, 'SKILLS'], [4794, 4824, 'SKILLS'], [4336, 4353, 'COMPUTING_SKILLS'], [4359, 4383, 'COMPUTING_SKILLS'], [716, 732, 'COMPUTING_SKILLS'], [744, 748, 'COMPUTING_SKILLS'], [871, 889, 'SKILLS'], [893, 910, 'SKILLS']], {'entities': [(6, 20, 'DATE'), (28, 43, 'PERSON'), (82, 97, 'PHONE'), (1155, 1186, 'EDUCATION'), (1187, 1207, 'INSTITUTION'), (1237, 1240, 'EDUCATION'), (1241, 1255, 'INSTITUTION'), (1285, 1293, 'EDUCATION'), (1294, 1331, 'INSTITUTION'), (1350, 1368, 'EDUCATION'), (1369, 1386, 'INSTITUTION'), (1405, 1427, 'EDUCATION'), (1430, 1451, 'INSTITUTION'), (1650, 1653, 'SKILLS'), (1808, 1814, 'SKILLS'), (1819, 1820, 'SKILLS'), (1861, 1867, 'ADDRESS'), (1872, 1878, 'ADDRESS'), (2354, 2375, 'ADDRESS'), (2377, 2407, 'SKILLS'), (2427, 2455, 'SKILLS'), (2550, 2567, 'SKILLS'), (2570, 2604, 'ADDRESS'), (3067, 3085, 'SKILLS'), (3191, 3214, 'COMPUTING_SKILLS'), (4854, 4878, 'ACCOMPLISHMENTS'), (4881, 4918, 'INSTITUTION'), (4919, 4961, 'ACCOMPLISHMENTS'), (4969, 4994, 'ACCOMPLISHMENTS'), (141, 162, 'EMPLOYER'), (173, 181, 'DATE'), (51, 74, 'EMAIL'), (188, 214, 'SKILLS'), (1209, 1223, 'DATE'), (1333, 1347, 'DATE'), (1266, 1280, 'DATE'), (1388, 1402, 'DATE'), (1463, 1474, 'DATE'), (1560, 1574, 'DATE'), (1540, 1557, 'ACCOMPLISHMENTS'), (1626, 1640, 'DATE'), (1641, 1649, 'DATE'), (1697, 1702, 'COMPUTING_SKILLS'), (1703, 1710, 'COMPUTING_SKILLS'), (1575, 1603, 'COMPUTING_SKILLS'), (1521, 1537, 'COMPUTING_SKILLS'), (1606, 1623, 'ACCOMPLISHMENTS'), (2306, 2333, 'COMPUTING_SKILLS'), (2336, 2352, 'DATE'), (2482, 2500, 'DATE'), (2518, 2547, 'DATE'), (2416, 2425, 'DATE'), (2608, 2617, 'DATE'), (2682, 2707, 'SKILLS'), (2738, 2745, 'DATE'), (3118, 3140, 'COMPUTING_SKILLS'), (4331, 4334, 'COMPUTING_SKILLS'), (4277, 4281, 'DATE'), (5006, 5018, 'DATE'), (5028, 5040, 'DATE'), (5049, 5062, 'DATE'), (5064, 5087, 'REFERENCES'), (2828, 2848, 'SKILLS'), (4767, 4789, 'SKILLS'), (4794, 4824, 'SKILLS'), (4336, 4353, 'COMPUTING_SKILLS'), (4359, 4383, 'COMPUTING_SKILLS'), (716, 732, 'COMPUTING_SKILLS'), (744, 748, 'COMPUTING_SKILLS'), (871, 889, 'SKILLS'), (893, 910, 'SKILLS')]}), ([[0, 15, 'PERSON'], [18, 29, 'PHONE'], [989, 1007, 'DATE'], [34, 55, 'EMAIL'], [920, 969, 'EMPLOYMENT'], [970, 986, 'EMPLOYER'], [1010, 1015, 'SKILLS'], [1077, 1096, 'SKILLS'], [1098, 1106, 'SKILLS'], [1112, 1120, 'SKILLS'], [1251, 1288, 'SKILLS'], [1385, 1418, 'SKILLS'], [1458, 1477, 'DATE'], [1422, 1438, 'EMPLOYMENT'], [1439, 1448, 'EMPLOYER'], [1517, 1524, 'SKILLS'], [1595, 1615, 'SKILLS'], [1839, 1878, 'EMPLOYMENT'], [1879, 1911, 'EMPLOYER'], [1937, 1960, 'SKILLS'], [2253, 2270, 'SKILLS'], [2319, 2335, 'SKILLS'], [2337, 2359, 'SKILLS'], [2272, 2317, 'SKILLS'], [2362, 2398, 'SKILLS'], [2409, 2428, 'SKILLS'], [2542, 2553, 'SKILLS'], [2555, 2576, 'SKILLS'], [2578, 2613, 'SKILLS'], [2615, 2626, 'SKILLS'], [2631, 2656, 'SKILLS'], [2702, 2722, 'SKILLS'], [2871, 2898, 'EMPLOYMENT'], [2899, 2943, 'EMPLOYER'], [2946, 2965, 'DATE'], [2990, 3001, 'SKILLS'], [2968, 2985, 'SKILLS'], [3025, 3049, 'SKILLS'], [3275, 3305, 'SKILLS'], [3435, 3464, 'SKILLS'], [3516, 3535, 'SKILLS'], [3591, 3602, 'DATE'], [3741, 3770, 'EMPLOYMENT'], [3771, 3785, 'EMPLOYER'], [3788, 3807, 'DATE'], [3809, 3849, 'SKILLS'], [3944, 3967, 'SKILLS'], [3969, 3990, 'SKILLS'], [3992, 4008, 'SKILLS'], [4024, 4052, 'SKILLS'], [4057, 4091, 'SKILLS'], [4093, 4132, 'SKILLS'], [4196, 4219, 'EMPLOYMENT'], [4221, 4242, 'EMPLOYER'], [4245, 4265, 'DATE'], [4302, 4347, 'SKILLS'], [4358, 4371, 'SKILLS'], [4374, 4394, 'SKILLS'], [4412, 4435, 'SKILLS'], [4468, 4497, 'SKILLS'], [4502, 4536, 'SKILLS'], [5094, 5130, 'SKILLS'], [5172, 5188, 'SKILLS'], [5155, 5170, 'SKILLS'], [5203, 5215, 'SKILLS'], [5216, 5237, 'SKILLS'], [5264, 5277, 'SKILLS'], [5279, 5294, 'SKILLS'], [5299, 5317, 'SKILLS'], [5319, 5341, 'SKILLS'], [5378, 5384, 'SKILLS'], [5386, 5426, 'SKILLS'], [5463, 5491, 'SKILLS'], [5493, 5533, 'SKILLS'], [5549, 5576, 'SKILLS'], [5657, 5673, 'SKILLS'], [5747, 5769, 'SKILLS'], [5783, 5802, 'SKILLS'], [5830, 5854, 'SKILLS'], [5945, 5965, 'SKILLS'], [6003, 6012, 'SKILLS'], [6017, 6030, 'SKILLS'], [6418, 6427, 'SKILLS'], [6429, 6442, 'SKILLS'], [6447, 6463, 'SKILLS'], [7376, 7394, 'SKILLS'], [7647, 7675, 'EDUCATION'], [7677, 7681, 'DATE'], [7684, 7714, 'EDUCATION'], [7716, 7720, 'DATE'], [7723, 7763, 'EDUCATION'], [8058, 8069, 'SKILLS'], [8072, 8082, 'SKILLS'], [7894, 7913, 'SKILLS'], [7918, 7926, 'SKILLS'], [7961, 7977, 'SKILLS'], [7937, 7952, 'SKILLS'], [7986, 8008, 'SKILLS'], [8010, 8045, 'ACCOMPLISHMENTS'], [4683, 4687, 'DATE'], [7006, 7020, 'SKILLS'], [6976, 7002, 'SKILLS'], [6928, 6971, 'SKILLS'], [7094, 7108, 'SKILLS'], [6170, 6200, 'SKILLS'], [294, 331, 'SKILLS'], [333, 350, 'SKILLS'], [355, 383, 'SKILLS']], {'entities': [(0, 15, 'PERSON'), (18, 29, 'PHONE'), (989, 1007, 'DATE'), (34, 55, 'EMAIL'), (920, 969, 'EMPLOYMENT'), (970, 986, 'EMPLOYER'), (1010, 1015, 'SKILLS'), (1077, 1096, 'SKILLS'), (1098, 1106, 'SKILLS'), (1112, 1120, 'SKILLS'), (1251, 1288, 'SKILLS'), (1385, 1418, 'SKILLS'), (1458, 1477, 'DATE'), (1422, 1438, 'EMPLOYMENT'), (1439, 1448, 'EMPLOYER'), (1517, 1524, 'SKILLS'), (1595, 1615, 'SKILLS'), (1839, 1878, 'EMPLOYMENT'), (1879, 1911, 'EMPLOYER'), (1937, 1960, 'SKILLS'), (2253, 2270, 'SKILLS'), (2319, 2335, 'SKILLS'), (2337, 2359, 'SKILLS'), (2272, 2317, 'SKILLS'), (2362, 2398, 'SKILLS'), (2409, 2428, 'SKILLS'), (2542, 2553, 'SKILLS'), (2555, 2576, 'SKILLS'), (2578, 2613, 'SKILLS'), (2615, 2626, 'SKILLS'), (2631, 2656, 'SKILLS'), (2702, 2722, 'SKILLS'), (2871, 2898, 'EMPLOYMENT'), (2899, 2943, 'EMPLOYER'), (2946, 2965, 'DATE'), (2990, 3001, 'SKILLS'), (2968, 2985, 'SKILLS'), (3025, 3049, 'SKILLS'), (3275, 3305, 'SKILLS'), (3435, 3464, 'SKILLS'), (3516, 3535, 'SKILLS'), (3591, 3602, 'DATE'), (3741, 3770, 'EMPLOYMENT'), (3771, 3785, 'EMPLOYER'), (3788, 3807, 'DATE'), (3809, 3849, 'SKILLS'), (3944, 3967, 'SKILLS'), (3969, 3990, 'SKILLS'), (3992, 4008, 'SKILLS'), (4024, 4052, 'SKILLS'), (4057, 4091, 'SKILLS'), (4093, 4132, 'SKILLS'), (4196, 4219, 'EMPLOYMENT'), (4221, 4242, 'EMPLOYER'), (4245, 4265, 'DATE'), (4302, 4347, 'SKILLS'), (4358, 4371, 'SKILLS'), (4374, 4394, 'SKILLS'), (4412, 4435, 'SKILLS'), (4468, 4497, 'SKILLS'), (4502, 4536, 'SKILLS'), (5094, 5130, 'SKILLS'), (5172, 5188, 'SKILLS'), (5155, 5170, 'SKILLS'), (5203, 5215, 'SKILLS'), (5216, 5237, 'SKILLS'), (5264, 5277, 'SKILLS'), (5279, 5294, 'SKILLS'), (5299, 5317, 'SKILLS'), (5319, 5341, 'SKILLS'), (5378, 5384, 'SKILLS'), (5386, 5426, 'SKILLS'), (5463, 5491, 'SKILLS'), (5493, 5533, 'SKILLS'), (5549, 5576, 'SKILLS'), (5657, 5673, 'SKILLS'), (5747, 5769, 'SKILLS'), (5783, 5802, 'SKILLS'), (5830, 5854, 'SKILLS'), (5945, 5965, 'SKILLS'), (6003, 6012, 'SKILLS'), (6017, 6030, 'SKILLS'), (6418, 6427, 'SKILLS'), (6429, 6442, 'SKILLS'), (6447, 6463, 'SKILLS'), (7376, 7394, 'SKILLS'), (7647, 7675, 'EDUCATION'), (7677, 7681, 'DATE'), (7684, 7714, 'EDUCATION'), (7716, 7720, 'DATE'), (7723, 7763, 'EDUCATION'), (8058, 8069, 'SKILLS'), (8072, 8082, 'SKILLS'), (7894, 7913, 'SKILLS'), (7918, 7926, 'SKILLS'), (7961, 7977, 'SKILLS'), (7937, 7952, 'SKILLS'), (7986, 8008, 'SKILLS'), (8010, 8045, 'ACCOMPLISHMENTS'), (4683, 4687, 'DATE'), (7006, 7020, 'SKILLS'), (6976, 7002, 'SKILLS'), (6928, 6971, 'SKILLS'), (7094, 7108, 'SKILLS'), (6170, 6200, 'SKILLS'), (294, 331, 'SKILLS'), (333, 350, 'SKILLS'), (355, 383, 'SKILLS')]}), ([[97, 110, 'PERSON'], [113, 126, 'GPE'], [128, 131, 'GPE'], [134, 150, 'PHONE'], [154, 178, 'EMAIL'], [257, 267, 'EDUCATION'], [269, 291, 'INSTITUTION'], [293, 300, 'GPE'], [302, 306, 'GPE'], [308, 322, 'GPE'], [348, 380, 'EDUCATION'], [389, 399, 'GPE'], [401, 405, 'DATE'], [410, 449, 'EDUCATION'], [451, 459, 'GPE'], [461, 471, 'GPE'], [473, 477, 'DATE'], [482, 505, 'EDUCATION'], [508, 533, 'INSTITUTION'], [534, 543, 'GPE'], [545, 549, 'DATE'], [553, 590, 'EDUCATION'], [593, 597, 'INSTITUTION'], [599, 603, 'DATE'], [608, 627, 'EDUCATION'], [630, 651, 'INSTITUTION'], [652, 661, 'GPE'], [663, 667, 'DATE'], [672, 693, 'EDUCATION'], [696, 721, 'INSTITUTION'], [746, 753, 'SKILLS'], [782, 793, 'INSTITUTION'], [795, 799, 'DATE'], [1623, 1642, 'DATE'], [1657, 1676, 'DATE'], [1769, 1789, 'DATE'], [1792, 1816, 'EMPLOYMENT'], [1818, 1836, 'EMPLOYER'], [1838, 1859, 'EMPLOYER'], [1861, 1869, 'GPE'], [1871, 1874, 'GPE'], [2055, 2088, 'EMPLOYMENT'], [2090, 2115, 'EMPLOYER'], [2117, 2125, 'GPE'], [2131, 2134, 'GPE'], [2199, 2213, 'SKILLS'], [2216, 2223, 'SKILLS'], [2225, 2240, 'SKILLS'], [2257, 2276, 'SKILLS'], [2328, 2345, 'SKILLS'], [2439, 2449, 'SKILLS'], [2579, 2588, 'SKILLS'], [2619, 2645, 'SKILLS'], [2661, 2683, 'SKILLS'], [2702, 2736, 'SKILLS'], [2851, 2882, 'SKILLS'], [2924, 2931, 'SKILLS'], [2933, 2949, 'SKILLS'], [3508, 3531, 'EMPLOYMENT'], [3537, 3549, 'EMPLOYER'], [3585, 3592, 'DATE'], [3703, 3714, 'SKILLS'], [3377, 3393, 'SKILLS'], [3787, 3798, 'SKILLS'], [3887, 3909, 'PERSON'], [3963, 3975, 'PERSON'], [4017, 4033, 'COMPUTING_SKILLS'], [4095, 4105, 'COMPUTING_SKILLS'], [4152, 4171, 'COMPUTING_SKILLS'], [4175, 4193, 'SKILLS'], [4197, 4217, 'SKILLS'], [4221, 4240, 'SKILLS'], [4264, 4295, 'ACCOMPLISHMENTS'], [4302, 4329, 'INSTITUTION'], [4340, 4370, 'ACCOMPLISHMENTS'], [4377, 4404, 'INSTITUTION'], [4406, 4410, 'DATE'], [4331, 4335, 'DATE'], [4415, 4441, 'ACCOMPLISHMENTS'], [4448, 4478, 'INSTITUTION'], [4480, 4483, 'DATE'], [4489, 4523, 'ACCOMPLISHMENTS'], [4530, 4560, 'INSTITUTION'], [4562, 4566, 'DATE'], [4571, 4597, 'ACCOMPLISHMENTS'], [4604, 4634, 'INSTITUTION'], [4636, 4640, 'DATE'], [4700, 4711, 'DATE'], [4767, 4781, 'DATE'], [4836, 4850, 'DATE'], [4811, 4835, 'EMPLOYMENT'], [4786, 4809, 'EMPLOYER'], [4874, 4883, 'ACCOMPLISHMENTS'], [4915, 4926, 'DATE'], [4986, 4998, 'DATE'], [5007, 5027, 'DATE'], [4936, 4955, 'INSTITUTION'], [4976, 4985, 'ACCOMPLISHMENTS'], [5347, 5364, 'SKILLS'], [5369, 5388, 'SKILLS'], [5481, 5493, 'SKILLS'], [5671, 5690, 'SKILLS'], [5857, 5876, 'SKILLS'], [5750, 5758, 'SKILLS'], [5759, 5770, 'SKILLS'], [5775, 5789, 'SKILLS'], [7519, 7539, 'DATE'], [6995, 7015, 'DATE'], [7018, 7042, 'EMPLOYMENT'], [7044, 7075, 'EMPLOYER'], [7077, 7085, 'GPE'], [7091, 7094, 'GPE'], [7542, 7556, 'EMPLOYMENT'], [7558, 7568, 'EMPLOYER'], [7570, 7586, 'GPE'], [7588, 7591, 'GPE'], [7688, 7699, 'SKILLS'], [7754, 7784, 'SKILLS'], [7956, 7976, 'DATE'], [7979, 8001, 'DATE'], [8003, 8025, 'EMPLOYER'], [8027, 8035, 'GPE'], [8041, 8044, 'GPE'], [8056, 8068, 'SKILLS'], [8150, 8170, 'DATE'], [8925, 8944, 'DATE'], [9324, 9344, 'DATE'], [9819, 9839, 'DATE'], [10018, 10038, 'DATE'], [10314, 10336, 'DATE'], [10453, 10464, 'DATE'], [10672, 10692, 'DATE'], [11192, 11212, 'DATE'], [11676, 11696, 'DATE'], [12184, 12204, 'DATE'], [9347, 9366, 'EMPLOYMENT'], [9371, 9390, 'EDUCATION'], [9395, 9416, 'EMPLOYER'], [9418, 9426, 'GPE'], [9432, 9435, 'GPE'], [9541, 9552, 'SKILLS'], [9686, 9704, 'SKILLS'], [9707, 9724, 'SKILLS'], [9769, 9783, 'SKILLS'], [9842, 9852, 'EMPLOYMENT'], [9857, 9867, 'EMPLOYER'], [9888, 9898, 'SKILLS'], [9873, 9881, 'GPE'], [10004, 10012, 'GPE'], [10047, 10066, 'SKILLS'], [10122, 10135, 'SKILLS'], [10187, 10197, 'SKILLS'], [10269, 10278, 'SKILLS'], [10344, 10362, 'SKILLS'], [10367, 10384, 'SKILLS'], [10469, 10490, 'EMPLOYER'], [10492, 10503, 'EMPLOYER'], [10504, 10509, 'EMPLOYER'], [10511, 10529, 'INSTITUTION'], [10531, 10547, 'INSTITUTION'], [10549, 10570, 'INSTITUTION'], [10572, 10605, 'INSTITUTION'], [10607, 10626, 'INSTITUTION'], [10697, 10721, 'EMPLOYMENT'], [10758, 10777, 'EMPLOYER'], [10859, 10875, 'SKILLS'], [11215, 11236, 'EMPLOYMENT'], [11262, 11289, 'EMPLOYER'], [11291, 11300, 'GPE'], [11302, 11306, 'GPE'], [11308, 11311, 'GPE'], [11328, 11335, 'SKILLS'], [11506, 11522, 'SKILLS'], [11526, 11538, 'SKILLS'], [11595, 11607, 'SKILLS'], [11699, 11718, 'EMPLOYMENT'], [11723, 11750, 'EMPLOYER'], [11752, 11764, 'GPE'], [11766, 11770, 'GPE'], [11772, 11774, 'GPE'], [11787, 11806, 'SKILLS'], [11820, 11839, 'SKILLS'], [12207, 12223, 'EMPLOYMENT'], [12224, 12242, 'EMPLOYMENT'], [12246, 12263, 'EMPLOYER'], [12264, 12274, 'GPE'], [12276, 12280, 'GPE'], [12281, 12283, 'GPE'], [12318, 12326, 'SKILLS'], [12328, 12336, 'SKILLS'], [12341, 12348, 'SKILLS'], [12511, 12530, 'SKILLS'], [12595, 12614, 'SKILLS'], [12408, 12416, 'SKILLS'], [1, 13, 'PERSON']], {'entities': [(97, 110, 'PERSON'), (113, 126, 'GPE'), (128, 131, 'GPE'), (134, 150, 'PHONE'), (154, 178, 'EMAIL'), (257, 267, 'EDUCATION'), (269, 291, 'INSTITUTION'), (293, 300, 'GPE'), (302, 306, 'GPE'), (308, 322, 'GPE'), (348, 380, 'EDUCATION'), (389, 399, 'GPE'), (401, 405, 'DATE'), (410, 449, 'EDUCATION'), (451, 459, 'GPE'), (461, 471, 'GPE'), (473, 477, 'DATE'), (482, 505, 'EDUCATION'), (508, 533, 'INSTITUTION'), (534, 543, 'GPE'), (545, 549, 'DATE'), (553, 590, 'EDUCATION'), (593, 597, 'INSTITUTION'), (599, 603, 'DATE'), (608, 627, 'EDUCATION'), (630, 651, 'INSTITUTION'), (652, 661, 'GPE'), (663, 667, 'DATE'), (672, 693, 'EDUCATION'), (696, 721, 'INSTITUTION'), (746, 753, 'SKILLS'), (782, 793, 'INSTITUTION'), (795, 799, 'DATE'), (1623, 1642, 'DATE'), (1657, 1676, 'DATE'), (1769, 1789, 'DATE'), (1792, 1816, 'EMPLOYMENT'), (1818, 1836, 'EMPLOYER'), (1838, 1859, 'EMPLOYER'), (1861, 1869, 'GPE'), (1871, 1874, 'GPE'), (2055, 2088, 'EMPLOYMENT'), (2090, 2115, 'EMPLOYER'), (2117, 2125, 'GPE'), (2131, 2134, 'GPE'), (2199, 2213, 'SKILLS'), (2216, 2223, 'SKILLS'), (2225, 2240, 'SKILLS'), (2257, 2276, 'SKILLS'), (2328, 2345, 'SKILLS'), (2439, 2449, 'SKILLS'), (2579, 2588, 'SKILLS'), (2619, 2645, 'SKILLS'), (2661, 2683, 'SKILLS'), (2702, 2736, 'SKILLS'), (2851, 2882, 'SKILLS'), (2924, 2931, 'SKILLS'), (2933, 2949, 'SKILLS'), (3508, 3531, 'EMPLOYMENT'), (3537, 3549, 'EMPLOYER'), (3585, 3592, 'DATE'), (3703, 3714, 'SKILLS'), (3377, 3393, 'SKILLS'), (3787, 3798, 'SKILLS'), (3887, 3909, 'PERSON'), (3963, 3975, 'PERSON'), (4017, 4033, 'COMPUTING_SKILLS'), (4095, 4105, 'COMPUTING_SKILLS'), (4152, 4171, 'COMPUTING_SKILLS'), (4175, 4193, 'SKILLS'), (4197, 4217, 'SKILLS'), (4221, 4240, 'SKILLS'), (4264, 4295, 'ACCOMPLISHMENTS'), (4302, 4329, 'INSTITUTION'), (4340, 4370, 'ACCOMPLISHMENTS'), (4377, 4404, 'INSTITUTION'), (4406, 4410, 'DATE'), (4331, 4335, 'DATE'), (4415, 4441, 'ACCOMPLISHMENTS'), (4448, 4478, 'INSTITUTION'), (4480, 4483, 'DATE'), (4489, 4523, 'ACCOMPLISHMENTS'), (4530, 4560, 'INSTITUTION'), (4562, 4566, 'DATE'), (4571, 4597, 'ACCOMPLISHMENTS'), (4604, 4634, 'INSTITUTION'), (4636, 4640, 'DATE'), (4700, 4711, 'DATE'), (4767, 4781, 'DATE'), (4836, 4850, 'DATE'), (4811, 4835, 'EMPLOYMENT'), (4786, 4809, 'EMPLOYER'), (4874, 4883, 'ACCOMPLISHMENTS'), (4915, 4926, 'DATE'), (4986, 4998, 'DATE'), (5007, 5027, 'DATE'), (4936, 4955, 'INSTITUTION'), (4976, 4985, 'ACCOMPLISHMENTS'), (5347, 5364, 'SKILLS'), (5369, 5388, 'SKILLS'), (5481, 5493, 'SKILLS'), (5671, 5690, 'SKILLS'), (5857, 5876, 'SKILLS'), (5750, 5758, 'SKILLS'), (5759, 5770, 'SKILLS'), (5775, 5789, 'SKILLS'), (7519, 7539, 'DATE'), (6995, 7015, 'DATE'), (7018, 7042, 'EMPLOYMENT'), (7044, 7075, 'EMPLOYER'), (7077, 7085, 'GPE'), (7091, 7094, 'GPE'), (7542, 7556, 'EMPLOYMENT'), (7558, 7568, 'EMPLOYER'), (7570, 7586, 'GPE'), (7588, 7591, 'GPE'), (7688, 7699, 'SKILLS'), (7754, 7784, 'SKILLS'), (7956, 7976, 'DATE'), (7979, 8001, 'DATE'), (8003, 8025, 'EMPLOYER'), (8027, 8035, 'GPE'), (8041, 8044, 'GPE'), (8056, 8068, 'SKILLS'), (8150, 8170, 'DATE'), (8925, 8944, 'DATE'), (9324, 9344, 'DATE'), (9819, 9839, 'DATE'), (10018, 10038, 'DATE'), (10314, 10336, 'DATE'), (10453, 10464, 'DATE'), (10672, 10692, 'DATE'), (11192, 11212, 'DATE'), (11676, 11696, 'DATE'), (12184, 12204, 'DATE'), (9347, 9366, 'EMPLOYMENT'), (9371, 9390, 'EDUCATION'), (9395, 9416, 'EMPLOYER'), (9418, 9426, 'GPE'), (9432, 9435, 'GPE'), (9541, 9552, 'SKILLS'), (9686, 9704, 'SKILLS'), (9707, 9724, 'SKILLS'), (9769, 9783, 'SKILLS'), (9842, 9852, 'EMPLOYMENT'), (9857, 9867, 'EMPLOYER'), (9888, 9898, 'SKILLS'), (9873, 9881, 'GPE'), (10004, 10012, 'GPE'), (10047, 10066, 'SKILLS'), (10122, 10135, 'SKILLS'), (10187, 10197, 'SKILLS'), (10269, 10278, 'SKILLS'), (10344, 10362, 'SKILLS'), (10367, 10384, 'SKILLS'), (10469, 10490, 'EMPLOYER'), (10492, 10503, 'EMPLOYER'), (10504, 10509, 'EMPLOYER'), (10511, 10529, 'INSTITUTION'), (10531, 10547, 'INSTITUTION'), (10549, 10570, 'INSTITUTION'), (10572, 10605, 'INSTITUTION'), (10607, 10626, 'INSTITUTION'), (10697, 10721, 'EMPLOYMENT'), (10758, 10777, 'EMPLOYER'), (10859, 10875, 'SKILLS'), (11215, 11236, 'EMPLOYMENT'), (11262, 11289, 'EMPLOYER'), (11291, 11300, 'GPE'), (11302, 11306, 'GPE'), (11308, 11311, 'GPE'), (11328, 11335, 'SKILLS'), (11506, 11522, 'SKILLS'), (11526, 11538, 'SKILLS'), (11595, 11607, 'SKILLS'), (11699, 11718, 'EMPLOYMENT'), (11723, 11750, 'EMPLOYER'), (11752, 11764, 'GPE'), (11766, 11770, 'GPE'), (11772, 11774, 'GPE'), (11787, 11806, 'SKILLS'), (11820, 11839, 'SKILLS'), (12207, 12223, 'EMPLOYMENT'), (12224, 12242, 'EMPLOYMENT'), (12246, 12263, 'EMPLOYER'), (12264, 12274, 'GPE'), (12276, 12280, 'GPE'), (12281, 12283, 'GPE'), (12318, 12326, 'SKILLS'), (12328, 12336, 'SKILLS'), (12341, 12348, 'SKILLS'), (12511, 12530, 'SKILLS'), (12595, 12614, 'SKILLS'), (12408, 12416, 'SKILLS'), (1, 13, 'PERSON')]}), ([[121, 164, 'ADDRESS'], [174, 186, 'PHONE'], [197, 217, 'EMAIL'], [335, 351, 'ACCOMPLISHMENTS'], [380, 418, 'SKILLS'], [423, 446, 'SKILLS'], [451, 476, 'SKILLS'], [492, 522, 'COMPUTING_SKILLS'], [564, 589, 'SKILLS'], [594, 630, 'SKILLS'], [635, 668, 'SKILLS'], [673, 684, 'SKILLS'], [720, 743, 'SKILLS'], [748, 773, 'SKILLS'], [778, 800, 'SKILLS'], [867, 894, 'SKILLS'], [899, 923, 'SKILLS'], [1049, 1062, 'PHONE'], [1066, 1086, 'EMAIL'], [2471, 2494, 'EMPLOYMENT'], [2498, 2510, 'EMPLOYER'], [2536, 2545, 'DATE'], [2513, 2521, 'GPE'], [2523, 2532, 'GPE'], [2550, 2570, 'EMPLOYMENT'], [2577, 2588, 'EMPLOYER'], [2591, 2595, 'GPE'], [2597, 2601, 'GPE'], [2602, 2611, 'DATE'], [2616, 2635, 'EMPLOYMENT'], [2671, 2692, 'EMPLOYER'], [2695, 2699, 'GPE'], [2701, 2705, 'GPE'], [2745, 2754, 'DATE'], [2759, 2775, 'EMPLOYMENT'], [2776, 2789, 'EMPLOYER'], [2791, 2796, 'GPE'], [2798, 2802, 'GPE'], [2803, 2812, 'DATE'], [2817, 2838, 'EMPLOYMENT'], [2838, 2861, 'EMPLOYER'], [2862, 2867, 'GPE'], [2869, 2873, 'GPE'], [2874, 2883, 'DATE'], [2939, 2953, 'PERSON'], [2955, 2998, 'ADDRESS'], [3008, 3020, 'PHONE'], [3031, 3051, 'EMAIL'], [3884, 3896, 'PHONE'], [3900, 3920, 'EMAIL'], [3958, 3967, 'DATE'], [3968, 3990, 'EMPLOYMENT'], [3994, 4014, 'EMPLOYER'], [4017, 4025, 'GPE'], [4027, 4036, 'GPE'], [4069, 4101, 'SKILLS'], [4104, 4125, 'SKILLS'], [4145, 4172, 'SKILLS'], [4457, 4469, 'SKILLS'], [4486, 4503, 'SKILLS'], [4792, 4813, 'SKILLS'], [4822, 4829, 'SKILLS'], [4831, 4847, 'SKILLS'], [4851, 4868, 'SKILLS'], [4895, 4917, 'SKILLS'], [5003, 5013, 'SKILLS'], [5018, 5037, 'SKILLS'], [5152, 5163, 'SKILLS'], [5169, 5208, 'ACCOMPLISHMENTS'], [5435, 5444, 'DATE'], [5445, 5465, 'EMPLOYMENT'], [5469, 5480, 'EMPLOYER'], [5483, 5487, 'GPE'], [5489, 5493, 'GPE'], [5515, 5555, 'SKILLS'], [5708, 5726, 'SKILLS'], [5731, 5741, 'SKILLS'], [5857, 5871, 'PERSON'], [5873, 5916, 'ADDRESS'], [5926, 5938, 'PHONE'], [5949, 5969, 'EMAIL'], [6070, 6086, 'ACCOMPLISHMENTS'], [6089, 6106, 'ACCOMPLISHMENTS'], [6135, 6173, 'SKILLS'], [6178, 6201, 'SKILLS'], [6206, 6231, 'SKILLS'], [6319, 6344, 'SKILLS'], [6349, 6385, 'SKILLS'], [6390, 6423, 'SKILLS'], [6475, 6498, 'SKILLS'], [6445, 6470, 'SKILLS'], [6428, 6439, 'SKILLS'], [6503, 6528, 'SKILLS'], [6533, 6555, 'SKILLS'], [6560, 6578, 'SKILLS'], [6622, 6649, 'SKILLS'], [6654, 6677, 'SKILLS'], [6805, 6817, 'PHONE'], [6821, 6841, 'EMAIL'], [6879, 6888, 'DATE'], [6889, 6908, 'EMPLOYMENT'], [6932, 6955, 'EMPLOYER'], [6958, 6962, 'GPE'], [6964, 6968, 'GPE'], [6990, 7012, 'SKILLS'], [7041, 7095, 'SKILLS'], [7100, 7119, 'SKILLS'], [7121, 7140, 'SKILLS'], [7182, 7231, 'SKILLS'], [7235, 7251, 'SKILLS'], [7253, 7268, 'SKILLS'], [7270, 7276, 'SKILLS'], [7278, 7295, 'SKILLS'], [7298, 7307, 'DATE'], [7308, 7324, 'EMPLOYMENT'], [7327, 7340, 'EMPLOYER'], [7342, 7347, 'GPE'], [7349, 7354, 'GPE'], [7562, 7595, 'SKILLS'], [7498, 7513, 'SKILLS'], [7528, 7557, 'SKILLS'], [7707, 7716, 'DATE'], [7717, 7737, 'EMPLOYMENT'], [7741, 7764, 'EMPLOYER'], [7765, 7770, 'GPE'], [7772, 7776, 'GPE'], [7952, 7972, 'SKILLS'], [8082, 8099, 'SKILLS'], [8282, 8294, 'DATE'], [8304, 8321, 'EMPLOYMENT'], [8324, 8351, 'EMPLOYER'], [8354, 8361, 'GPE'], [8362, 8366, 'GPE'], [8368, 8376, 'EMPLOYMENT'], [8379, 8406, 'EMPLOYER'], [8409, 8416, 'GPE'], [8417, 8421, 'GPE'], [8425, 8432, 'EMPLOYMENT'], [8434, 8465, 'EMPLOYER'], [8468, 8478, 'GPE'], [8480, 8484, 'GPE'], [8487, 8495, 'EMPLOYMENT'], [8497, 8527, 'EMPLOYER'], [8530, 8540, 'GPE'], [8542, 8546, 'GPE'], [4949, 4987, 'SKILLS'], [4585, 4627, 'SKILLS'], [4348, 4368, 'SKILLS'], [1235, 1267, 'SKILLS'], [1272, 1287, 'SKILLS'], [1375, 1412, 'SKILLS'], [1440, 1460, 'SKILLS'], [2358, 2379, 'SKILLS'], [105, 119, 'PERSON']], {'entities': [(121, 164, 'ADDRESS'), (174, 186, 'PHONE'), (197, 217, 'EMAIL'), (335, 351, 'ACCOMPLISHMENTS'), (380, 418, 'SKILLS'), (423, 446, 'SKILLS'), (451, 476, 'SKILLS'), (492, 522, 'COMPUTING_SKILLS'), (564, 589, 'SKILLS'), (594, 630, 'SKILLS'), (635, 668, 'SKILLS'), (673, 684, 'SKILLS'), (720, 743, 'SKILLS'), (748, 773, 'SKILLS'), (778, 800, 'SKILLS'), (867, 894, 'SKILLS'), (899, 923, 'SKILLS'), (1049, 1062, 'PHONE'), (1066, 1086, 'EMAIL'), (2471, 2494, 'EMPLOYMENT'), (2498, 2510, 'EMPLOYER'), (2536, 2545, 'DATE'), (2513, 2521, 'GPE'), (2523, 2532, 'GPE'), (2550, 2570, 'EMPLOYMENT'), (2577, 2588, 'EMPLOYER'), (2591, 2595, 'GPE'), (2597, 2601, 'GPE'), (2602, 2611, 'DATE'), (2616, 2635, 'EMPLOYMENT'), (2671, 2692, 'EMPLOYER'), (2695, 2699, 'GPE'), (2701, 2705, 'GPE'), (2745, 2754, 'DATE'), (2759, 2775, 'EMPLOYMENT'), (2776, 2789, 'EMPLOYER'), (2791, 2796, 'GPE'), (2798, 2802, 'GPE'), (2803, 2812, 'DATE'), (2817, 2838, 'EMPLOYMENT'), (2838, 2861, 'EMPLOYER'), (2862, 2867, 'GPE'), (2869, 2873, 'GPE'), (2874, 2883, 'DATE'), (2939, 2953, 'PERSON'), (2955, 2998, 'ADDRESS'), (3008, 3020, 'PHONE'), (3031, 3051, 'EMAIL'), (3884, 3896, 'PHONE'), (3900, 3920, 'EMAIL'), (3958, 3967, 'DATE'), (3968, 3990, 'EMPLOYMENT'), (3994, 4014, 'EMPLOYER'), (4017, 4025, 'GPE'), (4027, 4036, 'GPE'), (4069, 4101, 'SKILLS'), (4104, 4125, 'SKILLS'), (4145, 4172, 'SKILLS'), (4457, 4469, 'SKILLS'), (4486, 4503, 'SKILLS'), (4792, 4813, 'SKILLS'), (4822, 4829, 'SKILLS'), (4831, 4847, 'SKILLS'), (4851, 4868, 'SKILLS'), (4895, 4917, 'SKILLS'), (5003, 5013, 'SKILLS'), (5018, 5037, 'SKILLS'), (5152, 5163, 'SKILLS'), (5169, 5208, 'ACCOMPLISHMENTS'), (5435, 5444, 'DATE'), (5445, 5465, 'EMPLOYMENT'), (5469, 5480, 'EMPLOYER'), (5483, 5487, 'GPE'), (5489, 5493, 'GPE'), (5515, 5555, 'SKILLS'), (5708, 5726, 'SKILLS'), (5731, 5741, 'SKILLS'), (5857, 5871, 'PERSON'), (5873, 5916, 'ADDRESS'), (5926, 5938, 'PHONE'), (5949, 5969, 'EMAIL'), (6070, 6086, 'ACCOMPLISHMENTS'), (6089, 6106, 'ACCOMPLISHMENTS'), (6135, 6173, 'SKILLS'), (6178, 6201, 'SKILLS'), (6206, 6231, 'SKILLS'), (6319, 6344, 'SKILLS'), (6349, 6385, 'SKILLS'), (6390, 6423, 'SKILLS'), (6475, 6498, 'SKILLS'), (6445, 6470, 'SKILLS'), (6428, 6439, 'SKILLS'), (6503, 6528, 'SKILLS'), (6533, 6555, 'SKILLS'), (6560, 6578, 'SKILLS'), (6622, 6649, 'SKILLS'), (6654, 6677, 'SKILLS'), (6805, 6817, 'PHONE'), (6821, 6841, 'EMAIL'), (6879, 6888, 'DATE'), (6889, 6908, 'EMPLOYMENT'), (6932, 6955, 'EMPLOYER'), (6958, 6962, 'GPE'), (6964, 6968, 'GPE'), (6990, 7012, 'SKILLS'), (7041, 7095, 'SKILLS'), (7100, 7119, 'SKILLS'), (7121, 7140, 'SKILLS'), (7182, 7231, 'SKILLS'), (7235, 7251, 'SKILLS'), (7253, 7268, 'SKILLS'), (7270, 7276, 'SKILLS'), (7278, 7295, 'SKILLS'), (7298, 7307, 'DATE'), (7308, 7324, 'EMPLOYMENT'), (7327, 7340, 'EMPLOYER'), (7342, 7347, 'GPE'), (7349, 7354, 'GPE'), (7562, 7595, 'SKILLS'), (7498, 7513, 'SKILLS'), (7528, 7557, 'SKILLS'), (7707, 7716, 'DATE'), (7717, 7737, 'EMPLOYMENT'), (7741, 7764, 'EMPLOYER'), (7765, 7770, 'GPE'), (7772, 7776, 'GPE'), (7952, 7972, 'SKILLS'), (8082, 8099, 'SKILLS'), (8282, 8294, 'DATE'), (8304, 8321, 'EMPLOYMENT'), (8324, 8351, 'EMPLOYER'), (8354, 8361, 'GPE'), (8362, 8366, 'GPE'), (8368, 8376, 'EMPLOYMENT'), (8379, 8406, 'EMPLOYER'), (8409, 8416, 'GPE'), (8417, 8421, 'GPE'), (8425, 8432, 'EMPLOYMENT'), (8434, 8465, 'EMPLOYER'), (8468, 8478, 'GPE'), (8480, 8484, 'GPE'), (8487, 8495, 'EMPLOYMENT'), (8497, 8527, 'EMPLOYER'), (8530, 8540, 'GPE'), (8542, 8546, 'GPE'), (4949, 4987, 'SKILLS'), (4585, 4627, 'SKILLS'), (4348, 4368, 'SKILLS'), (1235, 1267, 'SKILLS'), (1272, 1287, 'SKILLS'), (1375, 1412, 'SKILLS'), (1440, 1460, 'SKILLS'), (2358, 2379, 'SKILLS'), (105, 119, 'PERSON')]}), ([[11, 29, 'PERSON'], [32, 82, 'ADDRESS'], [87, 99, 'PHONE'], [104, 133, 'EMAIL'], [695, 719, 'EMPLOYER'], [722, 736, 'GPE'], [738, 763, 'EMPLOYMENT'], [777, 796, 'DATE'], [804, 863, 'SKILLS'], [870, 909, 'SKILLS'], [913, 957, 'SKILLS'], [1134, 1159, 'SKILLS'], [1221, 1236, 'SKILLS'], [1294, 1321, 'SKILLS'], [1716, 1730, 'GPE'], [1695, 1709, 'EMPLOYER'], [1732, 1768, 'EMPLOYMENT'], [1769, 1794, 'DATE'], [1998, 2082, 'SKILLS'], [2336, 2383, 'SKILLS'], [2146, 2221, 'SKILLS'], [2440, 2459, 'SKILLS'], [2479, 2498, 'SKILLS'], [2516, 2519, 'SKILLS'], [2524, 2541, 'SKILLS'], [2600, 2617, 'EMPLOYER'], [2620, 2630, 'GPE'], [2633, 2653, 'EMPLOYMENT'], [2654, 2677, 'GPE'], [2679, 2703, 'DATE'], [2709, 2742, 'SKILLS'], [2894, 2951, 'SKILLS'], [3108, 3131, 'SKILLS'], [3407, 3432, 'SKILLS'], [3620, 3653, 'SKILLS'], [3657, 3726, 'SKILLS'], [3734, 3817, 'SKILLS'], [3819, 3901, 'SKILLS'], [3907, 3940, 'SKILLS'], [4125, 4142, 'EMPLOYER'], [4145, 4155, 'GPE'], [4159, 4177, 'EMPLOYMENT'], [4180, 4208, 'DATE'], [4386, 4407, 'SKILLS'], [4212, 4254, 'SKILLS'], [4431, 4463, 'SKILLS'], [4465, 4488, 'SKILLS'], [4525, 4552, 'SKILLS'], [4804, 4827, 'SKILLS'], [5017, 5048, 'SKILLS'], [5103, 5124, 'SKILLS'], [5237, 5261, 'EMPLOYER'], [5263, 5273, 'GPE'], [5285, 5293, 'EMPLOYMENT'], [5295, 5319, 'DATE'], [5325, 5367, 'SKILLS'], [5437, 5462, 'SKILLS'], [5566, 5588, 'SKILLS'], [5851, 5880, 'SKILLS'], [5881, 5899, 'SKILLS'], [6223, 6239, 'EMPLOYER'], [6240, 6252, 'GPE'], [6266, 6274, 'EMPLOYMENT'], [6276, 6300, 'DATE'], [6305, 6347, 'SKILLS'], [6477, 6520, 'SKILLS'], [6603, 6622, 'SKILLS'], [6779, 6787, 'EMPLOYER'], [6790, 6801, 'GPE'], [6805, 6831, 'EMPLOYMENT'], [6835, 6860, 'DATE'], [6866, 6880, 'SKILLS'], [6881, 6903, 'SKILLS'], [6966, 7006, 'SKILLS'], [7247, 7279, 'SKILLS'], [7423, 7447, 'INSTITUTION'], [7448, 7454, 'GPE'], [7456, 7496, 'EDUCATION'], [7498, 7512, 'DATE'], [7518, 7537, 'INSTITUTION'], [7539, 7549, 'GPE'], [7552, 7573, 'EDUCATION'], [7630, 7652, 'DATE'], [7657, 7681, 'INSTITUTION'], [7684, 7694, 'GPE'], [7697, 7717, 'EDUCATION'], [7719, 7748, 'DATE'], [7781, 7798, 'ACCOMPLISHMENTS'], [368, 419, 'SKILLS']], {'entities': [(11, 29, 'PERSON'), (32, 82, 'ADDRESS'), (87, 99, 'PHONE'), (104, 133, 'EMAIL'), (695, 719, 'EMPLOYER'), (722, 736, 'GPE'), (738, 763, 'EMPLOYMENT'), (777, 796, 'DATE'), (804, 863, 'SKILLS'), (870, 909, 'SKILLS'), (913, 957, 'SKILLS'), (1134, 1159, 'SKILLS'), (1221, 1236, 'SKILLS'), (1294, 1321, 'SKILLS'), (1716, 1730, 'GPE'), (1695, 1709, 'EMPLOYER'), (1732, 1768, 'EMPLOYMENT'), (1769, 1794, 'DATE'), (1998, 2082, 'SKILLS'), (2336, 2383, 'SKILLS'), (2146, 2221, 'SKILLS'), (2440, 2459, 'SKILLS'), (2479, 2498, 'SKILLS'), (2516, 2519, 'SKILLS'), (2524, 2541, 'SKILLS'), (2600, 2617, 'EMPLOYER'), (2620, 2630, 'GPE'), (2633, 2653, 'EMPLOYMENT'), (2654, 2677, 'GPE'), (2679, 2703, 'DATE'), (2709, 2742, 'SKILLS'), (2894, 2951, 'SKILLS'), (3108, 3131, 'SKILLS'), (3407, 3432, 'SKILLS'), (3620, 3653, 'SKILLS'), (3657, 3726, 'SKILLS'), (3734, 3817, 'SKILLS'), (3819, 3901, 'SKILLS'), (3907, 3940, 'SKILLS'), (4125, 4142, 'EMPLOYER'), (4145, 4155, 'GPE'), (4159, 4177, 'EMPLOYMENT'), (4180, 4208, 'DATE'), (4386, 4407, 'SKILLS'), (4212, 4254, 'SKILLS'), (4431, 4463, 'SKILLS'), (4465, 4488, 'SKILLS'), (4525, 4552, 'SKILLS'), (4804, 4827, 'SKILLS'), (5017, 5048, 'SKILLS'), (5103, 5124, 'SKILLS'), (5237, 5261, 'EMPLOYER'), (5263, 5273, 'GPE'), (5285, 5293, 'EMPLOYMENT'), (5295, 5319, 'DATE'), (5325, 5367, 'SKILLS'), (5437, 5462, 'SKILLS'), (5566, 5588, 'SKILLS'), (5851, 5880, 'SKILLS'), (5881, 5899, 'SKILLS'), (6223, 6239, 'EMPLOYER'), (6240, 6252, 'GPE'), (6266, 6274, 'EMPLOYMENT'), (6276, 6300, 'DATE'), (6305, 6347, 'SKILLS'), (6477, 6520, 'SKILLS'), (6603, 6622, 'SKILLS'), (6779, 6787, 'EMPLOYER'), (6790, 6801, 'GPE'), (6805, 6831, 'EMPLOYMENT'), (6835, 6860, 'DATE'), (6866, 6880, 'SKILLS'), (6881, 6903, 'SKILLS'), (6966, 7006, 'SKILLS'), (7247, 7279, 'SKILLS'), (7423, 7447, 'INSTITUTION'), (7448, 7454, 'GPE'), (7456, 7496, 'EDUCATION'), (7498, 7512, 'DATE'), (7518, 7537, 'INSTITUTION'), (7539, 7549, 'GPE'), (7552, 7573, 'EDUCATION'), (7630, 7652, 'DATE'), (7657, 7681, 'INSTITUTION'), (7684, 7694, 'GPE'), (7697, 7717, 'EDUCATION'), (7719, 7748, 'DATE'), (7781, 7798, 'ACCOMPLISHMENTS'), (368, 419, 'SKILLS')]}), ([[8, 24, 'PERSON'], [28, 44, 'PERSON'], [79, 91, 'PHONE'], [101, 127, 'EMAIL'], [139, 182, 'ADDRESS'], [197, 206, 'SKILLS'], [216, 251, 'SKILLS'], [302, 348, 'SKILLS'], [385, 408, 'COMPUTING_SKILLS'], [418, 430, 'COMPUTING_SKILLS'], [483, 502, 'EMPLOYER'], [516, 527, 'DATE'], [530, 550, 'EMPLOYMENT'], [569, 602, 'SKILLS'], [683, 693, 'SKILLS'], [698, 712, 'SKILLS'], [717, 745, 'SKILLS'], [749, 767, 'SKILLS'], [771, 801, 'SKILLS'], [805, 833, 'SKILLS'], [934, 963, 'EMPLOYER'], [964, 976, 'DATE'], [978, 1004, 'EMPLOYMENT'], [1023, 1055, 'SKILLS'], [1083, 1105, 'SKILLS'], [1130, 1159, 'SKILLS'], [1164, 1192, 'SKILLS'], [1228, 1261, 'SKILLS'], [1266, 1285, 'SKILLS'], [1289, 1319, 'SKILLS'], [1323, 1351, 'SKILLS'], [1367, 1391, 'SKILLS'], [1428, 1444, 'PERSON'], [1480, 1496, 'PERSON'], [1514, 1531, 'EMPLOYER'], [1532, 1543, 'DATE'], [1546, 1560, 'EMPLOYMENT'], [1579, 1586, 'SKILLS'], [1587, 1604, 'SKILLS'], [1609, 1632, 'SKILLS'], [1742, 1770, 'SKILLS'], [1774, 1793, 'SKILLS'], [1797, 1827, 'SKILLS'], [1831, 1852, 'SKILLS'], [1856, 1889, 'COMPUTING_SKILLS'], [1936, 1942, 'EMPLOYER'], [1943, 1951, 'GPE'], [1952, 1963, 'DATE'], [1966, 1990, 'EMPLOYMENT'], [2009, 2014, 'SKILLS'], [2016, 2032, 'SKILLS'], [2037, 2060, 'SKILLS'], [2125, 2135, 'SKILLS'], [2205, 2216, 'SKILLS'], [2220, 2239, 'SKILLS'], [2243, 2273, 'SKILLS'], [2327, 2348, 'SKILLS'], [2368, 2385, 'COMPUTING_SKILLS'], [2414, 2428, 'COMPUTING_SKILLS'], [2467, 2473, 'EMPLOYER'], [2474, 2485, 'DATE'], [2458, 2466, 'GPE'], [2488, 2503, 'EMPLOYMENT'], [2518, 2524, 'SKILLS'], [2526, 2542, 'SKILLS'], [2547, 2570, 'SKILLS'], [2633, 2649, 'SKILLS'], [2671, 2682, 'SKILLS'], [2686, 2705, 'SKILLS'], [2708, 2725, 'PERSON'], [2751, 2767, 'PERSON'], [2783, 2790, 'COMPUTING_SKILLS'], [2797, 2814, 'COMPUTING_SKILLS'], [2819, 2829, 'COMPUTING_SKILLS'], [2851, 2882, 'SKILLS'], [2895, 2908, 'SKILLS'], [2912, 2933, 'SKILLS'], [2961, 2985, 'EDUCATION'], [2989, 3020, 'EDUCATION'], [3024, 3064, 'EDUCATION'], [3069, 3098, 'EDUCATION'], [3103, 3124, 'EDUCATION'], [3128, 3143, 'ACCOMPLISHMENTS'], [3144, 3154, 'GPE'], [3196, 3238, 'COMPUTING_SKILLS']], {'entities': [(8, 24, 'PERSON'), (28, 44, 'PERSON'), (79, 91, 'PHONE'), (101, 127, 'EMAIL'), (139, 182, 'ADDRESS'), (197, 206, 'SKILLS'), (216, 251, 'SKILLS'), (302, 348, 'SKILLS'), (385, 408, 'COMPUTING_SKILLS'), (418, 430, 'COMPUTING_SKILLS'), (483, 502, 'EMPLOYER'), (516, 527, 'DATE'), (530, 550, 'EMPLOYMENT'), (569, 602, 'SKILLS'), (683, 693, 'SKILLS'), (698, 712, 'SKILLS'), (717, 745, 'SKILLS'), (749, 767, 'SKILLS'), (771, 801, 'SKILLS'), (805, 833, 'SKILLS'), (934, 963, 'EMPLOYER'), (964, 976, 'DATE'), (978, 1004, 'EMPLOYMENT'), (1023, 1055, 'SKILLS'), (1083, 1105, 'SKILLS'), (1130, 1159, 'SKILLS'), (1164, 1192, 'SKILLS'), (1228, 1261, 'SKILLS'), (1266, 1285, 'SKILLS'), (1289, 1319, 'SKILLS'), (1323, 1351, 'SKILLS'), (1367, 1391, 'SKILLS'), (1428, 1444, 'PERSON'), (1480, 1496, 'PERSON'), (1514, 1531, 'EMPLOYER'), (1532, 1543, 'DATE'), (1546, 1560, 'EMPLOYMENT'), (1579, 1586, 'SKILLS'), (1587, 1604, 'SKILLS'), (1609, 1632, 'SKILLS'), (1742, 1770, 'SKILLS'), (1774, 1793, 'SKILLS'), (1797, 1827, 'SKILLS'), (1831, 1852, 'SKILLS'), (1856, 1889, 'COMPUTING_SKILLS'), (1936, 1942, 'EMPLOYER'), (1943, 1951, 'GPE'), (1952, 1963, 'DATE'), (1966, 1990, 'EMPLOYMENT'), (2009, 2014, 'SKILLS'), (2016, 2032, 'SKILLS'), (2037, 2060, 'SKILLS'), (2125, 2135, 'SKILLS'), (2205, 2216, 'SKILLS'), (2220, 2239, 'SKILLS'), (2243, 2273, 'SKILLS'), (2327, 2348, 'SKILLS'), (2368, 2385, 'COMPUTING_SKILLS'), (2414, 2428, 'COMPUTING_SKILLS'), (2467, 2473, 'EMPLOYER'), (2474, 2485, 'DATE'), (2458, 2466, 'GPE'), (2488, 2503, 'EMPLOYMENT'), (2518, 2524, 'SKILLS'), (2526, 2542, 'SKILLS'), (2547, 2570, 'SKILLS'), (2633, 2649, 'SKILLS'), (2671, 2682, 'SKILLS'), (2686, 2705, 'SKILLS'), (2708, 2725, 'PERSON'), (2751, 2767, 'PERSON'), (2783, 2790, 'COMPUTING_SKILLS'), (2797, 2814, 'COMPUTING_SKILLS'), (2819, 2829, 'COMPUTING_SKILLS'), (2851, 2882, 'SKILLS'), (2895, 2908, 'SKILLS'), (2912, 2933, 'SKILLS'), (2961, 2985, 'EDUCATION'), (2989, 3020, 'EDUCATION'), (3024, 3064, 'EDUCATION'), (3069, 3098, 'EDUCATION'), (3103, 3124, 'EDUCATION'), (3128, 3143, 'ACCOMPLISHMENTS'), (3144, 3154, 'GPE'), (3196, 3238, 'COMPUTING_SKILLS')]}), ([[632, 670, 'EMPLOYMENT'], [670, 690, 'DATE'], [845, 854, 'SKILLS'], [731, 740, 'SKILLS'], [782, 791, 'SKILLS'], [796, 806, 'SKILLS'], [877, 897, 'EMPLOYMENT'], [898, 913, 'DATE'], [998, 1004, 'GPE'], [1006, 1014, 'GPE'], [1016, 1025, 'GPE'], [1028, 1035, 'SKILLS'], [1040, 1048, 'SKILLS'], [1149, 1165, 'EMPLOYMENT'], [1183, 1195, 'EMPLOYER'], [1197, 1206, 'DATE'], [1210, 1226, 'SKILLS'], [1326, 1342, 'EMPLOYMENT'], [1360, 1378, 'EMPLOYER'], [1381, 1390, 'DATE'], [1394, 1410, 'SKILLS'], [1412, 1426, 'SKILLS'], [1453, 1463, 'SKILLS'], [1464, 1478, 'SKILLS'], [1688, 1720, 'EDUCATION'], [1721, 1740, 'INSTITUTION'], [1742, 1752, 'GPE'], [1895, 1901, 'GPE'], [1903, 1912, 'GPE'], [1917, 1921, 'DATE'], [2021, 2056, 'ACCOMPLISHMENTS'], [2057, 2062, 'GPE'], [2064, 2069, 'GPE'], [2073, 2077, 'DATE'], [1761, 1805, 'ACCOMPLISHMENTS'], [1755, 1760, 'DATE'], [1807, 1826, 'INSTITUTION'], [1827, 1838, 'GPE'], [1841, 1846, 'DATE'], [1859, 1894, 'ACCOMPLISHMENTS'], [2171, 2190, 'EDUCATION'], [2134, 2142, 'GPE'], [2147, 2151, 'DATE'], [2192, 2198, 'GPE'], [43, 59, 'PERSON'], [72, 110, 'ADDRESS'], [122, 157, 'EMAIL'], [168, 180, 'PHONE'], [2078, 2115, 'ACCOMPLISHMENTS'], [372, 403, 'SKILLS'], [408, 419, 'SKILLS'], [1168, 1178, 'SKILLS']], {'entities': [(632, 670, 'EMPLOYMENT'), (670, 690, 'DATE'), (845, 854, 'SKILLS'), (731, 740, 'SKILLS'), (782, 791, 'SKILLS'), (796, 806, 'SKILLS'), (877, 897, 'EMPLOYMENT'), (898, 913, 'DATE'), (998, 1004, 'GPE'), (1006, 1014, 'GPE'), (1016, 1025, 'GPE'), (1028, 1035, 'SKILLS'), (1040, 1048, 'SKILLS'), (1149, 1165, 'EMPLOYMENT'), (1183, 1195, 'EMPLOYER'), (1197, 1206, 'DATE'), (1210, 1226, 'SKILLS'), (1326, 1342, 'EMPLOYMENT'), (1360, 1378, 'EMPLOYER'), (1381, 1390, 'DATE'), (1394, 1410, 'SKILLS'), (1412, 1426, 'SKILLS'), (1453, 1463, 'SKILLS'), (1464, 1478, 'SKILLS'), (1688, 1720, 'EDUCATION'), (1721, 1740, 'INSTITUTION'), (1742, 1752, 'GPE'), (1895, 1901, 'GPE'), (1903, 1912, 'GPE'), (1917, 1921, 'DATE'), (2021, 2056, 'ACCOMPLISHMENTS'), (2057, 2062, 'GPE'), (2064, 2069, 'GPE'), (2073, 2077, 'DATE'), (1761, 1805, 'ACCOMPLISHMENTS'), (1755, 1760, 'DATE'), (1807, 1826, 'INSTITUTION'), (1827, 1838, 'GPE'), (1841, 1846, 'DATE'), (1859, 1894, 'ACCOMPLISHMENTS'), (2171, 2190, 'EDUCATION'), (2134, 2142, 'GPE'), (2147, 2151, 'DATE'), (2192, 2198, 'GPE'), (43, 59, 'PERSON'), (72, 110, 'ADDRESS'), (122, 157, 'EMAIL'), (168, 180, 'PHONE'), (2078, 2115, 'ACCOMPLISHMENTS'), (372, 403, 'SKILLS'), (408, 419, 'SKILLS'), (1168, 1178, 'SKILLS')]}), ([[25, 40, 'ADDRESS'], [45, 57, 'PHONE'], [61, 82, 'EMAIL'], [1373, 1386, 'PERSON'], [1396, 1407, 'ACCOMPLISHMENTS'], [1458, 1485, 'EMPLOYER'], [1488, 1500, 'DATE'], [1503, 1537, 'EMPLOYMENT'], [1543, 1621, 'SKILLS'], [1764, 1779, 'SKILLS'], [1839, 1860, 'SKILLS'], [1864, 1879, 'SKILLS'], [1892, 1918, 'SKILLS'], [1950, 1967, 'EMPLOYER'], [1971, 1980, 'DATE'], [1983, 1996, 'EMPLOYMENT'], [2001, 2017, 'EMPLOYMENT'], [2195, 2218, 'SKILLS'], [2221, 2254, 'EMPLOYER'], [2255, 2264, 'DATE'], [2267, 2291, 'EMPLOYMENT'], [2331, 2386, 'SKILLS'], [2391, 2425, 'SKILLS'], [2430, 2471, 'SKILLS'], [2476, 2505, 'SKILLS'], [2510, 2544, 'SKILLS'], [2549, 2582, 'SKILLS'], [2604, 2644, 'SKILLS'], [2646, 2677, 'SKILLS'], [2680, 2700, 'EMPLOYER'], [2703, 2712, 'DATE'], [2715, 2751, 'SKILLS'], [2756, 2776, 'SKILLS'], [2821, 2852, 'SKILLS'], [2857, 2896, 'SKILLS'], [2902, 2911, 'SKILLS'], [2913, 2923, 'SKILLS'], [2928, 2957, 'SKILLS'], [4147, 4189, 'SKILLS'], [4193, 4237, 'SKILLS'], [3762, 3796, 'SKILLS'], [3801, 3821, 'SKILLS'], [550, 573, 'SKILLS'], [491, 545, 'SKILLS'], [600, 628, 'SKILLS'], [686, 715, 'SKILLS'], [633, 659, 'SKILLS'], [720, 743, 'SKILLS'], [749, 777, 'SKILLS'], [934, 976, 'SKILLS'], [987, 1008, 'SKILLS'], [1208, 1253, 'SKILLS'], [1328, 1372, 'SKILLS']], {'entities': [(25, 40, 'ADDRESS'), (45, 57, 'PHONE'), (61, 82, 'EMAIL'), (1373, 1386, 'PERSON'), (1396, 1407, 'ACCOMPLISHMENTS'), (1458, 1485, 'EMPLOYER'), (1488, 1500, 'DATE'), (1503, 1537, 'EMPLOYMENT'), (1543, 1621, 'SKILLS'), (1764, 1779, 'SKILLS'), (1839, 1860, 'SKILLS'), (1864, 1879, 'SKILLS'), (1892, 1918, 'SKILLS'), (1950, 1967, 'EMPLOYER'), (1971, 1980, 'DATE'), (1983, 1996, 'EMPLOYMENT'), (2001, 2017, 'EMPLOYMENT'), (2195, 2218, 'SKILLS'), (2221, 2254, 'EMPLOYER'), (2255, 2264, 'DATE'), (2267, 2291, 'EMPLOYMENT'), (2331, 2386, 'SKILLS'), (2391, 2425, 'SKILLS'), (2430, 2471, 'SKILLS'), (2476, 2505, 'SKILLS'), (2510, 2544, 'SKILLS'), (2549, 2582, 'SKILLS'), (2604, 2644, 'SKILLS'), (2646, 2677, 'SKILLS'), (2680, 2700, 'EMPLOYER'), (2703, 2712, 'DATE'), (2715, 2751, 'SKILLS'), (2756, 2776, 'SKILLS'), (2821, 2852, 'SKILLS'), (2857, 2896, 'SKILLS'), (2902, 2911, 'SKILLS'), (2913, 2923, 'SKILLS'), (2928, 2957, 'SKILLS'), (4147, 4189, 'SKILLS'), (4193, 4237, 'SKILLS'), (3762, 3796, 'SKILLS'), (3801, 3821, 'SKILLS'), (550, 573, 'SKILLS'), (491, 545, 'SKILLS'), (600, 628, 'SKILLS'), (686, 715, 'SKILLS'), (633, 659, 'SKILLS'), (720, 743, 'SKILLS'), (749, 777, 'SKILLS'), (934, 976, 'SKILLS'), (987, 1008, 'SKILLS'), (1208, 1253, 'SKILLS'), (1328, 1372, 'SKILLS')]}), ([[32, 67, 'PERSON'], [522, 538, 'EMPLOYER'], [543, 576, 'EMPLOYMENT'], [596, 611, 'DATE'], [774, 799, 'SKILLS'], [800, 817, 'SKILLS'], [1251, 1261, 'SKILLS'], [1265, 1284, 'SKILLS'], [1472, 1479, 'EMPLOYER'], [1488, 1504, 'EMPLOYMENT'], [1506, 1531, 'DATE'], [1587, 1593, 'GPE'], [1595, 1600, 'GPE'], [1856, 1875, 'SKILLS'], [1945, 1986, 'EDUCATION'], [1988, 2032, 'INSTITUTION'], [2033, 2047, 'GPE'], [2049, 2055, 'GPE'], [2147, 2161, 'DATE'], [2063, 2088, 'INSTITUTION'], [2057, 2062, 'GPE'], [2089, 2096, 'GPE'], [2096, 2102, 'GPE'], [2317, 2341, 'INSTITUTION'], [2343, 2353, 'GPE'], [2355, 2361, 'GPE'], [2363, 2368, 'GPE'], [2509, 2560, 'ACCOMPLISHMENTS'], [2563, 2569, 'GPE'], [2571, 2577, 'GPE'], [2577, 2612, 'ACCOMPLISHMENTS'], [2651, 2683, 'ACCOMPLISHMENTS'], [2684, 2695, 'GPE'], [2700, 2706, 'GPE'], [2708, 2713, 'GPE'], [2724, 2759, 'ACCOMPLISHMENTS'], [2761, 2766, 'GPE'], [2777, 2786, 'DATE'], [2787, 2833, 'EDUCATION'], [2841, 2846, 'GPE'], [2965, 2972, 'COMPUTING_SKILLS'], [2975, 2984, 'COMPUTING_SKILLS'], [2986, 2999, 'COMPUTING_SKILLS'], [3001, 3006, 'COMPUTING_SKILLS'], [3008, 3017, 'COMPUTING_SKILLS'], [3019, 3023, 'COMPUTING_SKILLS'], [3303, 3308, 'ACCOMPLISHMENTS'], [3310, 3316, 'ACCOMPLISHMENTS'], [3318, 3327, 'ACCOMPLISHMENTS'], [3331, 3337, 'ACCOMPLISHMENTS'], [3417, 3424, 'ACCOMPLISHMENTS'], [3426, 3435, 'ACCOMPLISHMENTS']], {'entities': [(32, 67, 'PERSON'), (522, 538, 'EMPLOYER'), (543, 576, 'EMPLOYMENT'), (596, 611, 'DATE'), (774, 799, 'SKILLS'), (800, 817, 'SKILLS'), (1251, 1261, 'SKILLS'), (1265, 1284, 'SKILLS'), (1472, 1479, 'EMPLOYER'), (1488, 1504, 'EMPLOYMENT'), (1506, 1531, 'DATE'), (1587, 1593, 'GPE'), (1595, 1600, 'GPE'), (1856, 1875, 'SKILLS'), (1945, 1986, 'EDUCATION'), (1988, 2032, 'INSTITUTION'), (2033, 2047, 'GPE'), (2049, 2055, 'GPE'), (2147, 2161, 'DATE'), (2063, 2088, 'INSTITUTION'), (2057, 2062, 'GPE'), (2089, 2096, 'GPE'), (2096, 2102, 'GPE'), (2317, 2341, 'INSTITUTION'), (2343, 2353, 'GPE'), (2355, 2361, 'GPE'), (2363, 2368, 'GPE'), (2509, 2560, 'ACCOMPLISHMENTS'), (2563, 2569, 'GPE'), (2571, 2577, 'GPE'), (2577, 2612, 'ACCOMPLISHMENTS'), (2651, 2683, 'ACCOMPLISHMENTS'), (2684, 2695, 'GPE'), (2700, 2706, 'GPE'), (2708, 2713, 'GPE'), (2724, 2759, 'ACCOMPLISHMENTS'), (2761, 2766, 'GPE'), (2777, 2786, 'DATE'), (2787, 2833, 'EDUCATION'), (2841, 2846, 'GPE'), (2965, 2972, 'COMPUTING_SKILLS'), (2975, 2984, 'COMPUTING_SKILLS'), (2986, 2999, 'COMPUTING_SKILLS'), (3001, 3006, 'COMPUTING_SKILLS'), (3008, 3017, 'COMPUTING_SKILLS'), (3019, 3023, 'COMPUTING_SKILLS'), (3303, 3308, 'ACCOMPLISHMENTS'), (3310, 3316, 'ACCOMPLISHMENTS'), (3318, 3327, 'ACCOMPLISHMENTS'), (3331, 3337, 'ACCOMPLISHMENTS'), (3417, 3424, 'ACCOMPLISHMENTS'), (3426, 3435, 'ACCOMPLISHMENTS')]})]\n"
     ]
    }
   ],
   "source": [
    "print(TRAINING_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f2b08090",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "labeled_data = []\n",
    "#ith open(r\"/home/chris/reesby/reverse_Malih/Doccano/all.jsonl\", \"r\") as read_file:\n",
    "with open(r\"/home/chris/reesby/reverse_Malih/python/Resume-Parser-master/Entity_Recognition_in_Resumes.json\", \"r\") as read_file:\n",
    "    for line in read_file:\n",
    "        data = json.loads(line)\n",
    "        labeled_data.append(data)\n",
    "#print(labeled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "24d6fa58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': ['Companies worked at'], 'points': [{'start': 1749, 'end': 1754, 'text': 'Oracle'}]}\n",
      "{'label': ['Companies worked at'], 'points': [{'start': 1696, 'end': 1701, 'text': 'Oracle'}]}\n",
      "{'label': ['Companies worked at'], 'points': [{'start': 1417, 'end': 1422, 'text': 'Oracle'}]}\n",
      "{'label': ['Skills'], 'points': [{'start': 1356, 'end': 1792, 'text': 'Languages: Core Java, Go Lang, Data Structures & Algorithms, Oracle\\nPL-SQL programming, Sales Force with APEX.\\nTools: RADTool, Jdeveloper, NetBeans, Eclipse, SQL developer,\\nPL/SQL Developer, WinSCP, Putty\\nWeb Technologies: JavaScript, XML, HTML, Webservice\\n\\nOperating Systems: Linux, Windows\\nVersion control system SVN & Git-Hub\\nDatabases: Oracle\\nMiddleware: Web logic, OC4J\\nProduct FLEXCUBE: Oracle FLEXCUBE Versions 10.x, 11.x and 12.x'}]}\n",
      "{'label': ['Companies worked at'], 'points': [{'start': 1209, 'end': 1214, 'text': 'Oracle'}]}\n",
      "{'label': ['Skills'], 'points': [{'start': 1136, 'end': 1247, 'text': 'APEX. (Less than 1 year), Data Structures (3 years), FLEXCUBE (5 years), Oracle (5 years),\\nAlgorithms (3 years)\\n'}]}\n",
      "{'label': ['Graduation Year'], 'points': [{'start': 928, 'end': 931, 'text': '2012'}]}\n",
      "{'label': ['College Name'], 'points': [{'start': 858, 'end': 888, 'text': 'Adithya Institute of Technology'}]}\n",
      "{'label': ['Degree'], 'points': [{'start': 821, 'end': 855, 'text': 'B.E in Computer Science Engineering'}]}\n",
      "{'label': ['Graduation Year'], 'points': [{'start': 787, 'end': 790, 'text': '2012'}]}\n",
      "{'label': ['Companies worked at'], 'points': [{'start': 744, 'end': 749, 'text': 'Oracle'}]}\n",
      "{'label': ['Designation'], 'points': [{'start': 722, 'end': 741, 'text': 'Associate Consultant'}]}\n",
      "{'label': ['Companies worked at'], 'points': [{'start': 658, 'end': 663, 'text': 'Oracle'}]}\n",
      "{'label': ['Designation'], 'points': [{'start': 640, 'end': 655, 'text': 'Staff Consultant'}]}\n",
      "{'label': ['Companies worked at'], 'points': [{'start': 574, 'end': 579, 'text': 'Oracle'}]}\n",
      "{'label': ['Designation'], 'points': [{'start': 555, 'end': 572, 'text': 'Senior Consultant\\n'}]}\n",
      "{'label': ['Companies worked at'], 'points': [{'start': 470, 'end': 492, 'text': 'Cloud Lending Solutions'}]}\n",
      "{'label': ['Designation'], 'points': [{'start': 444, 'end': 468, 'text': 'Senior Software Engineer\\n'}]}\n",
      "{'label': ['Companies worked at'], 'points': [{'start': 308, 'end': 313, 'text': 'Oracle'}]}\n",
      "{'label': ['Companies worked at'], 'points': [{'start': 234, 'end': 239, 'text': 'Oracle'}]}\n",
      "{'label': ['Companies worked at'], 'points': [{'start': 175, 'end': 197, 'text': 'Cloud Lending Solutions'}]}\n",
      "{'label': ['Email Address'], 'points': [{'start': 93, 'end': 136, 'text': 'indeed.com/r/Govardhana-K/\\nb2de315d95905b68\\n'}]}\n",
      "{'label': ['Location'], 'points': [{'start': 39, 'end': 47, 'text': 'Bengaluru'}]}\n",
      "{'label': ['Designation'], 'points': [{'start': 13, 'end': 37, 'text': 'Senior Software Engineer\\n'}]}\n",
      "{'label': ['Name'], 'points': [{'start': 0, 'end': 11, 'text': 'Govardhana K'}]}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-115-33dad1feeca4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m#entities.append((e[0], e[1],e[2]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mspacy_entry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"entities\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mTRAINING_DATA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspacy_entry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'label'"
     ]
    }
   ],
   "source": [
    "TRAINING_DATA = []\n",
    "for entry in labeled_data:\n",
    "    \n",
    "    entities = []\n",
    "    #print(entry)\n",
    "    #for key in entry:\n",
    "    #    print(key)\n",
    "    for e in entry[\"annotation\"]:\n",
    "        print(e)\n",
    "        #entities.append((e[0], e[1],e[2]))\n",
    "    spacy_entry = (entry['label'], {\"entities\": entities})\n",
    "    TRAINING_DATA.append(spacy_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c23fe30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb8c999",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6163d75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "817787fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chris/anaconda3/lib/python3.8/site-packages/spacy/language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \" donna harvey cv             page 1 of 3          ...\" with entities \"[(97, 110, 'PERSON'), (113, 126, 'GPE'), (128, 131...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities (with BILUO tag '-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "/home/chris/anaconda3/lib/python3.8/site-packages/spacy/language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"    personal details    manly west 4178    0435 ...\" with entities \"[(25, 40, 'ADDRESS'), (45, 57, 'PHONE'), (61, 82, ...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities (with BILUO tag '-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "[E024] Could not find an optimal move to supervise the parser. Usually, this means that the model can't be updated in a way that's valid and satisfies the correct annotations specified in the GoldParse. For example, are all labels added to the model? If you're training a named entity recognizer, also make sure that none of your annotated entity spans have leading or trailing whitespace or punctuation. You can also use the experimental `debug-data` command to validate your JSON-formatted training data. For details, run:\npython -m spacy debug-data --help",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-bbd3cb736276>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mannotations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mentities\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentities\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# Update the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/spacy/language.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, docs, golds, drop, sgd, losses, component_cfg)\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomponent_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"drop\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m             \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgolds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdW\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m                 \u001b[0msgd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.Parser.update\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.Parser._init_gold_batch\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mtransition_system.pyx\u001b[0m in \u001b[0;36mspacy.syntax.transition_system.TransitionSystem.get_oracle_sequence\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mtransition_system.pyx\u001b[0m in \u001b[0;36mspacy.syntax.transition_system.TransitionSystem.set_costs\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: [E024] Could not find an optimal move to supervise the parser. Usually, this means that the model can't be updated in a way that's valid and satisfies the correct annotations specified in the GoldParse. For example, are all labels added to the model? If you're training a named entity recognizer, also make sure that none of your annotated entity spans have leading or trailing whitespace or punctuation. You can also use the experimental `debug-data` command to validate your JSON-formatted training data. For details, run:\npython -m spacy debug-data --help"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import random\n",
    "import json\n",
    "nlp = spacy.blank(\"en\")  #spacy.load('resume_ner')#\n",
    "#nlp = spacy.load('en_core_web_lg')\n",
    "ner = nlp.create_pipe(\"ner\")\n",
    "\n",
    "ner.add_label(\"RESUME\")\n",
    "ner.add_label('PERSON')\n",
    "ner.add_label('ADDRESS')\n",
    "ner.add_label('INSTITUTION')\n",
    "ner.add_label('EDUCATION')\n",
    "ner.add_label('DATE')\n",
    "ner.add_label('EMPLOYMENT')\n",
    "ner.add_label('SKILLS')\n",
    "ner.add_label('MISC')\n",
    "ner.add_label('LINKEDIN')\n",
    "ner.add_label('PROFILE')\n",
    "ner.add_label('PHONE')\n",
    "ner.add_label('EMAIL')\n",
    "ner.add_label('EMPLOYER')\n",
    "ner.add_label('COMPUTING_SKILLS')\n",
    "ner.add_label('ACCOMPLISHMENTS')\n",
    "ner.add_label('REFERENCES')\n",
    "ner.add_label('GPE')\n",
    "\n",
    "nlp.add_pipe(ner)\n",
    "# Start the training\n",
    "nlp.begin_training()\n",
    "# Loop for 40 iterations\n",
    "for itn in range(40):\n",
    "    # Shuffle the training data\n",
    "    random.shuffle(TRAINING_DATA)\n",
    "    losses = {}\n",
    "# Batch the examples and iterate over them\n",
    "    for batch in spacy.util.minibatch(TRAINING_DATA, size=2):\n",
    "        texts = [text for text, entities in batch]\n",
    "        annotations = [entities for text, entities in batch]\n",
    "# Update the model\n",
    "        nlp.update(texts, annotations, losses=losses, drop=0.3)\n",
    "    print(losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b1b8ceac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_spacy(data,iterations):\n",
    "    nlp = spacy.blank('en')  # create blank Language class\n",
    "    # create the built-in pipeline components and add them to the pipeline\n",
    "    # nlp.create_pipe works for built-ins that are registered with spaCy\n",
    "    if 'ner' not in nlp.pipe_names:\n",
    "        ner = nlp.create_pipe('ner')\n",
    "        nlp.add_pipe(ner, last=True) \n",
    "\n",
    "    #add labels\n",
    "    for _, annotations in TRAINING_DATA:\n",
    "          for ent in annotations.get('entities'):\n",
    "            ner.add_label(ent[2])\n",
    "          \n",
    "    # get names of other pipes to disable them during training\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
    "    with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "        optimizer = nlp.begin_training()\n",
    "        for itn in range(iterations):\n",
    "            print(\"Starting iteration \" + str(itn))\n",
    "            random.shuffle(TRAINING_DATA)\n",
    "            losses = {}\n",
    "            for text, annotations in TRAINING_DATA:\n",
    "                try:\n",
    "                    nlp.update(\n",
    "                        [text],  \n",
    "                        [annotations],  \n",
    "                        drop=0.3,  \n",
    "                        sgd=optimizer,  \n",
    "                        losses=losses)\n",
    "                except Exception as error:\n",
    "                    print(error)\n",
    "                    continue\n",
    "            print(losses)\n",
    "    return nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7bab51d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iteration 0\n",
      "{}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x7f5aa586bdc0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_spacy(TRAINING_DATA,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fef104b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ACCOMPLISHMENTS',\n",
       " 'ADDRESS',\n",
       " 'COMPUTING_SKILLS',\n",
       " 'DATE',\n",
       " 'EDUCATION',\n",
       " 'EMAIL',\n",
       " 'EMPLOYER',\n",
       " 'EMPLOYMENT',\n",
       " 'GPE',\n",
       " 'INSTITUTION',\n",
       " 'LINKEDIN',\n",
       " 'MISC',\n",
       " 'PERSON',\n",
       " 'PHONE',\n",
       " 'PROFILE',\n",
       " 'REFERENCES',\n",
       " 'RESUME',\n",
       " 'SKILLS')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c5f421eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "#Converting JSON1 files to Spacy tuples format\n",
    "def convert_doccano_to_spacy(filepath):\n",
    "    with open(filepath, 'rb') as fp:\n",
    "        data = fp.readlines()\n",
    "        training_data = []\n",
    "        for record in data:\n",
    "            entities = []\n",
    "            read_record = json.loads(record)\n",
    "            text = read_record['data']\n",
    "            entities_record = read_record['label']\n",
    "            for start, end, label in entities_record:\n",
    "                entities.append((start, end, label))\n",
    "                training_data.append((text, {'entities': entities}))\n",
    "    return training_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "da85b38c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAINING_DATA = convert_doccano_to_spacy(\"/home/chris/reesby/reverse_Malih/Doccano/all.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b82d4122",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINING_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e742d903",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E024] Could not find an optimal move to supervise the parser. Usually, this means that the model can't be updated in a way that's valid and satisfies the correct annotations specified in the GoldParse. For example, are all labels added to the model? If you're training a named entity recognizer, also make sure that none of your annotated entity spans have leading or trailing whitespace or punctuation. You can also use the experimental `debug-data` command to validate your JSON-formatted training data. For details, run:\npython -m spacy debug-data --help",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-1d3e11b98c8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mannotations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mentities\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentities\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Update the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/spacy/language.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, docs, golds, drop, sgd, losses, component_cfg)\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomponent_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"drop\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m             \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgolds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdW\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m                 \u001b[0msgd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.Parser.update\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.Parser._init_gold_batch\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mtransition_system.pyx\u001b[0m in \u001b[0;36mspacy.syntax.transition_system.TransitionSystem.get_oracle_sequence\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mtransition_system.pyx\u001b[0m in \u001b[0;36mspacy.syntax.transition_system.TransitionSystem.set_costs\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: [E024] Could not find an optimal move to supervise the parser. Usually, this means that the model can't be updated in a way that's valid and satisfies the correct annotations specified in the GoldParse. For example, are all labels added to the model? If you're training a named entity recognizer, also make sure that none of your annotated entity spans have leading or trailing whitespace or punctuation. You can also use the experimental `debug-data` command to validate your JSON-formatted training data. For details, run:\npython -m spacy debug-data --help"
     ]
    }
   ],
   "source": [
    "for itn in range(40):\n",
    "    # Shuffle the training data\n",
    "    random.shuffle(TRAINING_DATA)\n",
    "    losses = {}\n",
    "# Batch the examples and iterate over them\n",
    "    for batch in spacy.util.minibatch(TRAINING_DATA, size=2):\n",
    "        texts = [text for text, entities in batch]\n",
    "        annotations = [entities for text, entities in batch]\n",
    "# Update the model\n",
    "        nlp.update(texts, annotations, losses=losses, drop=0.2)\n",
    "    print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92edef8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner = nlp.get_pipe(\"ner\")\n",
    "ner.add_label(\"B-PERSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c8f9711d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'minibatch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-b20fb68045f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                 \u001b[0;31m# batch up the examples using spaCy's minibatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                 \u001b[0;31m#size=compounding(2.0, batchsize, 1.005)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                                 \u001b[0mbatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminibatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAINING_DATA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m                                 \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                                         \u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'minibatch' is not defined"
     ]
    }
   ],
   "source": [
    "for itn in range(40):\n",
    "\t\t\t\trandom.shuffle(TRAINING_DATA)\n",
    "\t\t\t\tlosses = {}\n",
    "\t\t\t\t# batch up the examples using spaCy's minibatch\n",
    "\t\t\t\t#size=compounding(2.0, batchsize, 1.005)\n",
    "\t\t\t\tbatches = minibatch(TRAINING_DATA, 50) #size)\n",
    "\t\t\t\tfor batch in batches:\n",
    "\t\t\t\t\ttexts, annotations = zip(*batch)\n",
    "\t\t\t\t\tnlp.update(\n",
    "\t\t\t\t\t\ttexts,  # batch of texts\n",
    "\t\t\t\t\t\tannotations,  # batch of annotations\n",
    "\t\t\t\t\t\tdrop=dropout,  # dropout - make it harder to memorise data\n",
    "\t\t\t\t\t\tlosses=losses,\n",
    "\t\t\t\t\t)\n",
    "\t\t\t\tcount = itn + 1\n",
    "\t\t\t\tprint(\"Losses\", losses, \" Iteration: \", count, \" of \", n_iter, \" Fold: \" , input_file)\n",
    "\t\t\t\tsys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca07b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import generic wrappers\n",
    "from transformers import AutoModel, AutoTokenizer \n",
    "\n",
    "\n",
    "# Define the model repo\n",
    "model_name = \"manishiitg/resume-ner\" \n",
    "\n",
    "\n",
    "# Download pytorch model\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "# Transform input tokens \n",
    "inputs = tokenizer(peter_text[1:100], return_tensors=\"pt\")\n",
    "\n",
    "# Model apply\n",
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3657be5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4a700ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import logging\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from spacy.gold import GoldParse\n",
    "from spacy.scorer import Scorer\n",
    "\n",
    "\n",
    "def convert_data_to_spacy(JSON_FilePath):\n",
    "    try:\n",
    "        training_data = []\n",
    "        lines = []\n",
    "        with open(JSON_FilePath, \"r\", encoding=\"utf-8\") as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        for line in lines:\n",
    "            data = json.loads(line)\n",
    "            text = data[\"content\"]\n",
    "            entities = []\n",
    "            for annotation in data[\"annotation\"]:\n",
    "                # only a single point in text annotation.\n",
    "                point = annotation[\"points\"][0]\n",
    "                labels = annotation[\"label\"]\n",
    "                # handle both list of labels or a single label.\n",
    "                if not isinstance(labels, list):\n",
    "                    labels = [labels]\n",
    "\n",
    "                for label in labels:\n",
    "                    entities.append((point[\"start\"], point[\"end\"] + 1, label))\n",
    "\n",
    "            training_data.append((text, {\"entities\": entities}))\n",
    "\n",
    "        return training_data\n",
    "    except Exception as e:\n",
    "        logging.exception(\n",
    "            \"Unable to process \" + JSON_FilePath + \"\\n\" + \"error = \" + str(e)\n",
    "        )\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4033a9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TRAIN_DATA = convert_data_to_spacy('/home/chris/reesby/reverse_Malih/python/Resume-Parser-master/Entity_Recognition_in_Resumes.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3321866f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Unable to process /home/chris/reesby/reverse_Malih/Doccano/all.jsonl\n",
      "error = 'content'\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-116-26ce81338b98>\", line 21, in convert_data_to_spacy\n",
      "    text = data[\"content\"]\n",
      "KeyError: 'content'\n"
     ]
    }
   ],
   "source": [
    "TRAINING_DATA = convert_data_to_spacy(\"/home/chris/reesby/reverse_Malih/Doccano/all.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "1fd7f27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "\n",
    "def build_spacy_model(train, model):\n",
    "    num_iter = 100\n",
    "    if model is not None:\n",
    "        nlp = spacy.load(model)  # load existing spaCy model\n",
    "        print(\"Loaded model '%s'\" % model)\n",
    "    else:\n",
    "        nlp = spacy.blank(\"en\")  # create blank Language class\n",
    "        print(\"Created blank 'en' model\")\n",
    "\n",
    "    TRAIN_DATA = train\n",
    "    # create the built-in pipeline components and add them to the pipeline\n",
    "    # nlp.create_pipe works for built-ins that are registered with spaCy\n",
    "    if \"ner\" not in nlp.pipe_names:\n",
    "        ner = nlp.create_pipe(\"ner\")\n",
    "        nlp.add_pipe(ner, last=True)\n",
    "    else:\n",
    "        ner = nlp.get_pipe(\"ner\")\n",
    "\n",
    "    # add labels\n",
    "    for _, annotations in TRAIN_DATA:\n",
    "        for ent in annotations.get(\"entities\"):\n",
    "            \n",
    "            ner.add_label(ent[2])\n",
    "\n",
    "    # get names of other pipes to disable them during training\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n",
    "    with nlp.disable_pipes(*other_pipes), warnings.catch_warnings():  # only train NER\n",
    "        warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"spacy\")\n",
    "        if model is None:\n",
    "            optimizer = nlp.begin_training()\n",
    "        for itn in range(num_iter):\n",
    "            # train for 50 iteration\n",
    "            print(\"Starting iteration \" + str(itn))\n",
    "            random.shuffle(TRAIN_DATA)\n",
    "            losses = {}\n",
    "            for text, annotations in TRAIN_DATA:\n",
    "                try:\n",
    "                    nlp.update(\n",
    "                        [text],  # batch of texts\n",
    "                        [annotations],  # batch of annotations\n",
    "                        drop=0.2,  # dropout - make it harder to memorise data\n",
    "                        sgd=optimizer,  # callable to update weights\n",
    "                        losses=losses,\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "            print(losses)\n",
    "        #plt.scatter(itn, losses[\"ner\"])\n",
    "        #plt.ylabel(\"ner_loss\")\n",
    "        #plt.xlabel(\"Iterations\")\n",
    "        #plt.show()\n",
    "\n",
    "    nlp.to_disk(\"nlp_model\")\n",
    "    # plt.savefig(\"loss.png\")\n",
    "    return nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "7cafa9ea",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created blank 'en' model\n",
      "Starting iteration 0\n",
      "{'ner': 14208.397722794278}\n",
      "Starting iteration 1\n",
      "{'ner': 10290.876100309388}\n",
      "Starting iteration 2\n",
      "{'ner': 12019.649179039468}\n",
      "Starting iteration 3\n",
      "{'ner': 11041.912965121322}\n",
      "Starting iteration 4\n",
      "{'ner': 7556.105870439613}\n",
      "Starting iteration 5\n",
      "{'ner': 6998.120160554286}\n",
      "Starting iteration 6\n",
      "{'ner': 6092.6563845245055}\n",
      "Starting iteration 7\n",
      "{'ner': 7232.370569138731}\n",
      "Starting iteration 8\n",
      "{'ner': 4746.564893755847}\n",
      "Starting iteration 9\n",
      "{'ner': 5850.876040689234}\n",
      "Starting iteration 10\n",
      "{'ner': 4578.469948753975}\n",
      "Starting iteration 11\n",
      "{'ner': 4388.211800535973}\n",
      "Starting iteration 12\n",
      "{'ner': 7934.905154772421}\n",
      "Starting iteration 13\n",
      "{'ner': 4732.7523837081735}\n",
      "Starting iteration 14\n",
      "{'ner': 3960.874605380123}\n",
      "Starting iteration 15\n",
      "{'ner': 4568.806123594107}\n",
      "Starting iteration 16\n",
      "{'ner': 4125.741895400983}\n",
      "Starting iteration 17\n",
      "{'ner': 3929.5414740234146}\n",
      "Starting iteration 18\n",
      "{'ner': 3574.1447494540366}\n",
      "Starting iteration 19\n",
      "{'ner': 3288.6954046522546}\n",
      "Starting iteration 20\n",
      "{'ner': 3737.6643432152364}\n",
      "Starting iteration 21\n",
      "{'ner': 3795.880030124935}\n",
      "Starting iteration 22\n",
      "{'ner': 3206.789886391975}\n",
      "Starting iteration 23\n",
      "{'ner': 3336.8360856697855}\n",
      "Starting iteration 24\n",
      "{'ner': 2990.2925094694037}\n",
      "Starting iteration 25\n",
      "{'ner': 2829.5961323165834}\n",
      "Starting iteration 26\n",
      "{'ner': 2956.8120182975995}\n",
      "Starting iteration 27\n",
      "{'ner': 2902.2444671435246}\n",
      "Starting iteration 28\n",
      "{'ner': 2763.673629436009}\n",
      "Starting iteration 29\n",
      "{'ner': 2740.325703538094}\n",
      "Starting iteration 30\n",
      "{'ner': 2421.2036973121594}\n",
      "Starting iteration 31\n",
      "{'ner': 3151.391391227551}\n",
      "Starting iteration 32\n",
      "{'ner': 2705.2132262587047}\n",
      "Starting iteration 33\n",
      "{'ner': 2376.3890310904276}\n",
      "Starting iteration 34\n",
      "{'ner': 3112.6225293604816}\n",
      "Starting iteration 35\n",
      "{'ner': 2527.2456090189626}\n",
      "Starting iteration 36\n",
      "{'ner': 2674.8120199332825}\n",
      "Starting iteration 37\n",
      "{'ner': 2700.3749828102655}\n",
      "Starting iteration 38\n",
      "{'ner': 1964.6451043322254}\n",
      "Starting iteration 39\n",
      "{'ner': 1764.8830353283006}\n",
      "Starting iteration 40\n",
      "{'ner': 2178.5662252382413}\n",
      "Starting iteration 41\n",
      "{'ner': 2327.6734151037062}\n",
      "Starting iteration 42\n",
      "{'ner': 2212.1918681711927}\n",
      "Starting iteration 43\n",
      "{'ner': 2085.5890657302143}\n",
      "Starting iteration 44\n",
      "{'ner': 1992.8476585724302}\n",
      "Starting iteration 45\n",
      "{'ner': 2404.5829585686047}\n",
      "Starting iteration 46\n",
      "{'ner': 1818.463148498544}\n",
      "Starting iteration 47\n",
      "{'ner': 1652.1411961988526}\n",
      "Starting iteration 48\n",
      "{'ner': 1350.5758929239548}\n",
      "Starting iteration 49\n",
      "{'ner': 1540.0454134792235}\n",
      "Starting iteration 50\n",
      "{'ner': 1556.4527808638586}\n",
      "Starting iteration 51\n",
      "{'ner': 1921.7788593693488}\n",
      "Starting iteration 52\n",
      "{'ner': 2178.209379478852}\n",
      "Starting iteration 53\n",
      "{'ner': 1696.3875762487962}\n",
      "Starting iteration 54\n",
      "{'ner': 2061.107387348776}\n",
      "Starting iteration 55\n",
      "{'ner': 1899.4997558395437}\n",
      "Starting iteration 56\n",
      "{'ner': 1452.84507019178}\n",
      "Starting iteration 57\n",
      "{'ner': 1442.8324738227843}\n",
      "Starting iteration 58\n",
      "{'ner': 1741.13599576076}\n",
      "Starting iteration 59\n",
      "{'ner': 1329.3491743427476}\n",
      "Starting iteration 60\n",
      "{'ner': 1523.7846398463282}\n",
      "Starting iteration 61\n",
      "{'ner': 1402.1217867185594}\n",
      "Starting iteration 62\n",
      "{'ner': 1862.6303720519563}\n",
      "Starting iteration 63\n",
      "{'ner': 1270.5873191300964}\n",
      "Starting iteration 64\n",
      "{'ner': 1388.6792060385812}\n",
      "Starting iteration 65\n",
      "{'ner': 1513.6314492805318}\n",
      "Starting iteration 66\n",
      "{'ner': 1283.1443357607416}\n",
      "Starting iteration 67\n",
      "{'ner': 1539.1243935800524}\n",
      "Starting iteration 68\n",
      "{'ner': 1490.5613160317332}\n",
      "Starting iteration 69\n",
      "{'ner': 1751.1031707783304}\n",
      "Starting iteration 70\n",
      "{'ner': 1254.1711936014672}\n",
      "Starting iteration 71\n",
      "{'ner': 1586.0395770212353}\n",
      "Starting iteration 72\n",
      "{'ner': 1305.7930093674408}\n",
      "Starting iteration 73\n",
      "{'ner': 1296.940285188791}\n",
      "Starting iteration 74\n",
      "{'ner': 1231.2469355260387}\n",
      "Starting iteration 75\n",
      "{'ner': 1279.8312795650988}\n",
      "Starting iteration 76\n",
      "{'ner': 1242.7484950474468}\n",
      "Starting iteration 77\n",
      "{'ner': 809.7462797894126}\n",
      "Starting iteration 78\n",
      "{'ner': 1198.832807289646}\n",
      "Starting iteration 79\n",
      "{'ner': 1082.365472334504}\n",
      "Starting iteration 80\n",
      "{'ner': 1014.1240884916574}\n",
      "Starting iteration 81\n",
      "{'ner': 948.0154869512243}\n",
      "Starting iteration 82\n",
      "{'ner': 837.0634623771349}\n",
      "Starting iteration 83\n",
      "{'ner': 1122.7707959116312}\n",
      "Starting iteration 84\n",
      "{'ner': 972.8871252056155}\n",
      "Starting iteration 85\n",
      "{'ner': 973.8137511147327}\n",
      "Starting iteration 86\n",
      "{'ner': 1046.0546668392528}\n",
      "Starting iteration 87\n",
      "{'ner': 1123.8544828305194}\n",
      "Starting iteration 88\n",
      "{'ner': 852.6488186781795}\n",
      "Starting iteration 89\n",
      "{'ner': 1211.286196439548}\n",
      "Starting iteration 90\n",
      "{'ner': 792.7488950808148}\n",
      "Starting iteration 91\n",
      "{'ner': 1107.202803051162}\n",
      "Starting iteration 92\n",
      "{'ner': 961.6272422024177}\n",
      "Starting iteration 93\n",
      "{'ner': 855.7787581708667}\n",
      "Starting iteration 94\n",
      "{'ner': 947.2072595966036}\n",
      "Starting iteration 95\n",
      "{'ner': 904.0461799629609}\n",
      "Starting iteration 96\n",
      "{'ner': 850.6681041898142}\n",
      "Starting iteration 97\n",
      "{'ner': 745.8964180614419}\n",
      "Starting iteration 98\n",
      "{'ner': 852.9792428933017}\n",
      "Starting iteration 99\n",
      "{'ner': 1085.5086680500613}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x7f59db65bf40>"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_spacy_model(TRAIN_DATA,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d52367e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from spacy import displacy\n",
    "#nlp_res_model = spacy.load('nlp_model')\n",
    "#displacy.render(nlp_res_model(donna_text), style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "a33e10f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from doccano_transformer.datasets import NERDataset\n",
    "from doccano_transformer.utils import read_jsonl\n",
    "\n",
    "dataset = read_jsonl(filepath='/home/chris/reesby/reverse_Malih/Doccano/all.jsonl', dataset=NERDataset, encoding='utf-8')\n",
    "\n",
    "TRAINING_DATA =  dataset.to_spacy(tokenizer=str.split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "9afad663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object NERDataset.to_spacy at 0x7f5a4e5329e0>\n"
     ]
    }
   ],
   "source": [
    "print(TRAINING_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "a2c3b60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created blank 'en' model\n",
      "Starting iteration 0\n",
      "{}\n",
      "Starting iteration 1\n",
      "{}\n",
      "Starting iteration 2\n",
      "{}\n",
      "Starting iteration 3\n",
      "{}\n",
      "Starting iteration 4\n",
      "{}\n",
      "Starting iteration 5\n",
      "{}\n",
      "Starting iteration 6\n",
      "{}\n",
      "Starting iteration 7\n",
      "{}\n",
      "Starting iteration 8\n",
      "{}\n",
      "Starting iteration 9\n",
      "{}\n",
      "Starting iteration 10\n",
      "{}\n",
      "Starting iteration 11\n",
      "{}\n",
      "Starting iteration 12\n",
      "{}\n",
      "Starting iteration 13\n",
      "{}\n",
      "Starting iteration 14\n",
      "{}\n",
      "Starting iteration 15\n",
      "{}\n",
      "Starting iteration 16\n",
      "{}\n",
      "Starting iteration 17\n",
      "{}\n",
      "Starting iteration 18\n",
      "{}\n",
      "Starting iteration 19\n",
      "{}\n",
      "Starting iteration 20\n",
      "{}\n",
      "Starting iteration 21\n",
      "{}\n",
      "Starting iteration 22\n",
      "{}\n",
      "Starting iteration 23\n",
      "{}\n",
      "Starting iteration 24\n",
      "{}\n",
      "Starting iteration 25\n",
      "{}\n",
      "Starting iteration 26\n",
      "{}\n",
      "Starting iteration 27\n",
      "{}\n",
      "Starting iteration 28\n",
      "{}\n",
      "Starting iteration 29\n",
      "{}\n",
      "Starting iteration 30\n",
      "{}\n",
      "Starting iteration 31\n",
      "{}\n",
      "Starting iteration 32\n",
      "{}\n",
      "Starting iteration 33\n",
      "{}\n",
      "Starting iteration 34\n",
      "{}\n",
      "Starting iteration 35\n",
      "{}\n",
      "Starting iteration 36\n",
      "{}\n",
      "Starting iteration 37\n",
      "{}\n",
      "Starting iteration 38\n",
      "{}\n",
      "Starting iteration 39\n",
      "{}\n",
      "Starting iteration 40\n",
      "{}\n",
      "Starting iteration 41\n",
      "{}\n",
      "Starting iteration 42\n",
      "{}\n",
      "Starting iteration 43\n",
      "{}\n",
      "Starting iteration 44\n",
      "{}\n",
      "Starting iteration 45\n",
      "{}\n",
      "Starting iteration 46\n",
      "{}\n",
      "Starting iteration 47\n",
      "{}\n",
      "Starting iteration 48\n",
      "{}\n",
      "Starting iteration 49\n",
      "{}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x7f59d0eeef10>"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_spacy_model(TRAINING_DATA,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a41bd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7381773",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "f870140e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "  \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"manishiitg/distilbert-resume-parts-classify\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"manishiitg/distilbert-resume-parts-classify\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "100ef82a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokens = tokenizer(peter_text, padding=True, truncation=True, return_tensors=\"pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "583a349b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(**tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "4433ee61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceClassifierOutput(loss=None, logits=tensor([[-0.3887,  3.6951, -0.2164, -1.5175, -1.0144, -0.4429, -1.0947, -2.0734,\n",
      "         -0.5574, -2.3246, -2.7552,  0.8744]], grad_fn=<AddmmBackward>), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7eafd68",
   "metadata": {},
   "source": [
    "# Investigations into huggingface libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "ea12c5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity_group': 'ORG', 'score': 0.787362, 'word': 'met', 'start': 151, 'end': 154}, {'entity_group': 'ORG', 'score': 0.7318672, 'word': '##ology', 'start': 157, 'end': 162}, {'entity_group': 'LOC', 'score': 0.9200826, 'word': '##ney', 'start': 532, 'end': 535}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Initialize the NER pipeline\n",
    "ner_res = pipeline(\"ner\", model=   \"manishiitg/resume-ner\") #distilbert-resume-parts-classify\") \n",
    "#\"nikunjbjj/jd-resume-model\")# \n",
    "\n",
    "# NER task\n",
    "ner_result = ner(peter_text)\n",
    "\n",
    "# Print result\n",
    "print(ner_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "9e68c205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity_group': 'ORG', 'score': 0.787362, 'word': 'met', 'start': 151, 'end': 154}, {'entity_group': 'ORG', 'score': 0.7318672, 'word': '##ology', 'start': 157, 'end': 162}, {'entity_group': 'LOC', 'score': 0.9200826, 'word': '##ney', 'start': 532, 'end': 535}]\n"
     ]
    }
   ],
   "source": [
    "print(ner(peter_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "46b8e9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phone 123\n",
      "ORG bureau\n",
      "ORG of\n",
      "ORG ##ology\n",
      "ORG bo\n",
      "ORG ##m\n",
      "ExperianceYears 27\n",
      "ExperianceYears years\n",
      "Designation ##ologist\n",
      "DATE december\n",
      "DATE 2020\n",
      "EducationDegree masters\n",
      "DATE august\n",
      "DATE 2021\n",
      "EducationDegree master\n",
      "ExperianceYears 16\n",
      "ExperianceYears years\n",
      "DATE 2021\n"
     ]
    }
   ],
   "source": [
    "doc = ner_res(peter_text) # incase it isn't already lower case    \n",
    "for ent in doc:\n",
    "    #if(ent['entity']=='LABEL_9'):\n",
    "    print(ent['entity'],ent['word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119b0c14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20847c7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ce36ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31e2ec4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20bcd6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['diploma of higher education  health  bachelor of nursing science   pre registration'\n",
      " 'bachelor of medicine  bachelor of surgery'\n",
      " 'bachelor of education  primary   online ' ... 'm tech ' 'pharm d '\n",
      " 'phd ']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-cce208d018eb>:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  degree_uni = [i.lower() for i in df[2].str.replace('\\W', ' ')]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/home/chris/reesby/reverse_Malih/python/resume_parser-master/resume_parser/University_Courses.csv\", header=None)\n",
    "            #print(df[2])\n",
    "            \n",
    "degree_name = []\n",
    "# column 2 is the degree names - need to only have words no special characters that may affect the regex\n",
    "degree_uni = [i.lower() for i in df[2].str.replace('\\W', ' ')]\n",
    "            \n",
    "print(pd.unique(degree_uni))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0a5f48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
